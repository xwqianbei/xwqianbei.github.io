<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"xwqianbei.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.19.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="attention is all you need">
<meta property="og:type" content="website">
<meta property="og:title" content="米兰的小铁酱">
<meta property="og:url" content="http://xwqianbei.github.io/index.html">
<meta property="og:site_name" content="米兰的小铁酱">
<meta property="og:description" content="attention is all you need">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Wei">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://xwqianbei.github.io/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>米兰的小铁酱</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">米兰的小铁酱</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Wei</p>
  <div class="site-description" itemprop="description">attention is all you need</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">19</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/16/transformer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/16/transformer/" class="post-title-link" itemprop="url">transformer</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-03-16 12:52:36" itemprop="dateCreated datePublished" datetime="2024-03-16T12:52:36+08:00">2024-03-16</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>375</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Attention-Is-All-You-Need"><a href="#Attention-Is-All-You-Need" class="headerlink" title="Attention Is All You Need"></a>Attention Is All You Need</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li><strong>Transformer</strong>: based solely on <strong>attention mechanisms</strong>, dispensing with recurrence and convolutions entirely</li>
<li><strong>being more parallelizable</strong></li>
<li><strong>sequence to sequence</strong>(seq2seq)</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>Recurrent models 将 token的位置和时间步对齐</li>
<li><strong>attention mechanisms</strong>: 允许对token依赖关系进行建模，而无需考虑输入或输出序列中的距离</li>
</ul>
<h2 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h2><ul>
<li><strong>Encoder-Decoder structure</strong>: $x = (x_1, … , x_n)$ ——encoder—— $z = (z_1, …, z_n)$ ——decoder—— $y = (y_1, … , y_m)$</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/16/BERT/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/16/BERT/" class="post-title-link" itemprop="url">BERT</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-03-16 12:52:09 / 修改时间：13:00:04" itemprop="dateCreated datePublished" datetime="2024-03-16T12:52:09+08:00">2024-03-16</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.7k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>6 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding"><a href="#BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding" class="headerlink" title="BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"></a>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li><strong>BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers.</strong></li>
<li>the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li><strong>existing works</strong>: 将预训练语言表征用于下游任务的两种策略<ol>
<li>feature-based: ELMo 把pre-trained representation 作为额外的特征加入到任务特定的模型结构中</li>
<li>fine-tuning: GPT 在下游任务中简单的fine-tuning所有的预训练参数</li>
</ol>
</li>
<li><strong>limitation</strong>: the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks</li>
<li><strong>BERT</strong>: <ol>
<li><strong>MLM(masked language model)</strong>: Cloze task alleviates unidirectionality constraint -&gt; enables the representation to fuse the left and the right context</li>
<li><strong>next sentence prediction</strong>: pretrains text-pair representations</li>
</ol>
</li>
</ul>
<h2 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h2><h3 id="Unsupervised-Feature-based-Approaches"><a href="#Unsupervised-Feature-based-Approaches" class="headerlink" title="Unsupervised Feature-based  Approaches"></a>Unsupervised Feature-based  Approaches</h3><ul>
<li><strong>pretrain word embedding</strong>: left-to-right language model -&gt; 区分左右上下中正确或者不正确的单词</li>
<li><strong>pretrain sentence representation</strong>: 1. 对候选的下一个句子进行排名 2.  根据给定的前一个句子的表征从左到右地生成下一个句子地单词</li>
<li><strong>ELMo</strong>: <ol>
<li>They extract context-sensitive features from a left-to-right and a right-to-left language model. </li>
<li>The contextual representation of each token is the concatenation of the left-to-right and right-to-left representations<h3 id="Unsupervised-Fine-tuning-Approaches"><a href="#Unsupervised-Fine-tuning-Approaches" class="headerlink" title="Unsupervised Fine-tuning Approaches"></a>Unsupervised Fine-tuning Approaches</h3></li>
</ol>
</li>
<li>pre-trained from unlabeled text and fine-tuned for a supervised downstream task</li>
<li>OpenAI GPT<h3 id="Transfer-Learning-from-Supervised-Data"><a href="#Transfer-Learning-from-Supervised-Data" class="headerlink" title="Transfer Learning from Supervised Data"></a>Transfer Learning from Supervised Data</h3></li>
</ul>
<h2 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h2><h3 id="pre-training-and-fine-tuning"><a href="#pre-training-and-fine-tuning" class="headerlink" title="pre-training and fine-tuning"></a>pre-training and fine-tuning</h3><ul>
<li><strong>pre-training</strong>: During pre-training, the model is trained on unlabeled data over different pre-training tasks.</li>
<li><strong>fine-tuning</strong>: For finetuning, the BERT model is first initialized with the pre-trained parameters, and all of the parameters are fine-tuned using labeled data from the downstream tasks.</li>
<li>每个不同的下游任务都对用相同的预训练参数<br><img src="/2024/03/16/BERT/1710050250445.png" alt="1710050250445"><h3 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h3></li>
<li><strong>multi-layer bidirectional Transformer encoder</strong></li>
<li><em>L</em>: the number of Layers(Transformer blocks)</li>
<li><em>H</em>: the hidden size</li>
<li><em>A</em>: the number of self-attention heads</li>
<li><strong>$BERT_{BASE}$</strong>: (L = 12, H = 768, A = 12, Total Parameters = 110M)</li>
<li><strong>$BERT_{LARGE}$</strong>: (L = 24, H = 1024, A = 16, Total Parameters = 340M)</li>
<li><strong>BERT V.S. GPT</strong>: bidirectional self-attention V.S.  constrained self-attention(every token can only attend to context to its left.)<h3 id="Input-Output-Representations"><a href="#Input-Output-Representations" class="headerlink" title="Input/Output Representations"></a>Input/Output Representations</h3></li>
<li><strong>input sequence</strong>: input 可以是随意跨度的连续文本 input sequence可以是single sentence 或者 two sentences packed together<ol>
<li><em>Word Embedding</em>: WordPiece embeddings with a 30000 token vocabulary</li>
<li><em>First token of input sequnence</em>: <strong>[CLS] special classification token as C (dim = H)</strong></li>
<li><em>Sentences differentite</em>: <ol>
<li>[CLS] sentenceA [SEP] sentenceB</li>
<li>learned token embedding as $E_{A}$ or $E_{B}$, sentenceA or sentenceB<br><img src="/2024/03/16/BERT/1710053093135.png" alt="1710053093135"></li>
</ol>
</li>
</ol>
</li>
<li><strong>output representation</strong>: <ol>
<li>[CLS] as $C \in R^{H}$</li>
<li>final vector itoken -&gt; $T_{i} \in R^{H}$<h2 id="Pre-training-BERT"><a href="#Pre-training-BERT" class="headerlink" title="Pre-training BERT"></a>Pre-training BERT</h2><h3 id="Task-1-Masked-LM-MLM"><a href="#Task-1-Masked-LM-MLM" class="headerlink" title="Task #1: Masked LM(MLM)"></a>Task #1: Masked LM(MLM)</h3></li>
</ol>
</li>
<li>it is reasonable to believe that a deep bidirectional model is strictly more powerful than either a left-to-right model or the shallow concatenation of a left-toright and a right-to-left model.</li>
<li>standard conditional language models can only be trained left-to-right or right-to-left, <strong>since bidirectional conditioning would allow each word to indirectly “see itself”</strong></li>
<li><strong>MLM(masked LM)</strong>: 随机mask每个sequence 15% 的tokens<ol>
<li>pretrain时 input sequence 有[MASK] token 但是 fine-tuning时是没有[MASK] token的， 为了缓解这种差异，对这 15% mask tokens进行处理</li>
<li>最终 80% [MASK] 10 [RND(rondam token)] 10 [SAME(same token)]<br><img src="/2024/03/16/BERT/1710054577043.png" alt="1710054577043"><h3 id="Task-2-Next-Sentence-Prediction-NSP"><a href="#Task-2-Next-Sentence-Prediction-NSP" class="headerlink" title="Task #2: Next Sentence Prediction(NSP)"></a>Task #2: Next Sentence Prediction(NSP)</h3></li>
</ol>
</li>
<li>QA task and Natural Language Inference (NLI) are based on understanding the <strong>relationship between two sentences</strong>, <strong>which is not directly captured by language modeling.</strong></li>
<li><strong>binarized(0/1) next sentence prediction task</strong>: 判断sentenceB 是否是 sentenceA 的下一句<ul>
<li><strong>50%</strong> of the time B is the actual next sentence that follows A (labeled as IsNext),</li>
<li><strong>50%</strong> of the time it is a random sentence from the corpus (labeled as NotNext)</li>
<li>[CLS] C 被用作 NSP 二分类任务<h3 id="Pre-training-data"><a href="#Pre-training-data" class="headerlink" title="Pre-training data"></a>Pre-training data</h3></li>
</ul>
</li>
</ul>
<ol>
<li>BooksCorpus (800M words)</li>
<li>English Wikipedia (2,500M words).(Only passages)</li>
<li>It is critical to use a <strong>document-level corpus</strong> rather than a shuffled sentence-level corpus</li>
</ol>
<h2 id="Fine-tuning-BERT"><a href="#Fine-tuning-BERT" class="headerlink" title="Fine-tuning BERT"></a>Fine-tuning BERT</h2><ul>
<li>At the output, the token representations are fed into an output layer for tokenlevel tasks, such as sequence tagging or question answering, and the [CLS] representation is fed into an output layer for classification, such as entailment or sentiment analysis.</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/15/GoMARL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/15/GoMARL/" class="post-title-link" itemprop="url">GoMARL</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-03-15 11:17:36" itemprop="dateCreated datePublished" datetime="2024-03-15T11:17:36+08:00">2024-03-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-20 18:44:46" itemprop="dateModified" datetime="2024-03-20T18:44:46+08:00">2024-03-20</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.7k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>6 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Automatic-Grouping-for-Efficient-Cooperative-Multi-Agent-Reinforcement-Learning"><a href="#Automatic-Grouping-for-Efficient-Cooperative-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Automatic Grouping for Efficient Cooperative Multi-Agent Reinforcement Learning"></a>Automatic Grouping for Efficient Cooperative Multi-Agent Reinforcement Learning</h1><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li><strong>GoMARL</strong>: Group-oriented Multi-Agent Reinforcement Learning learn automatic grouping without domain knowledge for efficient cooperation.</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul>
<li>GoMARL:<ol>
<li>GoMARL holds a dualhierarchical value factorization</li>
<li>learns dynamic groups with a “select-and-kick-out” scheme.</li>
</ol>
</li>
<li>GoMARL continuously selects agents unsuitable for their current groups based on the learning weights of the decomposition from the group-wise value to local utilities and kicks them out to reorganize the group division.</li>
<li>GoMARL transforms various informative training signals, including individual group-related information, group state, and global state, into network weights, which extracts effective guidance for policy improvement and enables flexible adaptation to the dynamic changes in the number of subgroups and the number of agents per group.</li>
</ul>
<h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><h2 id="Group-oriented-Multi-Agent-Reinforcement-Learning"><a href="#Group-oriented-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Group-oriented Multi-Agent Reinforcement Learning"></a>Group-oriented Multi-Agent Reinforcement Learning</h2><ul>
<li><strong>Atuomatic grouping module</strong>: GoMARL decomposes the global action-value Qtot into groupwise values Qg and trains agents by groups in a fine-grained manner.<br><img src="/2024/03/15/GoMARL/1710561769884.png" alt="1710561769884"><h2 id="4-1-Automatic-Grouping-Mechanism"><a href="#4-1-Automatic-Grouping-Mechanism" class="headerlink" title="4.1 Automatic Grouping Mechanism"></a>4.1 Automatic Grouping Mechanism</h2></li>
<li>learn a mapping relationship $f_{g}$ : A -&gt; G. -&gt; divide the team into dynamic groups in an end-to-end fashion by maximizing the expected global return $Q_{g}^{tot}$.</li>
<li><strong>Individual    w! Generator</strong>: GoMARL “selects and kicks out” agents whose individual utilities hold small mixing weights and contribute a little to their group-wise Q values</li>
<li><p>We empirically utilize seventy percent of each group’s average weight to assess whether an agent fits its current group.<br><img src="/2024/03/15/GoMARL/1710852685014.png" alt="1710852685014"></p>
</li>
<li><p><strong>Group Adjustment Operator</strong>: $O_{g}:\{w_{1}^{1},…,W_{1}^{n}\}-&gt;\{w_{1}^{g1},…,w_{1}^{gm}\}$ concatenates the wi1 of agents in the same group to form a set of group-wise wg 1 to generate group action-value.<br><img src="/2024/03/15/GoMARL/1710852756019.png" alt="1710852756019"></p>
</li>
</ul>
<h2 id="4-2-Specialized-Agent-Network-for-Decentralized-Execution"><a href="#4-2-Specialized-Agent-Network-for-Decentralized-Execution" class="headerlink" title="4.2 Specialized Agent Network for Decentralized Execution"></a>4.2 Specialized Agent Network for Decentralized Execution</h2><ul>
<li><strong>group-wise information e</strong>: Integrating group-wise information e into the decision-making process enables consideration of cooperative behaviors.<br><img src="/2024/03/15/GoMARL/1710853359419.png" alt="1710853359419"></li>
<li><p><strong>group-related info encoder $f_{e}(·; \theta_{e})$</strong>: train the encoder network as an extractor, where the extracted agent info $e$ of agents from the same group should be similar. To avoid all agents’ $e^{i}$ collapsing to be alikem the regularizer also encourages diversity between agents from different groups.<br><img src="/2024/03/15/GoMARL/1710854191337.png" alt="1710854191337"></p>
</li>
<li><p><strong>Group-related Info Decoder</strong>: $e^{i}$ fed into a decoder $f_{d}(·;\theta_{d})$ to generate the parameters of the agent network’s upper MLP</p>
<ol>
<li>Our method hybridizes the efficiency of parameter-sharing and the policy diversity needed for complex collaboration.</li>
<li>providing informative group-related information to enrich local utilities and promote intra-group cooperation.</li>
</ol>
</li>
</ul>
<h2 id="4-3-Overall-Learning-Framework"><a href="#4-3-Overall-Learning-Framework" class="headerlink" title="4.3 Overall Learning Framework"></a>4.3 Overall Learning Framework</h2><p><img src="/2024/03/15/GoMARL/1710855631168.png" alt="1710855631168"></p>
<ul>
<li>two mixing networks:<ol>
<li>group-wise $Q^{g}$</li>
<li>global $Q^{tot}$</li>
</ol>
</li>
<li>group-wise $Q^{g}$: <ol>
<li>$w_{1}^{g}$ -&gt; “selects and kicks out” decides the group division</li>
<li>$w_{2}^{g}$ -&gt; generate $Q^{g}$\ carries group status information</li>
</ol>
</li>
<li>$w_{2}^{g}$: Group-related Info $e = \{e_{t}^{1},e_{t}^{2},…,e_{t}^{n}\}$  (from group-related info encoder) -&gt; pooling Operation -&gt; Group State$s = \{s_{t}^{g1},s_{t}^{g2},…,s_{t}^{gm}\}$ -&gt; Group-wise 𝐰𝟐 Generator$f_{w2}(s_{g})$ -&gt; $\{w_{2}^{g1}, … ,w_{2}^{gm}\}$</li>
<li>$Q^{tot}$: <ol>
<li>$w_{1}^{Q^{tot}}$: $s = \{s_{t}^{g1},s_{t}^{g2},…,s_{t}^{gm}\}$ -&gt; $f_{w1}^{i}(·;\theta_{w1}^[i])$ -&gt; $\{w_{1}^{g1},…,w_{1}^{gm}\}$ -&gt; k dim hidden state</li>
<li>global state $s$ -&gt; $f_{w2}(·|s)$ -&gt; $w_{2}$ -&gt; $Q^{tot}$<br><img src="/2024/03/15/GoMARL/1710860129623.png" alt="1710860129623"></li>
</ol>
</li>
</ul>
<h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="5-1-Performance-on-SMAC"><a href="#5-1-Performance-on-SMAC" class="headerlink" title="5.1 Performance on SMAC"></a>5.1 Performance on SMAC</h2><ul>
<li><strong>Overall performance</strong>:<br><img src="/2024/03/15/GoMARL/1710930045436.png" alt="1710930045436"></li>
<li><strong>Parameter size for value mixing.</strong>: GoMARL outperforms other methods despite using fewer mixing parameters, highlighting its inherent superiority over methods relying on stronger mixing networks.<br><img src="/2024/03/15/GoMARL/1710930152325.png" alt="1710930152325"></li>
<li><strong>Component analysis and ablation study</strong>:<ol>
<li>Learned grouping analysis<br><img src="/2024/03/15/GoMARL/1710930947555.png" alt="1710930947555"></li>
<li>Component study of the specialized agents: We transplant our specialized agent network (SAN) into other baselines to verify module effectiveness.<br><img src="/2024/03/15/GoMARL/1710931015065.png" alt="1710931015065"></li>
<li>Ablation study of the informative group-related signals: <h2 id="5-2-Performance-on-Google-Research-Football"><a href="#5-2-Performance-on-Google-Research-Football" class="headerlink" title="5.2 Performance on Google Research Football"></a>5.2 Performance on Google Research Football</h2></li>
</ol>
</li>
<li>in which the first group brought the ball into the penalty area through smooth coordination, while the second group created two shoots and the final goal through skillful cooperation<br><img src="/2024/03/15/GoMARL/1710931307596.png" alt="1710931307596"></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/12/RLHF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/12/RLHF/" class="post-title-link" itemprop="url">RLHF</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-03-12 12:45:44" itemprop="dateCreated datePublished" datetime="2024-03-12T12:45:44+08:00">2024-03-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-15 11:17:03" itemprop="dateModified" datetime="2024-03-15T11:17:03+08:00">2024-03-15</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.1k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>4 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Training-language-models-to-follow-instructions-with-human-feedback"><a href="#Training-language-models-to-follow-instructions-with-human-feedback" class="headerlink" title="Training language models to follow instructions with human feedback"></a>Training language models to follow instructions with human feedback</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li><strong>Challenge</strong>: 一味地增大大模型也不能从本质上更好地遵循用户的意图， 大模型生成的输出可能是不真实的，有毒害的 或者是对用户没有帮助的</li>
<li><strong>In this paper</strong>: 展示了一种通过根据人类反馈进行微调来使大模型与用户对各种任务的意图保持一致的途径</li>
<li><strong>InstructGPT</strong>: <ol>
<li>we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning.</li>
<li>We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback.</li>
</ol>
</li>
<li><strong>Result</strong>: In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters.</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li><strong>misaligned</strong>: LM的目标是在互联网的网页上预测下一个token 而不是 有效且安全地遵循人类执行</li>
<li><strong>RLHF</strong>: uses human preferences as reward signal to fine-tune our models.</li>
</ul>
<h2 id="Methods-and-experimental-details"><a href="#Methods-and-experimental-details" class="headerlink" title="Methods and experimental details"></a>Methods and experimental details</h2><h3 id="3-1-High-level-methodology"><a href="#3-1-High-level-methodology" class="headerlink" title="3.1 High-level methodology"></a>3.1 High-level methodology</h3><ul>
<li>start with:<ol>
<li>a pretrained language model</li>
<li>a distribution of prompts(which we want our model to produce aligned outputs)</li>
<li>a team of trained hunman labrlers</li>
</ol>
</li>
<li>steps:<ol>
<li><strong>collect demonstration data, and train a supervised policy</strong>: <ul>
<li>human labelers provide demonstrations of the desired behavior on the input prompt distribution. </li>
<li>We then fine-tune a pretrained GPT-3 model on this data using supervised learning.</li>
</ul>
</li>
<li><strong>Collect comparison data, and train a reward model.</strong>:<ul>
<li>We collect a dataset of comparisons between model outputs, where labelers indicate which output they prefer for a given input</li>
<li>We then train a reward model to predict the human-preferred output.</li>
</ul>
</li>
<li><strong>Optimize a policy against the reward model using PPO.</strong>:<ul>
<li>We use the output of the RM as a scalar reward.</li>
<li>We fine-tune the supervised policy to optimize this reward using the PPO algorithm<h3 id="3-2-Dataset"><a href="#3-2-Dataset" class="headerlink" title="3.2 Dataset"></a>3.2 Dataset</h3></li>
</ul>
</li>
</ol>
</li>
<li><strong>prompts dataset</strong>: 1. primarily of text prompts submitted to a commercial language model API 2. a small number of labeler-written prompts.</li>
<li><strong>prompts are diverse</strong>: include generation, question answering, dialog, summarization, extractions, and other natural language tasks</li>
<li><strong>prompts clean</strong>: 1. heuristically deduplicate prompts  2. ensure that the validation and test sets contain no data from users whose data is in the training set. 3. We also filter prompts containing personally identifiable information (PII).</li>
<li><strong>prompts  produce three different datasets used in our fine-tuning procedure</strong>:<ol>
<li>SFT dataset</li>
<li>RM dataset</li>
<li>PPO dataset</li>
</ol>
</li>
</ul>
<h3 id="3-3-Human-data-collection"><a href="#3-3-Human-data-collection" class="headerlink" title="3.3 Human data collection"></a>3.3 Human data collection</h3><h3 id="3-4-Models"><a href="#3-4-Models" class="headerlink" title="3.4 Models"></a>3.4 Models</h3><ol>
<li><strong>Supervised fine-tuning(SFT)</strong>: fine-tune GPT-3 on our labeler demonstrations using supervised learning.</li>
<li></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/11/DPO/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/11/DPO/" class="post-title-link" itemprop="url">DPO</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-03-11 13:16:25 / 修改时间：15:28:32" itemprop="dateCreated datePublished" datetime="2024-03-11T13:16:25+08:00">2024-03-11</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>963</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Direct-Preference-Optimization-Your-Language-Model-is-Secretly-a-Reward-Model"><a href="#Direct-Preference-Optimization-Your-Language-Model-is-Secretly-a-Reward-Model" class="headerlink" title="Direct Preference Optimization: Your Language Model is Secretly a Reward Model"></a>Direct Preference Optimization: Your Language Model is Secretly a Reward Model</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li><strong>RLHF</strong>: 收集人类偏好标签数据，使用强化学习对齐人类偏好</li>
<li><strong>challenge</strong>: RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model</li>
<li><strong>DPO</strong>: <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2></li>
<li><strong>RLHF</strong>: <ol>
<li>fit a reward model to a dataset of human prefereneces</li>
<li>use RL to optimize a language model policy to produce response assigned high reward without drifting excessively far from the original model</li>
<li>RLHF pipline is considerably more complex than supervised learning</li>
</ol>
</li>
<li><strong>DPO</strong>: <ol>
<li>without explict reward modeling or reinforcement learning</li>
<li>implicity optimizes the same objective as existing RLHF algorithms(reward maximization with a KL-divergence constraint)</li>
<li>DPO update increases the relative log probability of preferred to dispreferred responses</li>
<li>but it incorporates a dynamic, per-example importance weight that prevents the model degeneration that we find occurs with a naive probability ratio objective.</li>
</ol>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/10/%E5%85%B3%E4%BA%8Ehexo-new/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/10/%E5%85%B3%E4%BA%8Ehexo-new/" class="post-title-link" itemprop="url">关于hexo new</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-03-10 12:40:06" itemprop="dateCreated datePublished" datetime="2024-03-10T12:40:06+08:00">2024-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-16 12:56:54" itemprop="dateModified" datetime="2024-03-16T12:56:54+08:00">2024-03-16</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>546</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="关于hexo-new"><a href="#关于hexo-new" class="headerlink" title="关于hexo new"></a>关于hexo new</h1><p><a target="_blank" rel="noopener" href="https://hexo.io/docs/commands.html#new">官网说明</a><br><img src="/2024/03/10/%E5%85%B3%E4%BA%8Ehexo-new/1710045767599.png" alt="1710045767599"></p>
<ul>
<li>如果layout没有指明的话，hexo会使用config.yml中的default_layout的默认配置，一般默认是post</li>
<li>如果title中包含空格的话，则需要使用引号</li>
</ul>
<h2 id="hexo-new-post"><a href="#hexo-new-post" class="headerlink" title="hexo new post"></a>hexo new post</h2><ul>
<li>layout 为 post时，会在./source/_posts下创建一个title.md文档 </li>
<li>使用markdown编辑title.md 并 执行 <code>hexo g -d</code>则可以在网页中看到相应内容</li>
</ul>
<h2 id="hexo-new-draft"><a href="#hexo-new-draft" class="headerlink" title="hexo new draft"></a>hexo new draft</h2><ul>
<li>执行 <code>hexo new draft &#39;title&#39;</code> 后， hexo会在./source/_drafts下创建一个 title.md文档（如果是第一次执行则会先创建_drafts文件夹）</li>
<li>该title.md为草稿状态 执行 <code>hexo g -d</code>则在网页中看不到相应内容</li>
<li><strong>如何发布draft状态的文档？</strong> -&gt; <code>hexo publish draft title</code> 这样_drafts下的title.md会消失，_posts下会出现一个title.md</li>
<li>可以使用<code>hexo g --draft</code>， <code>hexo s --draft</code>命令来在本地预览我们的草稿效果</li>
</ul>
<h2 id="hexo-new-page"><a href="#hexo-new-page" class="headerlink" title="hexo new page"></a>hexo new page</h2><ul>
<li><code>hexo new page &#39;about&#39;</code> 会在source下生成一个名为about的文件夹， 文件夹下会有一个index.md的文件</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/" class="post-title-link" itemprop="url">ATTENTION-GUIDED CONTRASTIVE ROLE REPRE-SENTATIONS FOR MULTI-AGENT REINFORCEMENT LEARNING</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-03-04 21:27:25" itemprop="dateCreated datePublished" datetime="2024-03-04T21:27:25+08:00">2024-03-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-08 23:31:56" itemprop="dateModified" datetime="2024-03-08T23:31:56+08:00">2024-03-08</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>8 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING-ICLR-24-Nanjing-University"><a href="#ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING-ICLR-24-Nanjing-University" class="headerlink" title="ATTENTION-GUIDED CONTRASTIVE ROLE REPRE-SENTATIONS FOR MULTI-AGENT REINFORCEMENT LEARNING ICLR-24 Nanjing University"></a>ATTENTION-GUIDED CONTRASTIVE ROLE REPRE-SENTATIONS FOR MULTI-AGENT REINFORCEMENT LEARNING ICLR-24 Nanjing University</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li><strong>Challenge</strong>: 智能体之间的有效合作</li>
<li><strong>motivation</strong>: 受角色和智能体行为模式之间相关性的启发</li>
<li><strong>ACORM</strong>: Attention-guided COntrastive Role representation learning for MARL (ACORM) -&gt; 促进智能体之间 行为异质化、知识传输、技能上的协调</li>
<li><strong>methods</strong>: <ol>
<li>使用最大化互信息来形式化角色表征学习(role representation learning) -&gt; 推导出对比学习目标 -&gt; 精简估计负样本的分布 </li>
<li>利用注意力机制促进在价值分解中global state 关注到 学习到的role representations -&gt; 隐式地指导智能体协调在一个技能性的skillful role space 以生成具有表现力的信用分配</li>
</ol>
</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li><strong>challenge</strong>: 共享policy参数 加速massive agents场景下的 合作学习 -&gt; 导致同质的行为 阻碍了多样性探索和复杂的合作 </li>
<li><strong>existing works</strong>: Contrastive Identity-Aware Learning for Multi-Agent Value Decomposition -&gt; 利用对比学习使得agent对应的identify representation 相互区分 -&gt; 忽略了通过隐式任务分配进行team分解的有效性   通过分层控制结构将任务分解为一组技能 或者 子任务</li>
<li><strong>methods</strong>: <ol>
<li>形式化学习目标为 role 和 它的representation 之间的互信息 -&gt; 最大限度减少role的不确定性 最小化保留role无关信息 为了简单的近似 negative pairs 的分布 -&gt; 通过编码它的trajectory到隐空间中 提取agent的行为 并根据隐空间定期地将agent分为几个簇 -&gt; 来自不同簇的点被分配为负对</li>
<li>使用注意力机制 促进 在价值分解时 global state 注意 学习到的role representation -&gt; 隐式的指导 agent 在一个 skillful role space 中协调 -&gt; 随着role的涌现生成更有表现力的 信用分配</li>
</ol>
</li>
</ul>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><ul>
<li><strong>idea</strong>: 学习一个紧凑的角色表示(compact role representation) 这个compact role representation可以个性化智能体复杂的行为模式 -&gt; 使用这个角色信息可以促进个体 policy 学习 和 引导agent 协作 -&gt; 相似角色的 agents 可以通过更积极的知识传输 享受更高的学习效率 并且 不同角色的区分也可以保证智能体的异质性<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Our idea is to learn a compact role representation that can characterize complex behavior patterns of agents, and use the role information to facilitate individual policy learning and guide agent coordination. Agents with similar roles can enjoy higher learning efficiency via more aggressive knowledge transfer, and agent heterogeneity is also guaranteed with the discrimination of diverse roles.</span><br></pre></td></tr></table></figure></li>
<li><strong>definition 1:</strong> 在多智能体任务中，每个agent都和一个描述其行为模式的role Mi 相关联 -&gt; 其中Mi 通过 role representation zi 量化表示 -&gt; zi 通过 L个observation-action pairs训练 这些O-A pairs来自agent i的trajectory -&gt; πzi : O × A × Z → [0, 1] is the individual policy for agent i</li>
<li><strong>ACORM</strong>: （1）通过对比学习 学习 agents 对应的 role representations zi （2）使用注意力机制 促进 global state 关注 学习到的role patterns -&gt; 引导在high-level role space 中 技能上的智能体协调 -&gt; 促进有表现力的信用分配</li>
</ul>
<h3 id="Contrastive-Role-Representations"><a href="#Contrastive-Role-Representations" class="headerlink" title="Contrastive Role Representations"></a>Contrastive Role Representations</h3><ul>
<li><strong>Objective</strong>: 1. agents with similar behavior patterns exhibit closer role representations 2. with notably different strategies are pushed away from each other.</li>
<li><strong>key issues</strong> 1. how to define a feasible metric to quantify the degree of similaroty between agent’s behaviors 2. how to develop an efficient method to optimize the discrimination of role representations</li>
<li><strong>1 Agent Embedding</strong>:  $e^{t}_{i}=f_{\phi}(o_{i}^{t-1}, a_{i}^{t-1}, e_{i}^{t-1})$ distance between the obtained agent embeddings -&gt; metric to measure the behavior dissimilarity between agents</li>
<li><p><strong>2 Contrastive Learning</strong>: discriminative role representation &lt;- agent’s behaviors patterns   -&gt;   maximize the mutual information between the role and its representation learn a role encoder that maximally reduces role uncertainty while minimally preserving role-irrelevant information<br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709886563461.png" alt="1709886563461"></p>
</li>
<li><p>$L_{CL}$:<br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709886677274.png" alt="1709886677274"><br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709886690507.png" alt="1709886690507"><br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709886699683.png" alt="1709886699683"><br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709886709036.png" alt="1709886709036"></p>
<ul>
<li>$|M| = K$ K：we partition all n agents into K clusters $\{C_{j}\}_{j=1}^{K}$ according to agent embeddings.</li>
<li>$z^{T}_{i}Wz_{i’}$ where W is a learnable parameter matrix</li>
</ul>
</li>
<li><strong>MOCO method</strong>: maintain a query encoder θq and a key encoder θk, and use a momentum update to facilitate the key representations’ consistency as<br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709887238174.png" alt="1709887238174"><br>where β ∈ [0, 1) is a momentum coefficient, and only parameters θq are updated by backpropagation.</li>
</ul>
<h3 id="ATTENTION-GUIDED-ROLE-COORDINATION"><a href="#ATTENTION-GUIDED-ROLE-COORDINATION" class="headerlink" title="ATTENTION-GUIDED ROLE COORDINATION"></a>ATTENTION-GUIDED ROLE COORDINATION</h3><ul>
<li>global state 和 agent’s role representations 进行多头注意力机制计算: 促进global state关注学习到的 role representations -&gt; 从而在价值分解中提供更具有表现力的信用分配</li>
</ul>
<h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><p><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709893541789.png" alt="1709893541789"></p>
<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><ol>
<li>Can ACORM facilitate learning efficiency and stability in complex multi-agent domains? If so, what are the respective contributions of different modules to the performance gains? (See Sec. 3.1).</li>
<li>Can ACORM learn meaningful role representations associated with agent’s behavior patterns and achieve effective dynamic team composition? (See Sec. 3.2).</li>
<li>Can ACORM successfully attend to learned role representations to realize skillful role coordination and more expressive credit assignment? (See Sec. 3.3).</li>
</ol>
<h3 id="3-1-efficiency-and-stability"><a href="#3-1-efficiency-and-stability" class="headerlink" title="3.1 efficiency and stability"></a>3.1 efficiency and stability</h3><ul>
<li><strong>performance</strong>:<br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709895486679.png" alt="1709895486679"></li>
<li>A noteworthy point is that ACORM outperforms all baselines by the largest margin on super hard maps that demand a significantly higher degree of behavior diversity and coordination: MMM2, 3s5z_vs_3s6z, and corridor.</li>
<li>ACORM exhibits the lowest variance in learning curves, signifying not only superior learning efficiency but also enhanced training stability.</li>
<li><strong>Abations</strong>:<br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709897074004.png" alt="1709897074004"></li>
<li>It demonstrates that both components are essential for ACORM’s capability and they are complementary to each other.</li>
<li>Specifically, ACORM_w/o_MHA (Vanilla) obtains very similar performance compared to ACORM_w/o_MHA, indicating that the effectiveness comes from the attention module other than encoding the state trajectory via a GRU.</li>
</ul>
<h3 id="3-2-CONTRASTIVE-ROLE-REPRESENTATIONS"><a href="#3-2-CONTRASTIVE-ROLE-REPRESENTATIONS" class="headerlink" title="3.2 CONTRASTIVE ROLE REPRESENTATIONS"></a>3.2 CONTRASTIVE ROLE REPRESENTATIONS</h3><p><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709908700732.png" alt="1709908700732"></p>
<ul>
<li><strong>why use the contrastive learning</strong>: <ul>
<li><strong>ei v.s. zi</strong>: Initially (t = 1, 12), all agent embeddings tend to be crowded together with limited discrimination, and the K-means algorithm moderately separates them into several clusters. Via contrastive learning, the acquired role representations within the same cluster are pushed closer to each other, and those in different clusters are notably separated.</li>
<li>At a later stage (t = 40), agent embeddings are already scattered widely throughout the space with a good clustering effect so far. This phenomenon indicates that the system has learned effective role assignment with heterogeneous behavior patterns. Then, the role encoder transforms these agent embeddings into more discriminative role representations.</li>
<li>至于本文为什么要在K-means聚类的基础上再做对比学习，我认为应该是et的特征包含了很多任务无关的信息，而进行对比学习可以提取出更为抽象有用的特征zt 仅包含agent技能合作相关的信息<h3 id="3-3-ATTENTION-GUIDED-ROLE-COORDINATION"><a href="#3-3-ATTENTION-GUIDED-ROLE-COORDINATION" class="headerlink" title="3.3 ATTENTION-GUIDED ROLE COORDINATION"></a>3.3 ATTENTION-GUIDED ROLE COORDINATION</h3><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709909066167.png" alt="1709909066167"></li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/02/pytorch%E4%B8%ADreshape%E5%92%8Ctranspose/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/02/pytorch%E4%B8%ADreshape%E5%92%8Ctranspose/" class="post-title-link" itemprop="url">pytorch中reshape和transpose</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-03-02 20:58:24 / 修改时间：22:01:24" itemprop="dateCreated datePublished" datetime="2024-03-02T20:58:24+08:00">2024-03-02</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>998</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="pytorch中reshape和transpose"><a href="#pytorch中reshape和transpose" class="headerlink" title="pytorch中reshape和transpose"></a>pytorch中reshape和transpose</h1><h2 id="torch-reshape-input-shape-x-reshape-size"><a href="#torch-reshape-input-shape-x-reshape-size" class="headerlink" title="torch.reshape(input, shape) x.reshape(size)"></a>torch.reshape(input, shape) x.reshape(size)</h2><ul>
<li><strong>reshape就相当于把原本的数据从最里层[]中的数据开始逐层展开成一维的数据, 然后重构数据</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.arange(<span class="number">24</span>).reshape(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">y = torch.reshape(x, (<span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;x: <span class="subst">&#123;x&#125;</span>\ny: <span class="subst">&#123;y&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">x: tensor([[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">         [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">         [ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">         [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>],</span><br><span class="line">         [<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>]]])</span><br><span class="line">y: tensor([[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>],</span><br><span class="line">         [ <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>],</span><br><span class="line">         [ <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>],</span><br><span class="line">         [ <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>],</span><br><span class="line">         [<span class="number">15</span>, <span class="number">16</span>, <span class="number">17</span>],</span><br><span class="line">         [<span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">         [<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>]]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="/2024/03/02/pytorch%E4%B8%ADreshape%E5%92%8Ctranspose/1709385244067.png" alt="1709385244067"></p>
<h2 id="2-torch-transpose-input-dim0-dim1-gt-tensor"><a href="#2-torch-transpose-input-dim0-dim1-gt-tensor" class="headerlink" title="2 torch.transpose(input, dim0, dim1) -&gt; tensor"></a>2 torch.transpose(input, dim0, dim1) -&gt; tensor</h2><ul>
<li>transpose操作可能经常使用，但是当维度高时很容易对数据的结构产生理解上的混乱，<strong>关键在于不用管数据层面时怎么转置的，而是抓住每个维度的意义，转置只是把两个维度的意义交换了一下，而其他维度是不会改变的</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.arange(<span class="number">24</span>).reshape(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">y = torch.transpose(x, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;x=<span class="subst">&#123;x&#125;</span>\ny=<span class="subst">&#123;y&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">x=tensor([[[[ <span class="number">0</span>,  <span class="number">1</span>],</span><br><span class="line">          [ <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">          [ <span class="number">4</span>,  <span class="number">5</span>]],</span><br><span class="line"></span><br><span class="line">         [[ <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">          [ <span class="number">8</span>,  <span class="number">9</span>],</span><br><span class="line">          [<span class="number">10</span>, <span class="number">11</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[<span class="number">12</span>, <span class="number">13</span>],</span><br><span class="line">          [<span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">          [<span class="number">16</span>, <span class="number">17</span>]],</span><br><span class="line"></span><br><span class="line">         [[<span class="number">18</span>, <span class="number">19</span>],</span><br><span class="line">          [<span class="number">20</span>, <span class="number">21</span>],</span><br><span class="line">          [<span class="number">22</span>, <span class="number">23</span>]]]])</span><br><span class="line">y=tensor([[[[ <span class="number">0</span>,  <span class="number">1</span>],</span><br><span class="line">          [ <span class="number">6</span>,  <span class="number">7</span>]],</span><br><span class="line"></span><br><span class="line">         [[ <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">          [ <span class="number">8</span>,  <span class="number">9</span>]],</span><br><span class="line"></span><br><span class="line">         [[ <span class="number">4</span>,  <span class="number">5</span>],</span><br><span class="line">          [<span class="number">10</span>, <span class="number">11</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[<span class="number">12</span>, <span class="number">13</span>],</span><br><span class="line">          [<span class="number">18</span>, <span class="number">19</span>]],</span><br><span class="line"></span><br><span class="line">         [[<span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">          [<span class="number">20</span>, <span class="number">21</span>]],</span><br><span class="line"></span><br><span class="line">         [[<span class="number">16</span>, <span class="number">17</span>],</span><br><span class="line">          [<span class="number">22</span>, <span class="number">23</span>]]]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="/2024/03/02/pytorch%E4%B8%ADreshape%E5%92%8Ctranspose/1709388056943.png" alt="1709388056943"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/01/pytorch%E4%B8%AD%E5%85%B3%E4%BA%8E%E7%9F%A9%E9%98%B5%E7%9A%84%E4%B9%98%E6%B3%95%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/01/pytorch%E4%B8%AD%E5%85%B3%E4%BA%8E%E7%9F%A9%E9%98%B5%E7%9A%84%E4%B9%98%E6%B3%95%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">pytorch中关于矩阵的乘法总结</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-03-01 19:50:57" itemprop="dateCreated datePublished" datetime="2024-03-01T19:50:57+08:00">2024-03-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-02 20:26:17" itemprop="dateModified" datetime="2024-03-02T20:26:17+08:00">2024-03-02</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>7 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="pytorch中关于矩阵的乘法总结"><a href="#pytorch中关于矩阵的乘法总结" class="headerlink" title="pytorch中关于矩阵的乘法总结"></a>pytorch中关于矩阵的乘法总结</h1><p><strong>torch.mul(), *, torch.mm(), @, torch.bmm(), torch.dot(), torch.mv(), torch.matmul(), torch.einsum()</strong></p>
<h2 id="1-torch-mul-x-y-和-运算"><a href="#1-torch-mul-x-y-和-运算" class="headerlink" title="1 torch.mul(x, y) 和 * 运算"></a>1 torch.mul(x, y) 和 * 运算</h2><ul>
<li>表示两个矩阵对应位置上的元素相乘，可以广播<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">y = <span class="number">2</span></span><br><span class="line">z = torch.mul(x, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(x, y, x * y, z))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>]])</span><br><span class="line"><span class="number">2</span></span><br><span class="line">tensor([[<span class="number">2.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>]])</span><br><span class="line">tensor([[<span class="number">2.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="2-torch-mm-x-y-和-运算"><a href="#2-torch-mm-x-y-和-运算" class="headerlink" title="2 torch.mm(x, y) 和 @运算"></a>2 torch.mm(x, y) 和 @运算</h2><ul>
<li>线性代数中的矩阵乘法 x 和 y只能是二维 x = (n, m) y = (m, p) torch.mm(x, y) = (n, p) <strong>不支持广播</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">y = torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">z = torch.mm(x, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(x, y, x @ y, z))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tensor([[-<span class="number">0.6012</span>,  <span class="number">1.4065</span>, -<span class="number">0.8835</span>],</span><br><span class="line">        [ <span class="number">0.4794</span>,  <span class="number">0.7086</span>,  <span class="number">0.6491</span>]])</span><br><span class="line">tensor([[ <span class="number">0.4244</span>, -<span class="number">0.4029</span>,  <span class="number">1.6911</span>,  <span class="number">0.5680</span>],</span><br><span class="line">        [ <span class="number">2.0811</span>,  <span class="number">0.4253</span>, -<span class="number">0.9852</span>,  <span class="number">0.8593</span>],</span><br><span class="line">        [-<span class="number">0.5978</span>,  <span class="number">0.7914</span>, -<span class="number">0.7826</span>,  <span class="number">0.4671</span>]])</span><br><span class="line">tensor([[ <span class="number">3.2000</span>,  <span class="number">0.1413</span>, -<span class="number">1.7111</span>,  <span class="number">0.4544</span>],</span><br><span class="line">        [ <span class="number">1.2901</span>,  <span class="number">0.6219</span>, -<span class="number">0.3954</span>,  <span class="number">1.1845</span>]])</span><br><span class="line">tensor([[ <span class="number">3.2000</span>,  <span class="number">0.1413</span>, -<span class="number">1.7111</span>,  <span class="number">0.4544</span>],</span><br><span class="line">        [ <span class="number">1.2901</span>,  <span class="number">0.6219</span>, -<span class="number">0.3954</span>,  <span class="number">1.1845</span>]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="3-torch-bmm-x-y"><a href="#3-torch-bmm-x-y" class="headerlink" title="3 torch.bmm(x, y)"></a>3 torch.bmm(x, y)</h2><ul>
<li>执行一个batch的矩阵乘法 <strong>x 和 y 必须是3-D张量 且是x = (b, n, m) y = (b, n, p)</strong> <strong>不支持广播</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">y = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">z = torch.bmm(x, y) <span class="comment"># [2, 2, 4]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(x, y, z))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[ <span class="number">0.4304</span>,  <span class="number">0.9056</span>,  <span class="number">0.4578</span>],</span><br><span class="line">         [-<span class="number">3.1024</span>,  <span class="number">0.1185</span>,  <span class="number">0.8143</span>]],</span><br><span class="line"></span><br><span class="line">        [[-<span class="number">0.1249</span>, -<span class="number">0.7876</span>, -<span class="number">0.0426</span>],</span><br><span class="line">         [-<span class="number">1.5175</span>, -<span class="number">1.0602</span>,  <span class="number">2.4620</span>]]])</span><br><span class="line">tensor([[[-<span class="number">0.2403</span>, -<span class="number">0.5954</span>,  <span class="number">1.2178</span>, -<span class="number">1.3661</span>],</span><br><span class="line">         [ <span class="number">0.7626</span>, -<span class="number">0.0728</span>,  <span class="number">0.2353</span>,  <span class="number">0.0733</span>],</span><br><span class="line">         [-<span class="number">0.1070</span>, -<span class="number">0.3414</span>, -<span class="number">0.2480</span>, -<span class="number">1.0626</span>]],</span><br><span class="line"></span><br><span class="line">        [[-<span class="number">0.5171</span>, -<span class="number">0.6608</span>,  <span class="number">1.3164</span>, -<span class="number">1.2351</span>],</span><br><span class="line">         [ <span class="number">1.9305</span>,  <span class="number">0.1607</span>,  <span class="number">0.8634</span>, -<span class="number">0.6855</span>],</span><br><span class="line">         [-<span class="number">0.3664</span>,  <span class="number">0.3081</span>,  <span class="number">1.1023</span>, -<span class="number">1.6237</span>]]])</span><br><span class="line">tensor([[[ <span class="number">0.5383</span>, -<span class="number">0.4785</span>,  <span class="number">0.6237</span>, -<span class="number">1.0081</span>],</span><br><span class="line">         [ <span class="number">0.7487</span>,  <span class="number">1.5606</span>, -<span class="number">3.9523</span>,  <span class="number">3.3816</span>]],</span><br><span class="line"></span><br><span class="line">        [[-<span class="number">1.4404</span>, -<span class="number">0.0572</span>, -<span class="number">0.8915</span>,  <span class="number">0.7634</span>],</span><br><span class="line">         [-<span class="number">2.1641</span>,  <span class="number">1.5909</span>, -<span class="number">0.1993</span>, -<span class="number">1.3964</span>]]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="4-torch-dot-x-y-gt-tensor-scalar"><a href="#4-torch-dot-x-y-gt-tensor-scalar" class="headerlink" title="4 torch.dot(x, y) -&gt; tensor (scalar)"></a>4 torch.dot(x, y) -&gt; tensor (scalar)</h1><ul>
<li><strong>两个元素个数相同的一维张量</strong>点积运算 <strong>和numpy的dot不同，torch.dot(x, y)仅支持两个一维张量</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">y = torch.tensor([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">z = torch.dot(x, y) <span class="comment"># 1*4 + 2*5 + 3*6 = 32</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(x, y, z))</span><br><span class="line"></span><br><span class="line"><span class="comment"># error</span></span><br><span class="line"><span class="comment"># y = torch.tensor([[1, 2, 3], [1, 2, 3], [1, 2, 3]])</span></span><br><span class="line"><span class="comment"># z = torch.dot(x, y)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">tensor([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"><span class="number">32</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="5-torch-mv-x-y-gt-Tensor"><a href="#5-torch-mv-x-y-gt-Tensor" class="headerlink" title="5 torch.mv(x, y) -&gt; Tensor"></a>5 torch.mv(x, y) -&gt; Tensor</h1><ul>
<li><strong>matrix-vector and x = (n, m) y = (m, ) -&gt; return = (n, )</strong> 不支持广播<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">y = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">z = torch.mv(x, y) <span class="comment"># [1*1 + 2*2 + 3*3, 4*1 + 5*2 + 6*3]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(x, y, z))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ERROR</span></span><br><span class="line"><span class="comment"># z = torch.mv(y, x)</span></span><br><span class="line"><span class="comment"># print(&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;.format(x, y, z))</span></span><br><span class="line"><span class="comment"># y = torch.tensor([1, 2])</span></span><br><span class="line"><span class="comment"># z = torch.mv(y, x)</span></span><br><span class="line"><span class="comment"># print(&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;.format(x, y, z))</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">tensor([<span class="number">14</span>, <span class="number">32</span>])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="6-torch-matmul-x-y-gt-tensor"><a href="#6-torch-matmul-x-y-gt-tensor" class="headerlink" title="6 torch.matmul(x, y) -&gt; tensor"></a>6 torch.matmul(x, y) -&gt; tensor</h1><ul>
<li>比较全能的一种乘法 <strong>支持广播</strong> 支持任何维度可相乘的tensor相乘<br><img src="/2024/03/01/pytorch%E4%B8%AD%E5%85%B3%E4%BA%8E%E7%9F%A9%E9%98%B5%E7%9A%84%E4%B9%98%E6%B3%95%E6%80%BB%E7%BB%93/1709381483833.png" alt="1709381483833"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">y = torch.randn(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">z = torch.matmul(x, y) <span class="comment"># [2, 2, 2, 2]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(x, y, z))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[[-<span class="number">0.9772</span>, -<span class="number">0.0628</span>, -<span class="number">0.5369</span>],</span><br><span class="line">          [-<span class="number">0.3113</span>,  <span class="number">1.7524</span>,  <span class="number">0.7249</span>]],</span><br><span class="line"></span><br><span class="line">         [[-<span class="number">1.1878</span>,  <span class="number">0.0895</span>,  <span class="number">0.7625</span>],</span><br><span class="line">          [ <span class="number">0.2828</span>,  <span class="number">0.1154</span>, -<span class="number">0.8482</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ <span class="number">0.8277</span>,  <span class="number">0.4449</span>,  <span class="number">0.0741</span>],</span><br><span class="line">          [ <span class="number">0.9390</span>, -<span class="number">0.6762</span>,  <span class="number">0.4093</span>]],</span><br><span class="line"></span><br><span class="line">         [[-<span class="number">0.2564</span>,  <span class="number">0.8857</span>, -<span class="number">0.1946</span>],</span><br><span class="line">          [-<span class="number">0.9418</span>,  <span class="number">0.0510</span>, -<span class="number">0.2456</span>]]]])</span><br><span class="line">tensor([[[[-<span class="number">0.0997</span>,  <span class="number">0.2760</span>],</span><br><span class="line">          [-<span class="number">0.7134</span>, -<span class="number">0.4839</span>],</span><br><span class="line">          [-<span class="number">1.3931</span>,  <span class="number">0.2729</span>]],</span><br><span class="line"></span><br><span class="line">         [[-<span class="number">0.4765</span>,  <span class="number">0.5714</span>],</span><br><span class="line">          [ <span class="number">1.4368</span>,  <span class="number">1.2979</span>],</span><br><span class="line">          [ <span class="number">1.0061</span>,  <span class="number">0.2874</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[-<span class="number">0.0596</span>,  <span class="number">0.5366</span>],</span><br><span class="line">          [ <span class="number">0.2938</span>, -<span class="number">0.6728</span>],</span><br><span class="line">          [-<span class="number">0.0664</span>, -<span class="number">1.8749</span>]],</span><br><span class="line"></span><br><span class="line">         [[ <span class="number">0.1983</span>, -<span class="number">0.2220</span>],</span><br><span class="line">          [-<span class="number">1.4755</span>, -<span class="number">2.2627</span>],</span><br><span class="line">          [-<span class="number">0.4390</span>,  <span class="number">0.4608</span>]]]])</span><br><span class="line">tensor([[[[ <span class="number">0.8902</span>, -<span class="number">0.3858</span>],</span><br><span class="line">          [-<span class="number">2.2289</span>, -<span class="number">0.7362</span>]],</span><br><span class="line"></span><br><span class="line">         [[ <span class="number">1.4617</span>, -<span class="number">0.3435</span>],</span><br><span class="line">          [-<span class="number">0.8224</span>,  <span class="number">0.0675</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ <span class="number">0.0764</span>,  <span class="number">0.0058</span>],</span><br><span class="line">          [-<span class="number">0.2818</span>,  <span class="number">0.1914</span>]],</span><br><span class="line"></span><br><span class="line">         [[-<span class="number">1.2722</span>, -<span class="number">2.0368</span>],</span><br><span class="line">          [-<span class="number">0.1542</span>, -<span class="number">0.0195</span>]]]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="7-torch-einsum-gt-爱因斯坦求和约定"><a href="#7-torch-einsum-gt-爱因斯坦求和约定" class="headerlink" title="7 torch.einsum() -&gt; 爱因斯坦求和约定"></a>7 torch.einsum() -&gt; 爱因斯坦求和约定</h1><ul>
<li><em>功能十分强大，支持求和运算, 各种乘法运算, transpose运算等等</em><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># trace</span></span><br><span class="line">torch.einsum(<span class="string">&#x27;ii&#x27;</span>, torch.randn(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># diagonal</span></span><br><span class="line">torch.einsum(<span class="string">&#x27;ii-&gt;i&#x27;</span>, torch.randn(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># outer product</span></span><br><span class="line">x = torch.randn(<span class="number">5</span>)</span><br><span class="line">y = torch.randn(<span class="number">4</span>)</span><br><span class="line">torch.einsum(<span class="string">&#x27;i,j-&gt;ij&#x27;</span>, x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># batch matrix multiplication</span></span><br><span class="line">As = torch.randn(<span class="number">3</span>, <span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line">Bs = torch.randn(<span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>)</span><br><span class="line">torch.einsum(<span class="string">&#x27;bij,bjk-&gt;bik&#x27;</span>, As, Bs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># with sublist format and ellipsis</span></span><br><span class="line">torch.einsum(As, [..., <span class="number">0</span>, <span class="number">1</span>], Bs, [..., <span class="number">1</span>, <span class="number">2</span>], [..., <span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># batch permute</span></span><br><span class="line">A = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">torch.einsum(<span class="string">&#x27;...ij-&gt;...ji&#x27;</span>, A).shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># equivalent to torch.nn.functional.bilinear</span></span><br><span class="line">A = torch.randn(<span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>)</span><br><span class="line">l = torch.randn(<span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line">r = torch.randn(<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">torch.einsum(<span class="string">&#x27;bn,anm,bm-&gt;ba&#x27;</span>, l, A, r)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="8-总结"><a href="#8-总结" class="headerlink" title="8 总结"></a>8 总结</h1><p>一般在神经网络中常用的就是 1. torch.dot(x, y) 求两个向量的点积 2. torch.bmm(x, y) 求一个batch的矩阵数据相乘 (<strong>必须是三维[b, n, m] × [b, m, q]</strong>) 3. torch.matmul(x, y)<strong>求维度超过三维或者需要广播的矩阵乘法</strong></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/02/26/RACE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/02/26/RACE/" class="post-title-link" itemprop="url">RACE</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-02-26 20:57:10" itemprop="dateCreated datePublished" datetime="2024-02-26T20:57:10+08:00">2024-02-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-29 12:06:50" itemprop="dateModified" datetime="2024-02-29T12:06:50+08:00">2024-02-29</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="RACE-Improve-Multi-Agent-Reinforcement-Learning-with-Representation-Asymmetry-and-Collaborative-Evolution"><a href="#RACE-Improve-Multi-Agent-Reinforcement-Learning-with-Representation-Asymmetry-and-Collaborative-Evolution" class="headerlink" title="RACE: Improve Multi-Agent Reinforcement Learning with Representation Asymmetry and Collaborative Evolution"></a>RACE: Improve Multi-Agent Reinforcement Learning with Representation Asymmetry and Collaborative Evolution</h1><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li><strong>challenge</strong>: MARL 在合作方面 挣扎在低质量的奖励信号和高不稳定性</li>
<li><strong>Evolutionary Algorithm(EA)</strong>: 更好的收敛、更加健壮鲁棒、对奖励信号不敏感</li>
<li><strong>in this paper</strong>: 本文提出一个混合框架： Representation Asymmetry and Collaboration Evolution (RACE) -&gt; 将EA和MARL结合 以达到高效的合作</li>
<li><strong>method</strong>: RACE 维持一个MARL team和一群EA teams. 为了高效的知识共享和策略探索 -&gt; RACE 把不同team控制相同agent的 policies 分解成 1. shared nonlinear observation representation encoder（共享的非线性观察表示编码器encoder） 2. individual linear policy representations.（独立的线性策略表示） trick1: 为了解决部分观察的问题, 本文引入Value-Aware Mutual Information Maximization （价值感知 互信息最大化）-&gt; 利用有关全局状态的有用信息增强共享表示    trick2: 为了促进协调 -&gt; 使用新颖的 agent-level 交叉和变异算子来进化种群 -&gt; 为MARL提供多样化的经验  trick3: MARL优化它的策略并且将它们注入到种群中进化</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul>
<li><strong>motivation</strong>: EA has strong exploration ability, good robustness, and stable convergence. EA offers numerous strengths that can complement the weaknesses of MARL.</li>
<li><strong>challenge</strong>: 独立维持和优化每个team的policy是非常不高效的 并且这样无法利用其他team获得的有价值的知识 在广阔的非线性策略空间探索合作是非常低效的</li>
<li><strong>methods</strong>: 提出两级团队策略测结构 1. 共享的非线性观察表示(shared observation represention encoder) 2. 独立的线性策略表示(independent policy representions)</li>
<li><strong>represention asymmetry</strong>: independent policy构建的不同表示范围</li>
<li><strong>observation representation encoder</strong>: 负责共享任务相关和合作相关的知识 -&gt; 通过价值函数最大化的集成（涉及所有的EA team 和 MARL team）更新方向进行优化</li>
<li><strong>Value-Aware Mutual Information Maximization</strong>: 最大化共享观察表示(shared observation representations) 和全局状态的互信息(MI)。 -&gt; 在低价值状态下进行最大化可能导致对共享观察表示(shared observation representation)的负面影响 -&gt; 导致合作不理想 -&gt; Value-Aware MI: 归一化状态价值函数作为权重 已到达 提取全局状态信息加入共享观察表示(shared observation representations)</li>
<li><strong>independent linear policy</strong>: 在更加紧凑和有利的线性空间 policy的探索更加有效 从而促进合作</li>
<li><strong>EA</strong>: EA进化种群 生成多样性的经验 -&gt; 被MARL使用 -&gt; 反过来，MARL team通过收集的样本进行优化 并且定期加入种群进化</li>
<li>agent-level 交叉变异 -&gt; 交换两个team的individual policy representation -&gt; 探索更好的团队合作</li>
</ul>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><ol>
<li>Representation Asymmetry of team construction</li>
<li>How to learn the shared observation representation encoders</li>
<li>How to improve MARL with Collaborative Evolution</li>
</ol>
<ul>
<li><strong>motivation</strong>: 每个team 独立的策略构建限制了teams之间的知识共享和在策略空间上的探索 -&gt; inspired by ERL-Re -&gt; 本文提出Representation-Asymmetry Team Construction(RATC) 使能够高效的知识共享和策略探索</li>
</ul>
<h3 id="Shared-Observation-Representation-Learning"><a href="#Shared-Observation-Representation-Learning" class="headerlink" title="Shared Observation Representation Learning"></a>Shared Observation Representation Learning</h3>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Wei</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">41k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">1:08</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
