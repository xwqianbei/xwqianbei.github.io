<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"xwqianbei.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.19.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="attention is all you need">
<meta property="og:type" content="website">
<meta property="og:title" content="米兰的小铁酱">
<meta property="og:url" content="http://xwqianbei.github.io/index.html">
<meta property="og:site_name" content="米兰的小铁酱">
<meta property="og:description" content="attention is all you need">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Wei">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://xwqianbei.github.io/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>米兰的小铁酱</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">米兰的小铁酱</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Wei</p>
  <div class="site-description" itemprop="description">attention is all you need</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">13</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/" class="post-title-link" itemprop="url">ATTENTION-GUIDED CONTRASTIVE ROLE REPRE-SENTATIONS FOR MULTI-AGENT REINFORCEMENT LEARNING</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-03-04 21:27:25" itemprop="dateCreated datePublished" datetime="2024-03-04T21:27:25+08:00">2024-03-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-08 23:31:56" itemprop="dateModified" datetime="2024-03-08T23:31:56+08:00">2024-03-08</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>8 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING-ICLR-24-Nanjing-University"><a href="#ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING-ICLR-24-Nanjing-University" class="headerlink" title="ATTENTION-GUIDED CONTRASTIVE ROLE REPRE-SENTATIONS FOR MULTI-AGENT REINFORCEMENT LEARNING ICLR-24 Nanjing University"></a>ATTENTION-GUIDED CONTRASTIVE ROLE REPRE-SENTATIONS FOR MULTI-AGENT REINFORCEMENT LEARNING ICLR-24 Nanjing University</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li><strong>Challenge</strong>: 智能体之间的有效合作</li>
<li><strong>motivation</strong>: 受角色和智能体行为模式之间相关性的启发</li>
<li><strong>ACORM</strong>: Attention-guided COntrastive Role representation learning for MARL (ACORM) -&gt; 促进智能体之间 行为异质化、知识传输、技能上的协调</li>
<li><strong>methods</strong>: <ol>
<li>使用最大化互信息来形式化角色表征学习(role representation learning) -&gt; 推导出对比学习目标 -&gt; 精简估计负样本的分布 </li>
<li>利用注意力机制促进在价值分解中global state 关注到 学习到的role representations -&gt; 隐式地指导智能体协调在一个技能性的skillful role space 以生成具有表现力的信用分配</li>
</ol>
</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li><strong>challenge</strong>: 共享policy参数 加速massive agents场景下的 合作学习 -&gt; 导致同质的行为 阻碍了多样性探索和复杂的合作 </li>
<li><strong>existing works</strong>: Contrastive Identity-Aware Learning for Multi-Agent Value Decomposition -&gt; 利用对比学习使得agent对应的identify representation 相互区分 -&gt; 忽略了通过隐式任务分配进行team分解的有效性   通过分层控制结构将任务分解为一组技能 或者 子任务</li>
<li><strong>methods</strong>: <ol>
<li>形式化学习目标为 role 和 它的representation 之间的互信息 -&gt; 最大限度减少role的不确定性 最小化保留role无关信息 为了简单的近似 negative pairs 的分布 -&gt; 通过编码它的trajectory到隐空间中 提取agent的行为 并根据隐空间定期地将agent分为几个簇 -&gt; 来自不同簇的点被分配为负对</li>
<li>使用注意力机制 促进 在价值分解时 global state 注意 学习到的role representation -&gt; 隐式的指导 agent 在一个 skillful role space 中协调 -&gt; 随着role的涌现生成更有表现力的 信用分配</li>
</ol>
</li>
</ul>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><ul>
<li><strong>idea</strong>: 学习一个紧凑的角色表示(compact role representation) 这个compact role representation可以个性化智能体复杂的行为模式 -&gt; 使用这个角色信息可以促进个体 policy 学习 和 引导agent 协作 -&gt; 相似角色的 agents 可以通过更积极的知识传输 享受更高的学习效率 并且 不同角色的区分也可以保证智能体的异质性<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Our idea is to learn a compact role representation that can characterize complex behavior patterns of agents, and use the role information to facilitate individual policy learning and guide agent coordination. Agents with similar roles can enjoy higher learning efficiency via more aggressive knowledge transfer, and agent heterogeneity is also guaranteed with the discrimination of diverse roles.</span><br></pre></td></tr></table></figure></li>
<li><strong>definition 1:</strong> 在多智能体任务中，每个agent都和一个描述其行为模式的role Mi 相关联 -&gt; 其中Mi 通过 role representation zi 量化表示 -&gt; zi 通过 L个observation-action pairs训练 这些O-A pairs来自agent i的trajectory -&gt; πzi : O × A × Z → [0, 1] is the individual policy for agent i</li>
<li><strong>ACORM</strong>: （1）通过对比学习 学习 agents 对应的 role representations zi （2）使用注意力机制 促进 global state 关注 学习到的role patterns -&gt; 引导在high-level role space 中 技能上的智能体协调 -&gt; 促进有表现力的信用分配</li>
</ul>
<h3 id="Contrastive-Role-Representations"><a href="#Contrastive-Role-Representations" class="headerlink" title="Contrastive Role Representations"></a>Contrastive Role Representations</h3><ul>
<li><strong>Objective</strong>: 1. agents with similar behavior patterns exhibit closer role representations 2. with notably different strategies are pushed away from each other.</li>
<li><strong>key issues</strong> 1. how to define a feasible metric to quantify the degree of similaroty between agent’s behaviors 2. how to develop an efficient method to optimize the discrimination of role representations</li>
<li><strong>1 Agent Embedding</strong>:  $e^{t}_{i}=f_{\phi}(o_{i}^{t-1}, a_{i}^{t-1}, e_{i}^{t-1})$ distance between the obtained agent embeddings -&gt; metric to measure the behavior dissimilarity between agents</li>
<li><p><strong>2 Contrastive Learning</strong>: discriminative role representation &lt;- agent’s behaviors patterns   -&gt;   maximize the mutual information between the role and its representation learn a role encoder that maximally reduces role uncertainty while minimally preserving role-irrelevant information<br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709886563461.png" alt="1709886563461"></p>
</li>
<li><p>$L_{CL}$:<br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709886677274.png" alt="1709886677274"><br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709886690507.png" alt="1709886690507"><br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709886699683.png" alt="1709886699683"><br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709886709036.png" alt="1709886709036"></p>
<ul>
<li>$|M| = K$ K：we partition all n agents into K clusters $\{C_{j}\}_{j=1}^{K}$ according to agent embeddings.</li>
<li>$z^{T}_{i}Wz_{i’}$ where W is a learnable parameter matrix</li>
</ul>
</li>
<li><strong>MOCO method</strong>: maintain a query encoder θq and a key encoder θk, and use a momentum update to facilitate the key representations’ consistency as<br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709887238174.png" alt="1709887238174"><br>where β ∈ [0, 1) is a momentum coefficient, and only parameters θq are updated by backpropagation.</li>
</ul>
<h3 id="ATTENTION-GUIDED-ROLE-COORDINATION"><a href="#ATTENTION-GUIDED-ROLE-COORDINATION" class="headerlink" title="ATTENTION-GUIDED ROLE COORDINATION"></a>ATTENTION-GUIDED ROLE COORDINATION</h3><ul>
<li>global state 和 agent’s role representations 进行多头注意力机制计算: 促进global state关注学习到的 role representations -&gt; 从而在价值分解中提供更具有表现力的信用分配</li>
</ul>
<h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><p><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709893541789.png" alt="1709893541789"></p>
<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><ol>
<li>Can ACORM facilitate learning efficiency and stability in complex multi-agent domains? If so, what are the respective contributions of different modules to the performance gains? (See Sec. 3.1).</li>
<li>Can ACORM learn meaningful role representations associated with agent’s behavior patterns and achieve effective dynamic team composition? (See Sec. 3.2).</li>
<li>Can ACORM successfully attend to learned role representations to realize skillful role coordination and more expressive credit assignment? (See Sec. 3.3).</li>
</ol>
<h3 id="3-1-efficiency-and-stability"><a href="#3-1-efficiency-and-stability" class="headerlink" title="3.1 efficiency and stability"></a>3.1 efficiency and stability</h3><ul>
<li><strong>performance</strong>:<br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709895486679.png" alt="1709895486679"></li>
<li>A noteworthy point is that ACORM outperforms all baselines by the largest margin on super hard maps that demand a significantly higher degree of behavior diversity and coordination: MMM2, 3s5z_vs_3s6z, and corridor.</li>
<li>ACORM exhibits the lowest variance in learning curves, signifying not only superior learning efficiency but also enhanced training stability.</li>
<li><strong>Abations</strong>:<br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709897074004.png" alt="1709897074004"></li>
<li>It demonstrates that both components are essential for ACORM’s capability and they are complementary to each other.</li>
<li>Specifically, ACORM_w/o_MHA (Vanilla) obtains very similar performance compared to ACORM_w/o_MHA, indicating that the effectiveness comes from the attention module other than encoding the state trajectory via a GRU.</li>
</ul>
<h3 id="3-2-CONTRASTIVE-ROLE-REPRESENTATIONS"><a href="#3-2-CONTRASTIVE-ROLE-REPRESENTATIONS" class="headerlink" title="3.2 CONTRASTIVE ROLE REPRESENTATIONS"></a>3.2 CONTRASTIVE ROLE REPRESENTATIONS</h3><p><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709908700732.png" alt="1709908700732"></p>
<ul>
<li><strong>why use the contrastive learning</strong>: <ul>
<li><strong>ei v.s. zi</strong>: Initially (t = 1, 12), all agent embeddings tend to be crowded together with limited discrimination, and the K-means algorithm moderately separates them into several clusters. Via contrastive learning, the acquired role representations within the same cluster are pushed closer to each other, and those in different clusters are notably separated.</li>
<li>At a later stage (t = 40), agent embeddings are already scattered widely throughout the space with a good clustering effect so far. This phenomenon indicates that the system has learned effective role assignment with heterogeneous behavior patterns. Then, the role encoder transforms these agent embeddings into more discriminative role representations.</li>
<li>至于本文为什么要在K-means聚类的基础上再做对比学习，我认为应该是et的特征包含了很多任务无关的信息，而进行对比学习可以提取出更为抽象有用的特征zt 仅包含agent技能合作相关的信息<h3 id="3-3-ATTENTION-GUIDED-ROLE-COORDINATION"><a href="#3-3-ATTENTION-GUIDED-ROLE-COORDINATION" class="headerlink" title="3.3 ATTENTION-GUIDED ROLE COORDINATION"></a>3.3 ATTENTION-GUIDED ROLE COORDINATION</h3><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709909066167.png" alt="1709909066167"></li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/02/pytorch%E4%B8%ADreshape%E5%92%8Ctranspose/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/02/pytorch%E4%B8%ADreshape%E5%92%8Ctranspose/" class="post-title-link" itemprop="url">pytorch中reshape和transpose</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-03-02 20:58:24 / 修改时间：22:01:24" itemprop="dateCreated datePublished" datetime="2024-03-02T20:58:24+08:00">2024-03-02</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>998</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>2 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="pytorch中reshape和transpose"><a href="#pytorch中reshape和transpose" class="headerlink" title="pytorch中reshape和transpose"></a>pytorch中reshape和transpose</h1><h2 id="torch-reshape-input-shape-x-reshape-size"><a href="#torch-reshape-input-shape-x-reshape-size" class="headerlink" title="torch.reshape(input, shape) x.reshape(size)"></a>torch.reshape(input, shape) x.reshape(size)</h2><ul>
<li><strong>reshape就相当于把原本的数据从最里层[]中的数据开始逐层展开成一维的数据, 然后重构数据</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.arange(<span class="number">24</span>).reshape(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">y = torch.reshape(x, (<span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;x: <span class="subst">&#123;x&#125;</span>\ny: <span class="subst">&#123;y&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">x: tensor([[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">         [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">         [ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">         [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>],</span><br><span class="line">         [<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>]]])</span><br><span class="line">y: tensor([[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>],</span><br><span class="line">         [ <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>],</span><br><span class="line">         [ <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>],</span><br><span class="line">         [ <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>],</span><br><span class="line">         [<span class="number">15</span>, <span class="number">16</span>, <span class="number">17</span>],</span><br><span class="line">         [<span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">         [<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>]]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="/2024/03/02/pytorch%E4%B8%ADreshape%E5%92%8Ctranspose/1709385244067.png" alt="1709385244067"></p>
<h2 id="2-torch-transpose-input-dim0-dim1-gt-tensor"><a href="#2-torch-transpose-input-dim0-dim1-gt-tensor" class="headerlink" title="2 torch.transpose(input, dim0, dim1) -&gt; tensor"></a>2 torch.transpose(input, dim0, dim1) -&gt; tensor</h2><ul>
<li>transpose操作可能经常使用，但是当维度高时很容易对数据的结构产生理解上的混乱，<strong>关键在于不用管数据层面时怎么转置的，而是抓住每个维度的意义，转置只是把两个维度的意义交换了一下，而其他维度是不会改变的</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.arange(<span class="number">24</span>).reshape(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">y = torch.transpose(x, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;x=<span class="subst">&#123;x&#125;</span>\ny=<span class="subst">&#123;y&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">x=tensor([[[[ <span class="number">0</span>,  <span class="number">1</span>],</span><br><span class="line">          [ <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">          [ <span class="number">4</span>,  <span class="number">5</span>]],</span><br><span class="line"></span><br><span class="line">         [[ <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">          [ <span class="number">8</span>,  <span class="number">9</span>],</span><br><span class="line">          [<span class="number">10</span>, <span class="number">11</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[<span class="number">12</span>, <span class="number">13</span>],</span><br><span class="line">          [<span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">          [<span class="number">16</span>, <span class="number">17</span>]],</span><br><span class="line"></span><br><span class="line">         [[<span class="number">18</span>, <span class="number">19</span>],</span><br><span class="line">          [<span class="number">20</span>, <span class="number">21</span>],</span><br><span class="line">          [<span class="number">22</span>, <span class="number">23</span>]]]])</span><br><span class="line">y=tensor([[[[ <span class="number">0</span>,  <span class="number">1</span>],</span><br><span class="line">          [ <span class="number">6</span>,  <span class="number">7</span>]],</span><br><span class="line"></span><br><span class="line">         [[ <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">          [ <span class="number">8</span>,  <span class="number">9</span>]],</span><br><span class="line"></span><br><span class="line">         [[ <span class="number">4</span>,  <span class="number">5</span>],</span><br><span class="line">          [<span class="number">10</span>, <span class="number">11</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[<span class="number">12</span>, <span class="number">13</span>],</span><br><span class="line">          [<span class="number">18</span>, <span class="number">19</span>]],</span><br><span class="line"></span><br><span class="line">         [[<span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">          [<span class="number">20</span>, <span class="number">21</span>]],</span><br><span class="line"></span><br><span class="line">         [[<span class="number">16</span>, <span class="number">17</span>],</span><br><span class="line">          [<span class="number">22</span>, <span class="number">23</span>]]]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="/2024/03/02/pytorch%E4%B8%ADreshape%E5%92%8Ctranspose/1709388056943.png" alt="1709388056943"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/01/pytorch%E4%B8%AD%E5%85%B3%E4%BA%8E%E7%9F%A9%E9%98%B5%E7%9A%84%E4%B9%98%E6%B3%95%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/01/pytorch%E4%B8%AD%E5%85%B3%E4%BA%8E%E7%9F%A9%E9%98%B5%E7%9A%84%E4%B9%98%E6%B3%95%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">pytorch中关于矩阵的乘法总结</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-03-01 19:50:57" itemprop="dateCreated datePublished" datetime="2024-03-01T19:50:57+08:00">2024-03-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-03-02 20:26:17" itemprop="dateModified" datetime="2024-03-02T20:26:17+08:00">2024-03-02</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>7 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="pytorch中关于矩阵的乘法总结"><a href="#pytorch中关于矩阵的乘法总结" class="headerlink" title="pytorch中关于矩阵的乘法总结"></a>pytorch中关于矩阵的乘法总结</h1><p><strong>torch.mul(), *, torch.mm(), @, torch.bmm(), torch.dot(), torch.mv(), torch.matmul(), torch.einsum()</strong></p>
<h2 id="1-torch-mul-x-y-和-运算"><a href="#1-torch-mul-x-y-和-运算" class="headerlink" title="1 torch.mul(x, y) 和 * 运算"></a>1 torch.mul(x, y) 和 * 运算</h2><ul>
<li>表示两个矩阵对应位置上的元素相乘，可以广播<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">y = <span class="number">2</span></span><br><span class="line">z = torch.mul(x, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(x, y, x * y, z))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>]])</span><br><span class="line"><span class="number">2</span></span><br><span class="line">tensor([[<span class="number">2.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>]])</span><br><span class="line">tensor([[<span class="number">2.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="2-torch-mm-x-y-和-运算"><a href="#2-torch-mm-x-y-和-运算" class="headerlink" title="2 torch.mm(x, y) 和 @运算"></a>2 torch.mm(x, y) 和 @运算</h2><ul>
<li>线性代数中的矩阵乘法 x 和 y只能是二维 x = (n, m) y = (m, p) torch.mm(x, y) = (n, p) <strong>不支持广播</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">y = torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">z = torch.mm(x, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(x, y, x @ y, z))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tensor([[-<span class="number">0.6012</span>,  <span class="number">1.4065</span>, -<span class="number">0.8835</span>],</span><br><span class="line">        [ <span class="number">0.4794</span>,  <span class="number">0.7086</span>,  <span class="number">0.6491</span>]])</span><br><span class="line">tensor([[ <span class="number">0.4244</span>, -<span class="number">0.4029</span>,  <span class="number">1.6911</span>,  <span class="number">0.5680</span>],</span><br><span class="line">        [ <span class="number">2.0811</span>,  <span class="number">0.4253</span>, -<span class="number">0.9852</span>,  <span class="number">0.8593</span>],</span><br><span class="line">        [-<span class="number">0.5978</span>,  <span class="number">0.7914</span>, -<span class="number">0.7826</span>,  <span class="number">0.4671</span>]])</span><br><span class="line">tensor([[ <span class="number">3.2000</span>,  <span class="number">0.1413</span>, -<span class="number">1.7111</span>,  <span class="number">0.4544</span>],</span><br><span class="line">        [ <span class="number">1.2901</span>,  <span class="number">0.6219</span>, -<span class="number">0.3954</span>,  <span class="number">1.1845</span>]])</span><br><span class="line">tensor([[ <span class="number">3.2000</span>,  <span class="number">0.1413</span>, -<span class="number">1.7111</span>,  <span class="number">0.4544</span>],</span><br><span class="line">        [ <span class="number">1.2901</span>,  <span class="number">0.6219</span>, -<span class="number">0.3954</span>,  <span class="number">1.1845</span>]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="3-torch-bmm-x-y"><a href="#3-torch-bmm-x-y" class="headerlink" title="3 torch.bmm(x, y)"></a>3 torch.bmm(x, y)</h2><ul>
<li>执行一个batch的矩阵乘法 <strong>x 和 y 必须是3-D张量 且是x = (b, n, m) y = (b, n, p)</strong> <strong>不支持广播</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">y = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">z = torch.bmm(x, y) <span class="comment"># [2, 2, 4]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(x, y, z))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[ <span class="number">0.4304</span>,  <span class="number">0.9056</span>,  <span class="number">0.4578</span>],</span><br><span class="line">         [-<span class="number">3.1024</span>,  <span class="number">0.1185</span>,  <span class="number">0.8143</span>]],</span><br><span class="line"></span><br><span class="line">        [[-<span class="number">0.1249</span>, -<span class="number">0.7876</span>, -<span class="number">0.0426</span>],</span><br><span class="line">         [-<span class="number">1.5175</span>, -<span class="number">1.0602</span>,  <span class="number">2.4620</span>]]])</span><br><span class="line">tensor([[[-<span class="number">0.2403</span>, -<span class="number">0.5954</span>,  <span class="number">1.2178</span>, -<span class="number">1.3661</span>],</span><br><span class="line">         [ <span class="number">0.7626</span>, -<span class="number">0.0728</span>,  <span class="number">0.2353</span>,  <span class="number">0.0733</span>],</span><br><span class="line">         [-<span class="number">0.1070</span>, -<span class="number">0.3414</span>, -<span class="number">0.2480</span>, -<span class="number">1.0626</span>]],</span><br><span class="line"></span><br><span class="line">        [[-<span class="number">0.5171</span>, -<span class="number">0.6608</span>,  <span class="number">1.3164</span>, -<span class="number">1.2351</span>],</span><br><span class="line">         [ <span class="number">1.9305</span>,  <span class="number">0.1607</span>,  <span class="number">0.8634</span>, -<span class="number">0.6855</span>],</span><br><span class="line">         [-<span class="number">0.3664</span>,  <span class="number">0.3081</span>,  <span class="number">1.1023</span>, -<span class="number">1.6237</span>]]])</span><br><span class="line">tensor([[[ <span class="number">0.5383</span>, -<span class="number">0.4785</span>,  <span class="number">0.6237</span>, -<span class="number">1.0081</span>],</span><br><span class="line">         [ <span class="number">0.7487</span>,  <span class="number">1.5606</span>, -<span class="number">3.9523</span>,  <span class="number">3.3816</span>]],</span><br><span class="line"></span><br><span class="line">        [[-<span class="number">1.4404</span>, -<span class="number">0.0572</span>, -<span class="number">0.8915</span>,  <span class="number">0.7634</span>],</span><br><span class="line">         [-<span class="number">2.1641</span>,  <span class="number">1.5909</span>, -<span class="number">0.1993</span>, -<span class="number">1.3964</span>]]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="4-torch-dot-x-y-gt-tensor-scalar"><a href="#4-torch-dot-x-y-gt-tensor-scalar" class="headerlink" title="4 torch.dot(x, y) -&gt; tensor (scalar)"></a>4 torch.dot(x, y) -&gt; tensor (scalar)</h1><ul>
<li><strong>两个元素个数相同的一维张量</strong>点积运算 <strong>和numpy的dot不同，torch.dot(x, y)仅支持两个一维张量</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">y = torch.tensor([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">z = torch.dot(x, y) <span class="comment"># 1*4 + 2*5 + 3*6 = 32</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(x, y, z))</span><br><span class="line"></span><br><span class="line"><span class="comment"># error</span></span><br><span class="line"><span class="comment"># y = torch.tensor([[1, 2, 3], [1, 2, 3], [1, 2, 3]])</span></span><br><span class="line"><span class="comment"># z = torch.dot(x, y)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">tensor([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"><span class="number">32</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="5-torch-mv-x-y-gt-Tensor"><a href="#5-torch-mv-x-y-gt-Tensor" class="headerlink" title="5 torch.mv(x, y) -&gt; Tensor"></a>5 torch.mv(x, y) -&gt; Tensor</h1><ul>
<li><strong>matrix-vector and x = (n, m) y = (m, ) -&gt; return = (n, )</strong> 不支持广播<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">y = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">z = torch.mv(x, y) <span class="comment"># [1*1 + 2*2 + 3*3, 4*1 + 5*2 + 6*3]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(x, y, z))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ERROR</span></span><br><span class="line"><span class="comment"># z = torch.mv(y, x)</span></span><br><span class="line"><span class="comment"># print(&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;.format(x, y, z))</span></span><br><span class="line"><span class="comment"># y = torch.tensor([1, 2])</span></span><br><span class="line"><span class="comment"># z = torch.mv(y, x)</span></span><br><span class="line"><span class="comment"># print(&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;.format(x, y, z))</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">tensor([<span class="number">14</span>, <span class="number">32</span>])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="6-torch-matmul-x-y-gt-tensor"><a href="#6-torch-matmul-x-y-gt-tensor" class="headerlink" title="6 torch.matmul(x, y) -&gt; tensor"></a>6 torch.matmul(x, y) -&gt; tensor</h1><ul>
<li>比较全能的一种乘法 <strong>支持广播</strong> 支持任何维度可相乘的tensor相乘<br><img src="/2024/03/01/pytorch%E4%B8%AD%E5%85%B3%E4%BA%8E%E7%9F%A9%E9%98%B5%E7%9A%84%E4%B9%98%E6%B3%95%E6%80%BB%E7%BB%93/1709381483833.png" alt="1709381483833"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">y = torch.randn(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">z = torch.matmul(x, y) <span class="comment"># [2, 2, 2, 2]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(x, y, z))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[[-<span class="number">0.9772</span>, -<span class="number">0.0628</span>, -<span class="number">0.5369</span>],</span><br><span class="line">          [-<span class="number">0.3113</span>,  <span class="number">1.7524</span>,  <span class="number">0.7249</span>]],</span><br><span class="line"></span><br><span class="line">         [[-<span class="number">1.1878</span>,  <span class="number">0.0895</span>,  <span class="number">0.7625</span>],</span><br><span class="line">          [ <span class="number">0.2828</span>,  <span class="number">0.1154</span>, -<span class="number">0.8482</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ <span class="number">0.8277</span>,  <span class="number">0.4449</span>,  <span class="number">0.0741</span>],</span><br><span class="line">          [ <span class="number">0.9390</span>, -<span class="number">0.6762</span>,  <span class="number">0.4093</span>]],</span><br><span class="line"></span><br><span class="line">         [[-<span class="number">0.2564</span>,  <span class="number">0.8857</span>, -<span class="number">0.1946</span>],</span><br><span class="line">          [-<span class="number">0.9418</span>,  <span class="number">0.0510</span>, -<span class="number">0.2456</span>]]]])</span><br><span class="line">tensor([[[[-<span class="number">0.0997</span>,  <span class="number">0.2760</span>],</span><br><span class="line">          [-<span class="number">0.7134</span>, -<span class="number">0.4839</span>],</span><br><span class="line">          [-<span class="number">1.3931</span>,  <span class="number">0.2729</span>]],</span><br><span class="line"></span><br><span class="line">         [[-<span class="number">0.4765</span>,  <span class="number">0.5714</span>],</span><br><span class="line">          [ <span class="number">1.4368</span>,  <span class="number">1.2979</span>],</span><br><span class="line">          [ <span class="number">1.0061</span>,  <span class="number">0.2874</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[-<span class="number">0.0596</span>,  <span class="number">0.5366</span>],</span><br><span class="line">          [ <span class="number">0.2938</span>, -<span class="number">0.6728</span>],</span><br><span class="line">          [-<span class="number">0.0664</span>, -<span class="number">1.8749</span>]],</span><br><span class="line"></span><br><span class="line">         [[ <span class="number">0.1983</span>, -<span class="number">0.2220</span>],</span><br><span class="line">          [-<span class="number">1.4755</span>, -<span class="number">2.2627</span>],</span><br><span class="line">          [-<span class="number">0.4390</span>,  <span class="number">0.4608</span>]]]])</span><br><span class="line">tensor([[[[ <span class="number">0.8902</span>, -<span class="number">0.3858</span>],</span><br><span class="line">          [-<span class="number">2.2289</span>, -<span class="number">0.7362</span>]],</span><br><span class="line"></span><br><span class="line">         [[ <span class="number">1.4617</span>, -<span class="number">0.3435</span>],</span><br><span class="line">          [-<span class="number">0.8224</span>,  <span class="number">0.0675</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ <span class="number">0.0764</span>,  <span class="number">0.0058</span>],</span><br><span class="line">          [-<span class="number">0.2818</span>,  <span class="number">0.1914</span>]],</span><br><span class="line"></span><br><span class="line">         [[-<span class="number">1.2722</span>, -<span class="number">2.0368</span>],</span><br><span class="line">          [-<span class="number">0.1542</span>, -<span class="number">0.0195</span>]]]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="7-torch-einsum-gt-爱因斯坦求和约定"><a href="#7-torch-einsum-gt-爱因斯坦求和约定" class="headerlink" title="7 torch.einsum() -&gt; 爱因斯坦求和约定"></a>7 torch.einsum() -&gt; 爱因斯坦求和约定</h1><ul>
<li><em>功能十分强大，支持求和运算, 各种乘法运算, transpose运算等等</em><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># trace</span></span><br><span class="line">torch.einsum(<span class="string">&#x27;ii&#x27;</span>, torch.randn(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># diagonal</span></span><br><span class="line">torch.einsum(<span class="string">&#x27;ii-&gt;i&#x27;</span>, torch.randn(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># outer product</span></span><br><span class="line">x = torch.randn(<span class="number">5</span>)</span><br><span class="line">y = torch.randn(<span class="number">4</span>)</span><br><span class="line">torch.einsum(<span class="string">&#x27;i,j-&gt;ij&#x27;</span>, x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># batch matrix multiplication</span></span><br><span class="line">As = torch.randn(<span class="number">3</span>, <span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line">Bs = torch.randn(<span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>)</span><br><span class="line">torch.einsum(<span class="string">&#x27;bij,bjk-&gt;bik&#x27;</span>, As, Bs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># with sublist format and ellipsis</span></span><br><span class="line">torch.einsum(As, [..., <span class="number">0</span>, <span class="number">1</span>], Bs, [..., <span class="number">1</span>, <span class="number">2</span>], [..., <span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># batch permute</span></span><br><span class="line">A = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">torch.einsum(<span class="string">&#x27;...ij-&gt;...ji&#x27;</span>, A).shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># equivalent to torch.nn.functional.bilinear</span></span><br><span class="line">A = torch.randn(<span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>)</span><br><span class="line">l = torch.randn(<span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line">r = torch.randn(<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">torch.einsum(<span class="string">&#x27;bn,anm,bm-&gt;ba&#x27;</span>, l, A, r)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="8-总结"><a href="#8-总结" class="headerlink" title="8 总结"></a>8 总结</h1><p>一般在神经网络中常用的就是 1. torch.dot(x, y) 求两个向量的点积 2. torch.bmm(x, y) 求一个batch的矩阵数据相乘 (<strong>必须是三维[b, n, m] × [b, m, q]</strong>) 3. torch.matmul(x, y)<strong>求维度超过三维或者需要广播的矩阵乘法</strong></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/02/26/RACE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/02/26/RACE/" class="post-title-link" itemprop="url">RACE</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-02-26 20:57:10" itemprop="dateCreated datePublished" datetime="2024-02-26T20:57:10+08:00">2024-02-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-29 12:06:50" itemprop="dateModified" datetime="2024-02-29T12:06:50+08:00">2024-02-29</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>3 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="RACE-Improve-Multi-Agent-Reinforcement-Learning-with-Representation-Asymmetry-and-Collaborative-Evolution"><a href="#RACE-Improve-Multi-Agent-Reinforcement-Learning-with-Representation-Asymmetry-and-Collaborative-Evolution" class="headerlink" title="RACE: Improve Multi-Agent Reinforcement Learning with Representation Asymmetry and Collaborative Evolution"></a>RACE: Improve Multi-Agent Reinforcement Learning with Representation Asymmetry and Collaborative Evolution</h1><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li><strong>challenge</strong>: MARL 在合作方面 挣扎在低质量的奖励信号和高不稳定性</li>
<li><strong>Evolutionary Algorithm(EA)</strong>: 更好的收敛、更加健壮鲁棒、对奖励信号不敏感</li>
<li><strong>in this paper</strong>: 本文提出一个混合框架： Representation Asymmetry and Collaboration Evolution (RACE) -&gt; 将EA和MARL结合 以达到高效的合作</li>
<li><strong>method</strong>: RACE 维持一个MARL team和一群EA teams. 为了高效的知识共享和策略探索 -&gt; RACE 把不同team控制相同agent的 policies 分解成 1. shared nonlinear observation representation encoder（共享的非线性观察表示编码器encoder） 2. individual linear policy representations.（独立的线性策略表示） trick1: 为了解决部分观察的问题, 本文引入Value-Aware Mutual Information Maximization （价值感知 互信息最大化）-&gt; 利用有关全局状态的有用信息增强共享表示    trick2: 为了促进协调 -&gt; 使用新颖的 agent-level 交叉和变异算子来进化种群 -&gt; 为MARL提供多样化的经验  trick3: MARL优化它的策略并且将它们注入到种群中进化</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul>
<li><strong>motivation</strong>: EA has strong exploration ability, good robustness, and stable convergence. EA offers numerous strengths that can complement the weaknesses of MARL.</li>
<li><strong>challenge</strong>: 独立维持和优化每个team的policy是非常不高效的 并且这样无法利用其他team获得的有价值的知识 在广阔的非线性策略空间探索合作是非常低效的</li>
<li><strong>methods</strong>: 提出两级团队策略测结构 1. 共享的非线性观察表示(shared observation represention encoder) 2. 独立的线性策略表示(independent policy representions)</li>
<li><strong>represention asymmetry</strong>: independent policy构建的不同表示范围</li>
<li><strong>observation representation encoder</strong>: 负责共享任务相关和合作相关的知识 -&gt; 通过价值函数最大化的集成（涉及所有的EA team 和 MARL team）更新方向进行优化</li>
<li><strong>Value-Aware Mutual Information Maximization</strong>: 最大化共享观察表示(shared observation representations) 和全局状态的互信息(MI)。 -&gt; 在低价值状态下进行最大化可能导致对共享观察表示(shared observation representation)的负面影响 -&gt; 导致合作不理想 -&gt; Value-Aware MI: 归一化状态价值函数作为权重 已到达 提取全局状态信息加入共享观察表示(shared observation representations)</li>
<li><strong>independent linear policy</strong>: 在更加紧凑和有利的线性空间 policy的探索更加有效 从而促进合作</li>
<li><strong>EA</strong>: EA进化种群 生成多样性的经验 -&gt; 被MARL使用 -&gt; 反过来，MARL team通过收集的样本进行优化 并且定期加入种群进化</li>
<li>agent-level 交叉变异 -&gt; 交换两个team的individual policy representation -&gt; 探索更好的团队合作</li>
</ul>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><ol>
<li>Representation Asymmetry of team construction</li>
<li>How to learn the shared observation representation encoders</li>
<li>How to improve MARL with Collaborative Evolution</li>
</ol>
<ul>
<li><strong>motivation</strong>: 每个team 独立的策略构建限制了teams之间的知识共享和在策略空间上的探索 -&gt; inspired by ERL-Re -&gt; 本文提出Representation-Asymmetry Team Construction(RATC) 使能够高效的知识共享和策略探索</li>
</ul>
<h3 id="Shared-Observation-Representation-Learning"><a href="#Shared-Observation-Representation-Learning" class="headerlink" title="Shared Observation Representation Learning"></a>Shared Observation Representation Learning</h3>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/02/26/NA2Q/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/02/26/NA2Q/" class="post-title-link" itemprop="url">NA2Q</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-02-26 19:21:14 / 修改时间：19:57:30" itemprop="dateCreated datePublished" datetime="2024-02-26T19:21:14+08:00">2024-02-26</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>518</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="NA2Q-Neural-Attention-Additive-Model-for-Interpretable-Multi-Agent-Q-Learning"><a href="#NA2Q-Neural-Attention-Additive-Model-for-Interpretable-Multi-Agent-Q-Learning" class="headerlink" title="NA2Q: Neural Attention Additive Model for Interpretable Multi-Agent Q-Learning"></a>NA2Q: Neural Attention Additive Model for Interpretable Multi-Agent Q-Learning</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li><strong>challenge</strong>: 价值分解方法中不明了的信用分配机制 由于黑盒的network导致不能完全解释</li>
<li><strong>methods</strong>: 通过广义加性模型(GAM)系列研究可解释性的价值分解框架 Neural Attention Additive Q-learning (NA2Q) -&gt; 提供合作行为的内在理解</li>
<li><strong>identity semantic</strong>：构建身份语义消除信用模糊问题 -&gt; 局部语义掩码帮助诊断每个agent捕获相关任务信息</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li><strong>existing methods</strong>: 1. 基于特定实例近似的方法 旨在 通过Shapley value解释黑盒预测 或者是 使用聚类的技术在事后分析 -&gt; 这种方法很耗费计算资源并且不稳定 -&gt; 它们通常误解model or agent的决策  \ 2. 为了蒸馏智能体的决策，本文借助于模仿学习生成时候的全局解释 -&gt; 缺乏原始模型的透明度 并且 无法保证在复杂任务上的性能</li>
<li><strong>motivation</strong>: 从外部（事后）解释的碰壁导致点燃了对内在解释的研究兴趣， 尤其是在广义加性模型(GAM)</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/02/24/Consensus-Learning-for-Cooperative-Multi-Agent-Reinforcement-Learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/02/24/Consensus-Learning-for-Cooperative-Multi-Agent-Reinforcement-Learning/" class="post-title-link" itemprop="url">Consensus Learning for Cooperative Multi-Agent Reinforcement Learning</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-02-24 20:25:35" itemprop="dateCreated datePublished" datetime="2024-02-24T20:25:35+08:00">2024-02-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-29 17:17:14" itemprop="dateModified" datetime="2024-02-29T17:17:14+08:00">2024-02-29</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Consensus-Learning-for-Cooperative-Multi-Agent-Reinforcement-Learning"><a href="#Consensus-Learning-for-Cooperative-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Consensus Learning for Cooperative Multi-Agent Reinforcement Learning"></a>Consensus Learning for Cooperative Multi-Agent Reinforcement Learning</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li><strong>shortcoming</strong>: agent 缺乏共享信号 在执行动作时仅考虑了局部的观察</li>
<li><strong>inspired by</strong>: viewpoint invariance（试图不变性） + contrastive learning</li>
<li><strong>consensus learning</strong>: <strong>尽管基于局部观察，不同agents在没有交流的分散空间中可以推断出相同的consensus（共识）</strong></li>
<li><strong>Method</strong>: 将推断出的one-hot consensus 输入到agent network中 -&gt; 培养agent之间的合作精神</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li><strong>motivation</strong>: 尽管每个智能体的局部观察是独特的, 但是不同智能体对应的是相同的全局状体的不同表示 -&gt; 就像一个多视角问题 -&gt; 如果智能体可以意识到这个不变性，智能体就可以在执行时通过推断的共同意识来进行合作</li>
</ul>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">the observations of all agents at the same moment are different representations of the same global state,</span><br><span class="line"></span><br><span class="line">as shown in Figure 1. It is like a multi-view problem (Xu, Tao, and Xu 2013),</span><br><span class="line"></span><br><span class="line">where the same object can look different from various viewpoints.</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">If the agents are aware of the invariance, they can explicitly select</span><br><span class="line"></span><br><span class="line">cooperative actions by inferring the same consensus on the state from their</span><br><span class="line"></span><br><span class="line">different local observations during the decentralized execution.</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/2024/02/24/Consensus-Learning-for-Cooperative-Multi-Agent-Reinforcement-Learning/1708834968206.png" alt="1708834968206"></p>
<ul>
<li><p><strong>consensus</strong>: 怎么定义consensus -&gt; 最简单的方法就是把real global state作为consensus， 但是local observation infer global state 很难实现 -&gt; 采用对比学习</p>
</li>
<li><p><strong>COLA (COnsensus LeArning)</strong>: 利用对比学习通过不变性的形式将局部观察编码到离散的潜空间中 即使在同一时刻不同智能体之间的local observation非常不相似，在训练consensus representation model时依然会把他们作为相似的对待 -&gt; 这样可以让COLA中的agent收到完全不同的局部观察时，agent在执行时依然可以推断出相同的离散状态潜在变量</p>
</li>
</ul>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">COLA utilizes contrastive learning to encode local observations into discrete latent spaces through the form of invariances.</span><br><span class="line"></span><br><span class="line">Even though the local observations between agents at the same moment may be quite dissimilar,</span><br><span class="line"></span><br><span class="line">we still treat them as similar when training the consensus representation model.</span><br><span class="line"></span><br><span class="line">Thus, even if agents in COLA receive entirely different local observations,</span><br><span class="line"></span><br><span class="line">they can still infer the same discrete state latent variables during execution.</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>Intuitive interpretation</strong>: COLA 赋能 agent学习到人类社会中的“默契” 智能体之间没有实质的交流 但是依然能达到一个处于相同state的共识</li>
</ul>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Contrastive-Learning"><a href="#Contrastive-Learning" class="headerlink" title="Contrastive Learning"></a>Contrastive Learning</h3><ul>
<li><p>Constrastive Learning</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A dataset in contrastive learning tasks is typically organized by similar and dissimilar pairs. Then contrastive learning methods are trained by reducing the distance between augmented views of the same sample and increasing it between different ones (Wang and Isola 2020). In this way, contrastive learning enables the representation model to learn the general knowledge contained in the dataset.</span><br></pre></td></tr></table></figure>
<p><strong>负样本的选择对对比学习的性能影响很大</strong>  -&gt; 因此通常由人工来选择负样本 这样就限制了对比学习的开发 -&gt; <strong>new work： 通过类似聚类的技术 取消显示加入负样本</strong> 但是依然可以得到不错的性能 并且避免了塌陷(collapse)</p>
</li>
<li><p>Contrastive Learning in Reinforcement Learning: 通过比较不同时间的状态， <strong>对比学习可以将复杂的状态映射到低维的潜在空间 进而去除和学习无关的信息</strong></p>
</li>
</ul>
<h3 id="Knowledge-Distillation-with-No-Labels"><a href="#Knowledge-Distillation-with-No-Labels" class="headerlink" title="Knowledge Distillation with No Labels"></a>Knowledge Distillation with No Labels</h3><ul>
<li><strong>self-train and knowledge distillation</strong>:<ol>
<li>利用已标记的数据训练一个教师模型</li>
<li>教师模型对未标记的数据生成伪标签（软标签）</li>
<li>将生成为标签的数据与原始数据相结合 训练学生模型</li>
</ol>
</li>
<li><strong>self-DIstillation with NO labels</strong>:  <ol>
<li>完全没有带标签的数据 不存在预训练好的教师模型</li>
<li>教师模型和学生模型的结构完全一样</li>
<li>教师模型的参数是随机初始化的， 使用EMA的方式从学生模型上更新参数 </li>
</ol>
</li>
<li><strong>Emerging Properties in Self-Supervised Vision Transformers</strong>: 发表在ICCV-2021上提出DINO模型  及  伪代码</li>
</ul>
<p><img src="/2024/02/24/Consensus-Learning-for-Cooperative-Multi-Agent-Reinforcement-Learning/1709194106907.png" alt="1709194106907"><br><img src="/2024/02/24/Consensus-Learning-for-Cooperative-Multi-Agent-Reinforcement-Learning/1709194151157.png" alt="1709194151157"></p>
<ul>
<li><strong>consensus builder 模型结构：</strong><br><img src="/2024/02/24/Consensus-Learning-for-Cooperative-Multi-Agent-Reinforcement-Learning/image.png" alt="alt text"></li>
<li><strong>loss损失函数：</strong> K 是共识类别的数量<br><img src="/2024/02/24/Consensus-Learning-for-Cooperative-Multi-Agent-Reinforcement-Learning/1709194310765.png" alt="1709194310765"></li>
</ul>
<h3 id="COLA-Architecture"><a href="#COLA-Architecture" class="headerlink" title="COLA Architecture"></a>COLA Architecture</h3><ul>
<li><strong>We concatenate local observations with the one-hot consensus and feed them into the network.</strong></li>
<li><strong>loss:</strong> $L_{RL} = (y_{tot} - Q_{tot}(\tau , c, u))$<br><img src="/2024/02/24/Consensus-Learning-for-Cooperative-Multi-Agent-Reinforcement-Learning/1709194473121.png" alt="1709194473121"></li>
</ul>
<h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><h3 id="Performance-Comparison"><a href="#Performance-Comparison" class="headerlink" title="Performance Comparison"></a>Performance Comparison</h3><p><img src="/2024/02/24/Consensus-Learning-for-Cooperative-Multi-Agent-Reinforcement-Learning/1709194546681.png" alt="1709194546681"><br><img src="/2024/02/24/Consensus-Learning-for-Cooperative-Multi-Agent-Reinforcement-Learning/1709194567201.png" alt="1709194567201"></p>
<h3 id="Case-Study-and-Visualization"><a href="#Case-Study-and-Visualization" class="headerlink" title="Case Study and Visualization"></a>Case Study and Visualization</h3><ul>
<li>模型参数分析：<br><img src="/2024/02/24/Consensus-Learning-for-Cooperative-Multi-Agent-Reinforcement-Learning/1709194594721.png" alt="1709194594721"></li>
<li><p><strong>Result of Consensus Learning</strong>: </p>
<ol>
<li>in the 2D t-SNE embedding of states, the states with the same consensus generated by the agent tend to cluster together.</li>
<li>states with the same consensus often have similar estimated values or true returns.<br><img src="/2024/02/24/Consensus-Learning-for-Cooperative-Multi-Agent-Reinforcement-Learning/1709194625724.png" alt="1709194625724"><h3 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h3></li>
</ol>
</li>
<li><p>How does the hyperparameter K affect the performance of COLA?<br><img src="/2024/02/24/Consensus-Learning-for-Cooperative-Multi-Agent-Reinforcement-Learning/1709194655396.png" alt="1709194655396"></p>
</li>
<li><strong>conclusion</strong>: we conclude that the choice of K depends on the difficulty of the task. We should pick a higher K value when the reinforcement learning task is complex and vice versa.</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/02/23/Contrastive-Identity-Aware-Learning-for-Multi-Agent-Value-Decomposition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/02/23/Contrastive-Identity-Aware-Learning-for-Multi-Agent-Value-Decomposition/" class="post-title-link" itemprop="url">Contrastive Identity-Aware Learning for Multi-Agent Value Decomposition</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-02-23 10:34:54" itemprop="dateCreated datePublished" datetime="2024-02-23T10:34:54+08:00">2024-02-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-29 17:02:34" itemprop="dateModified" datetime="2024-02-29T17:02:34+08:00">2024-02-29</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>5.3k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>9 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Contrastive-Identity-Aware-Learning-for-Multi-Agent-Value-Decomposition-AAAI-23-Zhejiang-University-MARL-Contrastive-Learning"><a href="#Contrastive-Identity-Aware-Learning-for-Multi-Agent-Value-Decomposition-AAAI-23-Zhejiang-University-MARL-Contrastive-Learning" class="headerlink" title="Contrastive Identity-Aware Learning for Multi-Agent Value Decomposition /AAAI-23/Zhejiang University/MARL + Contrastive Learning"></a>Contrastive Identity-Aware Learning for Multi-Agent Value Decomposition /AAAI-23/Zhejiang University/MARL + Contrastive Learning</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li><strong>Challenges:</strong> 挑战在于促进多智能体之间的多样性行为</li>
<li><strong>Existing Methodes</strong>: 现有方法直接鼓励通过各种策略学习多样的agent network</li>
<li><strong>Shortcoming</strong>: 专门设计agent network的方法受到无法区分的indistinguishable VD network限制 -&gt; 导致智能体行为<strong>同质化</strong>，进而降低合作能力<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">One of the main challenges in VD is to promote diverse behaviors among agents, </span><br><span class="line">while existing methods directly encourage the diversity oflearned agent networks with various strategies. </span><br><span class="line">However, we argue that these dedicated designs for agent networks are still limited by the indistinguishable VD network, </span><br><span class="line">leading to homogeneous agent behaviors and thus downgrading the cooperation capability.</span><br></pre></td></tr></table></figure></li>
<li><strong>In this paper</strong>: Contrastive Identity-Aware learning (CIA) method(对比身份意识学习) -&gt; 提高VD network信用等级区分能力 -&gt; 多智能体行文更加多样性</li>
<li><strong>CIA</strong>: 利用对比学习最大化不同智能体的<strong>时间信用和身份表征</strong>之间的互信息 -&gt; 信用分配的充分表现和进一步突显个性<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">In this paper, we propose a novel Contrastive Identity-Aware learning (CIA) method, </span><br><span class="line">explicitly boosting the credit-level distinguishability of the VD network to break the bottleneck of multi-agent diversity.</span><br><span class="line">Specifically, our approach leverages contrastive learning to maximize the mutual information </span><br><span class="line">between the temporal credits and identity representations of different agents, </span><br><span class="line">encouraging the full expressiveness of credit assignment and further the emergence of individualities.</span><br></pre></td></tr></table></figure></li>
<li><strong>Experiment</strong>:  CIA 模块的算法实现简单而有效，可以轻松合并到各种 VD 架构中</li>
<li><strong>Code</strong>: <a target="_blank" rel="noopener" href="https://github.com/liushunyu/CIA">https://github.com/liushunyu/CIA</a></li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li><strong>Existing Methods</strong>: 1. <strong>归因agent之间的相似性</strong> 通过参数共享来同质化policy network / 2. 设计<strong>辅助的目标(+ loss)</strong>在policy network上解决<strong>agent-level</strong>的多样性 / 3. 为<strong>每个agent引入特定的networks</strong> 不惜牺牲完全参数共享的优势</li>
<li><strong>Motivation</strong>: 现有的方法都忽略了agents 的 policy networks 都是通过VD network来评估和改进的这一事实 -&gt; agents 行为的多样性实际上是依赖于信用分配的区分性 -&gt; 本文认为追逐agents policies的多样性依然受限到VD network 提供模糊的信用分配来证明不同agent的贡献<br><img src="/2024/02/23/Contrastive-Identity-Aware-Learning-for-Multi-Agent-Value-Decomposition/1708666648057.png" alt="1708666648057"></li>
<li><strong>In this paper</strong>: 本文从信用分配的新颖角度研究multi-agent的多样性 提出contrastive identity-aware learning method, termed as CIA -&gt; 鼓励credit-level 区分性</li>
<li><strong>Method</strong>:<ol>
<li><strong>利用基于梯度的归因来表示每个智能体的信用</strong>， 并且采用完整轨迹的时序信用来进一步考虑智能体的长期行为</li>
<li>最大化互不同智能体的时序信用和可学习身份表征之间的互信息</li>
<li>本文定制一个对比学习目标来导出互信息的易于处理的下界，因为估计和最大化神经网络的互信息通常很棘手</li>
</ol>
</li>
</ul>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><h3 id="Credit-Indistinguishability-Analysis"><a href="#Credit-Indistinguishability-Analysis" class="headerlink" title="Credit Indistinguishability Analysis"></a>Credit Indistinguishability Analysis</h3><ul>
<li>信用分配模糊：如果可学习的信用对于agent身份来说是不变的说明信用分配是模糊的</li>
<li>方法：QMIX(RS)在每个训练epoch，随机打乱输入到min network的values的顺序 / 计算训练后的网络采样的轨迹的<strong>KL散度距离表示信用分布的相似性</strong></li>
<li>结论：QMIX(RS)和original QMIX的性能一样，且两者的KL散度距离很小， 但是QMIX(CIA)的性能优于QMIX，且两者KL散度较大 -&gt; 说明CIA改善了QMIX的信用分配模糊问题<br><img src="/2024/02/23/Contrastive-Identity-Aware-Learning-for-Multi-Agent-Value-Decomposition/1708688325540.png" alt="1708688325540"><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Interestingly, even with the ambiguous credit assignment, the random-shuffle variant can </span><br><span class="line">still achieve the performance on par with those obtained by original QMIX. </span><br><span class="line">The KL-divergence distance also shows that the credit distribution of QMIX </span><br><span class="line">is similar as its random-shuffle variant, indicating that QMIX are insensitive to the identity of agents.</span><br><span class="line">Thus, its learned credits may be ambiguous, which limits the diverse behaviors of agents and damages the final performance.</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="Contrastive-Identity-Aware-Learning"><a href="#Contrastive-Identity-Aware-Learning" class="headerlink" title="Contrastive Identity-Aware Learning"></a>Contrastive Identity-Aware Learning</h3><ol>
<li><p>Temporal Credit Attribution</p>
<ul>
<li>key issue: 如何定义一个通用的信用来表示单个智能体的贡献<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Before promoting the distinguishability of credits, one key issue to be considered is: </span><br><span class="line">how to define a universal credit to represent the contributions of individual agents in different VD methods.</span><br></pre></td></tr></table></figure></li>
<li>method: 使用 gradient-based attribution mechanism（基于梯度的归因机制） 提取信用分配信息<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Towards addressing this problem, we consider a gradient-based attribution mechanism </span><br><span class="line">to extract the credit assignment information in the mixing network.</span><br></pre></td></tr></table></figure></li>
<li>gradient-based attribution mechanism: 计算output对于input的偏导数 -&gt; 揭示输入对于输出的影响程度 -&gt; 使用joint-action value 和 individual value之间的偏导数表示信用 -&gt; 确定每个agent的贡献 $x_{t}^{k} = \partial Q_{t}^{tot}/ \partial Q_{t}^{k} \in R$<br><em>越大的归因值对应的agent对最终结果影响越大</em></li>
<li>在贯序决策中，推断一个agent的贡献仅靠单个时间步的行为是不够的 -&gt; 采用时序信用归因 整个轨迹trajectory $x_{\tau}^{k}=[x_{1}^{k},x_{2}^{k},…,x_{N}^{k}] \in R^{N}$<br>$X_{\tau} \in R^(K \times N)$<br><em>N 是所有采样的τ具有的最大长度， 如果某个τ提前终止 则用 0 填充</em></li>
<li>结论： $X_{\tau \in R^{K \times N}}$ 时序信用归因考虑了agent长期的行为 -&gt; 进而更加稳定的衡量了agent的贡献</li>
</ul>
</li>
<li><p>Contrastive Identity-Aware Distinguishability（对比身份意识可区分性）<br>temporal credit attribution解决了信用的表示，还要进一步区分credit -&gt; 但是很难直接限制不同可学习的credit之间的距离<br>-&gt; 本文提出近似方法： 提出潜在身份表示作为agent的中间变量，并且通过这些表示调控独自的时序信用 -&gt; 实现身份意识的区分性</p>
<ul>
<li>identity representation: 每个agent对应一个可学习的随机初始化的身份表示 $ w^{k} \in R^{N} $</li>
<li>最大化temporal credits 和 identity representation的互信息 -&gt; 最大化identity representation 和 temporal credit的关联程度 $I_{x;w} = E_{x, w}[log(P(x|w)/P(x))]$<br>然而优化 $I_{x,w}$ 十分困难，因为估算互信息是不可解的</li>
<li>对比学习：$ I(x;w) &gt;= log(K) - L_{CL} $<br><img src="/2024/02/23/Contrastive-Identity-Aware-Learning-for-Multi-Agent-Value-Decomposition/1708760818204.png" alt="1708760818204"><br>-&gt; $w_{k}$ 会和 $x_{k}$ 靠近，并且和其他 $x_{k-}$ 远离<br>公式中$g(x_{\tau}^{k}, w^{k}) $ 表示 $ x_{\tau}^{k} $ 和 $ w^{k} $ 相似性，本文中使用点积运算表示</li>
<li><p>结论：<strong>这种身份层面的对比学习loss 1. 限制了学习到的身份表示均分分布在一个特定的超球面 而不会发散 2. 并且对应的时序信用也会分布在对应的身份表示周围</strong><br>-&gt; agent credits的身份意识之间的区分性 提供更加有区分度的信用分配</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">As shown in Figure 3(d), this identitywise contrastive learning </span><br><span class="line">loss constrains the learned identity representations to uniformly</span><br><span class="line">distribute on a specific creditidentity hypersphere without divergence, </span><br><span class="line">where the temporal credits distribute around their corresponding</span><br><span class="line">identity representation (Wang and Isola 2020). With the contrastive learning loss, </span><br><span class="line">CIA directly encourages the identity-awaredistinguishability among agent credits, </span><br><span class="line">providing a more discriminative credit assignment for multi-agent diversity.</span><br></pre></td></tr></table></figure>
<p><img src="/2024/02/23/Contrastive-Identity-Aware-Learning-for-Multi-Agent-Value-Decomposition/1708762823185.png" alt="1708762823185"></p>
</li>
<li><p>从分类的角度解释： 可以看成一个分类问题，input是temporal credits 那么identity是分类网络的参数 想要最小化这个loss 要么样本空间十分简单，要么模型足够复杂，但是网络结构仅包含一层线性层nn.Linear(N, K)则施加了一个强约束了输入的credits是线性可分的 <strong>需要注意的是这里输入的样本temporal credits也是可以学的，通过反向传播更新MIX Network</strong> $L_{all} = L_{TD} + \alpha L_{CL}$<br>*$\alpha$是一个trade off</p>
</li>
</ul>
</li>
</ol>
<h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><h3 id="Didactic-Game"><a href="#Didactic-Game" class="headerlink" title="Didactic Game"></a>Didactic Game</h3><ul>
<li>为了研究信用分配问题本文设计了一个教学游戏：每个agent回合制轮流吃到各自颜色对应的苹果奖励+10 每回合另一个agent被栅栏限制住每移动一格奖励为-1<br><img src="/2024/02/23/Contrastive-Identity-Aware-Learning-for-Multi-Agent-Value-Decomposition/1709195829662.png" alt="1709195829662"></li>
<li><strong>从c图可以看出两个agent有明确的信用分配区分 两个agent的时序信用随着回合的交替而交替变化</strong></li>
</ul>
<h3 id="SMAC-Benchmark"><a href="#SMAC-Benchmark" class="headerlink" title="SMAC Benchmark"></a>SMAC Benchmark</h3><p><img src="/2024/02/23/Contrastive-Identity-Aware-Learning-for-Multi-Agent-Value-Decomposition/1709196026013.png" alt="1709196026013"></p>
<h3 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h3><ul>
<li><strong>为了验证身份意识的作用</strong> 本文额外设计了直接通过分类进行时序信用区分的算法</li>
<li><strong>credit classification loss(CC loss)</strong>: 给定时序信用，直接预测对应的身份标签</li>
<li>三种方法的性能对比:<br><img src="/2024/02/23/Contrastive-Identity-Aware-Learning-for-Multi-Agent-Value-Decomposition/1709196272260.png" alt="1709196272260"></li>
<li>从图中可以看出CC loss的方差很大 分析原因是：<br><strong>Identity represents可以限制temporal credits在一个特定的credit-identity的空间中 使temporal credits围绕在identity representation的周围 而不发散，但是CC loss可能导致同一个agent对应的temporal credits分布在远离决策边界的地方</strong></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/02/12/learning-pytorch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/02/12/learning-pytorch/" class="post-title-link" itemprop="url">learning pytorch</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-02-12 23:39:33" itemprop="dateCreated datePublished" datetime="2024-02-12T23:39:33+08:00">2024-02-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-29 11:51:51" itemprop="dateModified" datetime="2024-02-29T11:51:51+08:00">2024-02-29</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>7 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="learning-Pytorch"><a href="#learning-Pytorch" class="headerlink" title="learning Pytorch"></a>learning Pytorch</h1><h2 id="Pytorch-构建模型的三种方式"><a href="#Pytorch-构建模型的三种方式" class="headerlink" title="Pytorch 构建模型的三种方式"></a>Pytorch 构建模型的三种方式</h2><ol>
<li>继承nn.Sequential按照层的顺序构建模型：这种方式仅仅适用于简单的模型，<br>-&gt; 按层顺序构建模型无需定义forward方法<br>(1) add_module方法</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn </span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line">class Xnet():</span><br><span class="line">    def __init__(self, input_dim, hidden_dim, output_dim):</span><br><span class="line">        net = nn.Sequential()</span><br><span class="line">        net.add_module(&quot;linear1&quot;, nn.Linear(input_dim, hidden_dim))</span><br><span class="line">        net.add_module(&quot;relu1&quot;, nn.ReLU())</span><br><span class="line">        net.add_module(&quot;linear2&quot;, nn.Linear(hidden_dim, output_dim))</span><br><span class="line">        self.net = net</span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    model1 = Xnet(10, 128, 2)</span><br><span class="line">    print(model1.net)</span><br><span class="line"></span><br><span class="line">#Sequential(</span><br><span class="line">#  (linear1): Linear(in_features=10, out_features=128, bias=True)</span><br><span class="line">#  (relu1): ReLU()</span><br><span class="line">#  (linear2): Linear(in_features=128, out_features=2, bias=True)</span><br><span class="line">#)</span><br></pre></td></tr></table></figure>
<p>(2) 利用变长参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">net = nn.Sequential(</span><br><span class="line">    nn.Linear(input_dim, hidden_dim),</span><br><span class="line">    nn.Relu(),</span><br><span class="line">    nn.Linear(hidden_dim, output_dim),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>(3) 使用OrderedDict</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from collections import OrderedDict</span><br><span class="line">import torch </span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line">class XNet():</span><br><span class="line"></span><br><span class="line">    def __init__(self, input_dim, hidden_dim, output_dim):</span><br><span class="line">        net = nn.Sequential(OrderedDict([</span><br><span class="line">            (&#x27;linear1&#x27;, nn.Linear(input_dim, hidden_dim)),</span><br><span class="line">            (&#x27;Relu&#x27;, nn.ReLU()),</span><br><span class="line">            (&#x27;linear2&#x27;, nn.Linear(hidden_dim, output_dim)),</span><br><span class="line">        ]))</span><br><span class="line">        self.net = net</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    net = XNet(4, 128, 2)</span><br><span class="line">    print(net.net)</span><br></pre></td></tr></table></figure>
<ol>
<li>继承nn.Module基类构建自定义模型</li>
</ol>
<ul>
<li>模型的层在<strong>init</strong>函数中定义，然后再forward函数中定义正向传播的逻辑<br>-&gt; 需要forward方法</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn </span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line">class Xnet(nn.Module):</span><br><span class="line">    def __init__(self, input_dim, hidden_dim, output_dim):</span><br><span class="line">        super(Xnet, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(input_dim, hidden_dim)</span><br><span class="line">        self.fc2 = nn.Linear(hidden_dim, output_dim)</span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        return self.fc2(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    model1 = Xnet(10, 128, 2)</span><br><span class="line">    print(model1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Xnet(</span><br><span class="line">#   (fc1): Linear(in_features=10, out_features=128, bias=True)</span><br><span class="line">#   (fc2): Linear(in_features=128, out_features=2, bias=True)</span><br><span class="line"># )</span><br></pre></td></tr></table></figure>
<ol>
<li>继承nn.Module基类构建模型，并用模型容器进行封装<br>-&gt; 结合前两种方法<br>(1) nn.Sequential作为模型容器</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">class Net(nn.Module):</span><br><span class="line">    </span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels=3,out_channels=32,kernel_size = 3),</span><br><span class="line">            nn.MaxPool2d(kernel_size = 2,stride = 2),</span><br><span class="line">            nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 5),</span><br><span class="line">            nn.MaxPool2d(kernel_size = 2,stride = 2),</span><br><span class="line">            nn.Dropout2d(p = 0.1),</span><br><span class="line">            nn.AdaptiveMaxPool2d((1,1))</span><br><span class="line">        )</span><br><span class="line">        self.dense = nn.Sequential(</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(64,32),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(32,1),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line">    def forward(self,x):</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        y = self.dense(x)</span><br><span class="line">        return y </span><br><span class="line">    </span><br><span class="line">net = Net()</span><br><span class="line">print(net)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>这里Sequential模块内部的layer是在内部就实现了forward的，所以只需要在Sequential模块之间实现forward函数就行了</li>
</ul>
<p>(2) 使用nn.ModuleList作为模型容器</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">class Net(nn.Module):</span><br><span class="line">    </span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.layers = nn.ModuleList([</span><br><span class="line">            nn.Conv2d(in_channels=3,out_channels=32,kernel_size = 3),</span><br><span class="line">            nn.MaxPool2d(kernel_size = 2,stride = 2),</span><br><span class="line">            nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 5),</span><br><span class="line">            nn.MaxPool2d(kernel_size = 2,stride = 2),</span><br><span class="line">            nn.Dropout2d(p = 0.1),</span><br><span class="line">            nn.AdaptiveMaxPool2d((1,1)),</span><br><span class="line">            nn.Flatten(),</span><br><span class="line">            nn.Linear(64,32),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(32,1),</span><br><span class="line">            nn.Sigmoid()]</span><br><span class="line">        )</span><br><span class="line">    def forward(self,x):</span><br><span class="line">        for layer in self.layers:</span><br><span class="line">            x = layer(x)</span><br><span class="line">        return x</span><br><span class="line">net = Net()</span><br><span class="line">print(net)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>ModuleList有和List相似的方法：append(module), extend(module), insert(index, module)</li>
<li>ModuleList没有顺序（不用保证List中相邻Layer的维度匹配，所以需要自己定义forward函数</li>
</ul>
<p>(3) nn.ModuleDict作为模型容器<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">class Net(nn.Module):</span><br><span class="line">    </span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.layers_dict = nn.ModuleDict(</span><br><span class="line">        	  &#123;&quot;conv1&quot;:nn.Conv2d(in_channels=3,out_channels=32,kernel_size = 3),</span><br><span class="line">               &quot;pool&quot;: nn.MaxPool2d(kernel_size = 2,stride = 2),</span><br><span class="line">               &quot;conv2&quot;:nn.Conv2d(in_channels=32,out_channels=64,kernel_size = 5),</span><br><span class="line">               &quot;dropout&quot;: nn.Dropout2d(p = 0.1),</span><br><span class="line">               &quot;adaptive&quot;:nn.AdaptiveMaxPool2d((1,1)),</span><br><span class="line">               &quot;flatten&quot;: nn.Flatten(),</span><br><span class="line">               &quot;linear1&quot;: nn.Linear(64,32),</span><br><span class="line">               &quot;relu&quot;:nn.ReLU(),</span><br><span class="line">               &quot;linear2&quot;: nn.Linear(32,1),</span><br><span class="line">               &quot;sigmoid&quot;: nn.Sigmoid()</span><br><span class="line">              &#125;)</span><br><span class="line">    def forward(self,x):</span><br><span class="line">        layers = [&quot;conv1&quot;,&quot;pool&quot;,&quot;conv2&quot;,&quot;pool&quot;,&quot;dropout&quot;,&quot;adaptive&quot;,</span><br><span class="line">                  &quot;flatten&quot;,&quot;linear1&quot;,&quot;relu&quot;,&quot;linear2&quot;,&quot;sigmoid&quot;]</span><br><span class="line">        for layer in layers:</span><br><span class="line">            x = self.layers_dict[layer](x)</span><br><span class="line">        return x</span><br><span class="line">net = Net()</span><br><span class="line">print(net)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<ul>
<li>ModuleDict具有普通字典的属性：clear(), items(), keys(), pop(key), update(modules)</li>
<li>ModuleDict定义的layers也不包含顺序性，需要自己定义forward函数</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/01/27/MARL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/01/27/MARL/" class="post-title-link" itemprop="url">MARL</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-01-27 16:55:17" itemprop="dateCreated datePublished" datetime="2024-01-27T16:55:17+08:00">2024-01-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-02-11 00:34:56" itemprop="dateModified" datetime="2024-02-11T00:34:56+08:00">2024-02-11</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.9k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>5 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="MARL综述"><a href="#MARL综述" class="headerlink" title="MARL综述"></a>MARL综述</h1><h2 id="多智能体系统"><a href="#多智能体系统" class="headerlink" title="多智能体系统"></a>多智能体系统</h2><ul>
<li>多智能体系统：包含m个智能体，智能体共享环境，智能体之间会相互影响 -&gt; 智能体会影响环境，从而影响其他智能体</li>
<li>和单智能体系统的区别：单智能体的环境是稳态的，状态转移概率和奖励函数是不变的， 而多智能体系统中，智能体在与环境交互的同时也间接或直接的和其他智能体进行交互</li>
<li><p>多智能体强化学习的难点：</p>
<ol>
<li>因为环境是非稳态的，导致智能体在相同状态执行相同动作，得到的状态转移概率和奖励函数的分布不同</li>
<li>多智能体的训练是多目标的，不同智能体需要最大化自己的回报</li>
<li>训练评估复杂度提升</li>
</ol>
<p><img src="/2024/01/27/MARL/1706346629825.png" alt="1706346629825"></p>
</li>
<li><p>按照任务特性可以把多智能体系统划分为</p>
</li>
</ul>
<ol>
<li>完全协作：智能体拥有一个共同目标</li>
<li>完全竞争：智能体间的目标冲突，一方收益导致另一方损失</li>
<li>混合关系：组内合作，组间竞争，例如球类比赛</li>
</ol>
<h2 id="博弈论简介"><a href="#博弈论简介" class="headerlink" title="博弈论简介"></a>博弈论简介</h2><ul>
<li>将智能体之间的协作和竞争建模为博弈问题， 通常将问题建模为正则博弈</li>
<li><p>正则式博弈 -&gt; (N, A, Q)</p>
<ul>
<li>N -&gt; N表示有限智能体的集合：大小为n, 每个智能体用i {1, 2, 3,…,n} 索引表示</li>
<li>A -&gt; A表示动作组合空间： A = A1 × A2 × … × An（笛卡尔积） 其中Ai 表示智能体i可以做的动作 a = (a1, a2, … , an) 表示一个动作组合</li>
<li>Q -&gt; Q表示效益：Q = {Q1, Q2, … , Qn} Qi 表示智能体i的收益函数<br>注意：这里Qi可能不仅仅取决于ai, 它往往可能被其他的智能体动作影响，所以Qi取决于动作组合a</li>
</ul>
</li>
</ul>
<p>情景：仅有两个智能体，且是完全竞争<br>-&gt; 二人零和博弈：此时收益函数满足Q1(a) + Q2(a) = 0</p>
<h2 id="多智能体强化学习"><a href="#多智能体强化学习" class="headerlink" title="多智能体强化学习"></a>多智能体强化学习</h2><p>单智能体强化学习将多步决策建模为MDP，多智能体强化学习一般被建模为随机博弈</p>
<ul>
<li>随机博弈： -&gt; {N, S, A, P, R, γ}</li>
</ul>
<ul>
<li>N -&gt; N表示有限智能体的集合</li>
<li>S -&gt; S表示环境中所有智能体共享的状态空间</li>
<li>A -&gt; A表示联合动作空间： Ai表示智能体i的动作空间， A = A1 × A2 × … × An a = (a1, a2, … , an) 表示一个动作组合</li>
<li>P -&gt; P表示状态转移函数：S × A 映射了在每个时间步，给定一个动作组合a 属于 A, 环境从s 属于 S 转移到 s’ 属于 S 的概率</li>
<li>R -&gt; R表示每个智能体的奖励函数：S × A × N Ri表示智能体i对应的奖励函数</li>
<li>γ -&gt; γ表示折扣因子</li>
</ul>
<p><strong>过程</strong>：在每一个时间步，智能体i 处于 状态s , 选择动作ai 属于 Ai, 构成联合动作 a = {a1, a2, … , an}并执行，环境转移到下一个状态s’~P(·|s, a)， 智能体i得到奖励Ri(s, a)， 每个智能体通过优化自身的策略函数 πi : S -&gt; Δ(Ai)最大化以其期望累计奖赏，以状态价值函数的形式表达如下：<br><img src="/2024/01/27/MARL/1706412112570.png" alt="1706412112570"></p>
<ul>
<li>上述的符号 i 代表除了智能体 i 之外的其他智能体。与单智能体强化学习中智能体仅仅需要考虑自身对环境的影响不同，多智能体系统中智能体之间也会相互影响，他们共同决策并且同时更新策略。</li>
<li>当系统中的其他智能体的策略固定时，智能体 i 可以最大化自己的收益函数，以寻找到相对于其他智能体的策略的最优策略 π∗</li>
<li>合理性和收敛性是学习算法最主要的评价指标<ul>
<li><strong>合理性</strong>：在对手使用一个恒定策略的情况下，当前智能体能够学习并收敛到一个相对 于对手策略的最优策略。</li>
<li><strong>收敛性</strong>：在其他智能体也使用学习算法时，当前智能体能够学习并收敛到一个稳定的策略。通常情况下，<em>收敛性针对系统中的所有智能体使用相同的学习算法</em>。</li>
</ul>
</li>
</ul>
<p><img src="/2024/01/27/MARL/1706412808069.png" alt="1706412808069"></p>
<ul>
<li><p>部分可观测随机博弈：定义为 M = {N, S, A, P, R, γ, Ω, O}</p>
<ul>
<li>Ω -&gt; Ω表示所有智能体的联合观测空间 Ω = Ω1 × Ω2 × … × Ωn, Ωi 表示智能体i的观测空间</li>
<li>O -&gt; O表示观测函数：S -&gt; Δ(Ω) O(Ω|s),指在给定状态 s 后关于联合观测 Ω 的函数概率</li>
</ul>
</li>
<li><strong>在协作任务场景</strong>, 可以进一步建模为 -&gt; 分布式局部可观测马尔可夫决策过程（Decentralized Partially Observable MDP, Dec-POMDP），-&gt; 每个智能体的奖赏函数相同</li>
</ul>
<h2 id="多智能体强化学习训练范式"><a href="#多智能体强化学习训练范式" class="headerlink" title="多智能体强化学习训练范式"></a>多智能体强化学习训练范式</h2><ol>
<li>智能体更新自身策略是否需要其他智能体信息：<ul>
<li>集中式训练(Centralized Training)</li>
<li>分布式训练(Decentralized Training)</li>
</ul>
</li>
<li>智能体执行阶段是否需要外部信息：<ul>
<li>集中式执行(Centralized Execution)</li>
<li>分布式执行(Decentralized Execution)</li>
</ul>
</li>
</ol>
<ul>
<li><p>三种范式：</p>
<ul>
<li>DTDE 分布式训练分布式执行</li>
<li>CTCE 集中式训练集中式执行</li>
<li>CTDE 集中式训练分布式执行<br><img src="/2024/01/27/MARL/1706421213707.png" alt="1706421213707"></li>
</ul>
</li>
<li>分布式训练分布式执行 DTDE：每个智能体<strong>仅利用自己的局部信息独立地进行策略更新和策略实现</strong>，不涉及到信息的交换<br>πi: Ωi -&gt; ∆(Ai)<br>IQL: 是基于DTDE的典型算法</li>
<li>集中式训练集中式执行 CTCE：<strong>智能体学习一个集中式的联合策略</strong><br>π: Ω -&gt; ∆(A).<br><strong>在CTCE框架下，可以使用任意一种单智能体强化学习算法训练多智能体系统</strong><br>-&gt; 算法的复杂度随状态和动作的维度增长呈维度爆炸 -&gt; 可通过策略分解 或者 值分解 来解决<br>-&gt; 无法评估每个智能体间的相互影响 -&gt; 信度分配问题会给学习效率带来较严重的影响 -&gt; 未解决</li>
<li>集中式训练分布式执行 CTDE：<strong>在训练阶段，智能体通过拿到其他智能体的信息甚至是全局信息以优化自己的局部策略</strong> <strong>在执行过程仅使用自己的局部信息进行决策</strong><br>πi: Ωi -&gt; ∆(A).<br>优势：</li>
</ul>
<ol>
<li>在训练过程中，拿到全局信息，可以缓解非稳态性</li>
<li>在执行过程中，可以直接基于局部信息按策略执行动作<br>问题：<br>CTDE 在处理异质多智能体（智能体的状态或者动作空间不一致）的时候，往往表现不佳 -&gt; 可以通过技能学习或者通过先分组，再采用局部 CTDE 的方式进行训练</li>
</ol>
<h2 id="多智能体强化学习的难点和挑战"><a href="#多智能体强化学习的难点和挑战" class="headerlink" title="多智能体强化学习的难点和挑战"></a>多智能体强化学习的难点和挑战</h2><ol>
<li><p>非稳态性： 导致智能体在相同状态执行相同动作，得到的状态转移概率和奖励函数的分布不同<br>在基于Q值更新的策略中存在大问题：</p>
<ul>
<li>进行TD更新需要进行动作采样，在多智能体中采样联合动作往往难度较大</li>
<li>随着智能体同时进行更新，经验回放池中的数据会过时<br>-&gt; 对对手或者队友进行建模<br>-&gt; 对回放数据进行重采样</li>
</ul>
</li>
<li>可拓展性：为了解决非稳态，多智能体往往需要考虑环境中的所有智能体的联合动作，联合动作会随着智能体的数量呈指数上升<br>-&gt; 同质智能体共享神经网络、异质智能体间独立训练<br>-&gt; 迁移学习</li>
<li>部分可观测性：考虑到环境中传感器的限制等因素，智能体往往很难获得全局状态，一般只能拿到部分信息，我 们一般把多智能体强化学习建模为 POSG 部分可观测随机博弈：定义为 M = {N, S, A, P, R, γ, Ω, O}<br>-&gt; 环境不再遵循马尔可夫性<br>-&gt; 多智能体通信：智能体之间通过信息传递，缓解多智能体的局部观测问题 则需定义</li>
</ol>
<ul>
<li>与谁通信</li>
<li>通信什么内容</li>
<li>何时通信</li>
</ul>
<p><img src="/2024/01/27/MARL/1706431067761.png" alt="1706431067761"></p>
<p>通信内容：1. 直接把自身局部信息发送给其他智能体 -&gt; 信息冗余、带宽损耗 2. <strong>发送者提取出最有用的信息</strong><br>通信时机：1. 每时每刻通信 2. <strong>关键时刻通信</strong> 更高效</p>
<h2 id="经典环境下的协作多智能体强化学习"><a href="#经典环境下的协作多智能体强化学习" class="headerlink" title="经典环境下的协作多智能体强化学习"></a>经典环境下的协作多智能体强化学习</h2><h3 id="基于值函数的多智能体协作"><a href="#基于值函数的多智能体协作" class="headerlink" title="基于值函数的多智能体协作"></a>基于值函数的多智能体协作</h3><ol>
<li><p>IQL<br><img src="/2024/01/27/MARL/IQL.png" alt="IQL"></p>
</li>
<li><p>VDN<br><img src="/2024/01/27/MARL/VDN.png" alt="VDN"></p>
</li>
<li><p>QMIX<br><img src="/2024/01/27/MARL/QMIX.png" alt="QMIX"></p>
</li>
<li><p>QTRAN<br><img src="/2024/01/27/MARL/QTRAN.png" alt="QTRAN"></p>
</li>
</ol>
<ul>
<li>参考：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/203164554">https://zhuanlan.zhihu.com/p/203164554</a></li>
</ul>
<h3 id="MADDPG"><a href="#MADDPG" class="headerlink" title="MADDPG"></a>MADDPG</h3><p><img src="/2024/01/27/MARL/MADDPG.png" alt="MADDPG"></p>
<h3 id="COMA"><a href="#COMA" class="headerlink" title="COMA"></a>COMA</h3><p><img src="/2024/01/27/MARL/COMA.png" alt="COMA"></p>
<ul>
<li>参考：<a target="_blank" rel="noopener" href="https://hub.baai.ac.cn/view/13622">https://hub.baai.ac.cn/view/13622</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/01/22/PPO/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="米兰的小铁酱">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 米兰的小铁酱">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/01/22/PPO/" class="post-title-link" itemprop="url">PPO</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-01-22 16:11:29 / 修改时间：18:26:20" itemprop="dateCreated datePublished" datetime="2024-01-22T16:11:29+08:00">2024-01-22</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>3</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="PPO"><a href="#PPO" class="headerlink" title="PPO"></a>PPO</h1><p><img src="/2024/01/22/PPO/1705917072236.png" alt="1705917072236"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Wei</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">29k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">49 分钟</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
