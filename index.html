<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"xwqianbei.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.19.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"æœç´¢...","empty":"æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœç´¢ç»“æœï¼š${query}","hits_time":"æ‰¾åˆ° ${hits} ä¸ªæœç´¢ç»“æœï¼ˆç”¨æ—¶ ${time} æ¯«ç§’ï¼‰","hits":"æ‰¾åˆ° ${hits} ä¸ªæœç´¢ç»“æœ"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="attention is all you need">
<meta property="og:type" content="website">
<meta property="og:title" content="ç±³å…°çš„å°é“é…±">
<meta property="og:url" content="http://xwqianbei.github.io/index.html">
<meta property="og:site_name" content="ç±³å…°çš„å°é“é…±">
<meta property="og:description" content="attention is all you need">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Wei">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://xwqianbei.github.io/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>ç±³å…°çš„å°é“é…±</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="åˆ‡æ¢å¯¼èˆªæ " role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">ç±³å…°çš„å°é“é…±</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="æœç´¢" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>é¦–é¡µ</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>å…³äº</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>æ ‡ç­¾</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>åˆ†ç±»</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>å½’æ¡£</a></li><li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>æ—¥ç¨‹è¡¨</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          æ–‡ç« ç›®å½•
        </li>
        <li class="sidebar-nav-overview">
          ç«™ç‚¹æ¦‚è§ˆ
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Wei</p>
  <div class="site-description" itemprop="description">attention is all you need</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">19</span>
          <span class="site-state-item-name">æ—¥å¿—</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">æ ‡ç­¾</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/16/transformer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/16/transformer/" class="post-title-link" itemprop="url">transformer</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">å‘è¡¨äº</span>

      <time title="åˆ›å»ºæ—¶é—´ï¼š2024-03-16 12:52:36" itemprop="dateCreated datePublished" datetime="2024-03-16T12:52:36+08:00">2024-03-16</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
      <span>375</span>
    </span>
    <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
      <span>1 åˆ†é’Ÿ</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Attention-Is-All-You-Need"><a href="#Attention-Is-All-You-Need" class="headerlink" title="Attention Is All You Need"></a>Attention Is All You Need</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li><strong>Transformer</strong>: based solely on <strong>attention mechanisms</strong>, dispensing with recurrence and convolutions entirely</li>
<li><strong>being more parallelizable</strong></li>
<li><strong>sequence to sequence</strong>(seq2seq)</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li>Recurrent models å°† tokençš„ä½ç½®å’Œæ—¶é—´æ­¥å¯¹é½</li>
<li><strong>attention mechanisms</strong>: å…è®¸å¯¹tokenä¾èµ–å…³ç³»è¿›è¡Œå»ºæ¨¡ï¼Œè€Œæ— éœ€è€ƒè™‘è¾“å…¥æˆ–è¾“å‡ºåºåˆ—ä¸­çš„è·ç¦»</li>
</ul>
<h2 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h2><ul>
<li><strong>Encoder-Decoder structure</strong>: $x = (x_1, â€¦ , x_n)$ â€”â€”encoderâ€”â€” $z = (z_1, â€¦, z_n)$ â€”â€”decoderâ€”â€” $y = (y_1, â€¦ , y_m)$</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/16/BERT/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/16/BERT/" class="post-title-link" itemprop="url">BERT</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">å‘è¡¨äº</span>
      

      <time title="åˆ›å»ºæ—¶é—´ï¼š2024-03-16 12:52:09 / ä¿®æ”¹æ—¶é—´ï¼š13:00:04" itemprop="dateCreated datePublished" datetime="2024-03-16T12:52:09+08:00">2024-03-16</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
      <span>3.7k</span>
    </span>
    <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
      <span>6 åˆ†é’Ÿ</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding"><a href="#BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding" class="headerlink" title="BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"></a>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li><strong>BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers.</strong></li>
<li>the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li><strong>existing works</strong>: å°†é¢„è®­ç»ƒè¯­è¨€è¡¨å¾ç”¨äºä¸‹æ¸¸ä»»åŠ¡çš„ä¸¤ç§ç­–ç•¥<ol>
<li>feature-based: ELMo æŠŠpre-trained representation ä½œä¸ºé¢å¤–çš„ç‰¹å¾åŠ å…¥åˆ°ä»»åŠ¡ç‰¹å®šçš„æ¨¡å‹ç»“æ„ä¸­</li>
<li>fine-tuning: GPT åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­ç®€å•çš„fine-tuningæ‰€æœ‰çš„é¢„è®­ç»ƒå‚æ•°</li>
</ol>
</li>
<li><strong>limitation</strong>: the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks</li>
<li><strong>BERT</strong>: <ol>
<li><strong>MLM(masked language model)</strong>: Cloze task alleviates unidirectionality constraint -&gt; enables the representation to fuse the left and the right context</li>
<li><strong>next sentence prediction</strong>: pretrains text-pair representations</li>
</ol>
</li>
</ul>
<h2 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h2><h3 id="Unsupervised-Feature-based-Approaches"><a href="#Unsupervised-Feature-based-Approaches" class="headerlink" title="Unsupervised Feature-based  Approaches"></a>Unsupervised Feature-based  Approaches</h3><ul>
<li><strong>pretrain word embedding</strong>: left-to-right language model -&gt; åŒºåˆ†å·¦å³ä¸Šä¸‹ä¸­æ­£ç¡®æˆ–è€…ä¸æ­£ç¡®çš„å•è¯</li>
<li><strong>pretrain sentence representation</strong>: 1. å¯¹å€™é€‰çš„ä¸‹ä¸€ä¸ªå¥å­è¿›è¡Œæ’å 2.  æ ¹æ®ç»™å®šçš„å‰ä¸€ä¸ªå¥å­çš„è¡¨å¾ä»å·¦åˆ°å³åœ°ç”Ÿæˆä¸‹ä¸€ä¸ªå¥å­åœ°å•è¯</li>
<li><strong>ELMo</strong>: <ol>
<li>They extract context-sensitive features from a left-to-right and a right-to-left language model. </li>
<li>The contextual representation of each token is the concatenation of the left-to-right and right-to-left representations<h3 id="Unsupervised-Fine-tuning-Approaches"><a href="#Unsupervised-Fine-tuning-Approaches" class="headerlink" title="Unsupervised Fine-tuning Approaches"></a>Unsupervised Fine-tuning Approaches</h3></li>
</ol>
</li>
<li>pre-trained from unlabeled text and fine-tuned for a supervised downstream task</li>
<li>OpenAI GPT<h3 id="Transfer-Learning-from-Supervised-Data"><a href="#Transfer-Learning-from-Supervised-Data" class="headerlink" title="Transfer Learning from Supervised Data"></a>Transfer Learning from Supervised Data</h3></li>
</ul>
<h2 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h2><h3 id="pre-training-and-fine-tuning"><a href="#pre-training-and-fine-tuning" class="headerlink" title="pre-training and fine-tuning"></a>pre-training and fine-tuning</h3><ul>
<li><strong>pre-training</strong>: During pre-training, the model is trained on unlabeled data over different pre-training tasks.</li>
<li><strong>fine-tuning</strong>: For finetuning, the BERT model is first initialized with the pre-trained parameters, and all of the parameters are fine-tuned using labeled data from the downstream tasks.</li>
<li>æ¯ä¸ªä¸åŒçš„ä¸‹æ¸¸ä»»åŠ¡éƒ½å¯¹ç”¨ç›¸åŒçš„é¢„è®­ç»ƒå‚æ•°<br><img src="/2024/03/16/BERT/1710050250445.png" alt="1710050250445"><h3 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h3></li>
<li><strong>multi-layer bidirectional Transformer encoder</strong></li>
<li><em>L</em>: the number of Layers(Transformer blocks)</li>
<li><em>H</em>: the hidden size</li>
<li><em>A</em>: the number of self-attention heads</li>
<li><strong>$BERT_{BASE}$</strong>: (L = 12, H = 768, A = 12, Total Parameters = 110M)</li>
<li><strong>$BERT_{LARGE}$</strong>: (L = 24, H = 1024, A = 16, Total Parameters = 340M)</li>
<li><strong>BERT V.S. GPT</strong>: bidirectional self-attention V.S.  constrained self-attention(every token can only attend to context to its left.)<h3 id="Input-Output-Representations"><a href="#Input-Output-Representations" class="headerlink" title="Input/Output Representations"></a>Input/Output Representations</h3></li>
<li><strong>input sequence</strong>: input å¯ä»¥æ˜¯éšæ„è·¨åº¦çš„è¿ç»­æ–‡æœ¬ input sequenceå¯ä»¥æ˜¯single sentence æˆ–è€… two sentences packed together<ol>
<li><em>Word Embedding</em>: WordPiece embeddings with a 30000 token vocabulary</li>
<li><em>First token of input sequnence</em>: <strong>[CLS] special classification token as C (dim = H)</strong></li>
<li><em>Sentences differentite</em>: <ol>
<li>[CLS] sentenceA [SEP] sentenceB</li>
<li>learned token embedding as $E_{A}$ or $E_{B}$, sentenceA or sentenceB<br><img src="/2024/03/16/BERT/1710053093135.png" alt="1710053093135"></li>
</ol>
</li>
</ol>
</li>
<li><strong>output representation</strong>: <ol>
<li>[CLS] as $C \in R^{H}$</li>
<li>final vector itoken -&gt; $T_{i} \in R^{H}$<h2 id="Pre-training-BERT"><a href="#Pre-training-BERT" class="headerlink" title="Pre-training BERT"></a>Pre-training BERT</h2><h3 id="Task-1-Masked-LM-MLM"><a href="#Task-1-Masked-LM-MLM" class="headerlink" title="Task #1: Masked LM(MLM)"></a>Task #1: Masked LM(MLM)</h3></li>
</ol>
</li>
<li>it is reasonable to believe that a deep bidirectional model is strictly more powerful than either a left-to-right model or the shallow concatenation of a left-toright and a right-to-left model.</li>
<li>standard conditional language models can only be trained left-to-right or right-to-left, <strong>since bidirectional conditioning would allow each word to indirectly â€œsee itselfâ€</strong></li>
<li><strong>MLM(masked LM)</strong>: éšæœºmaskæ¯ä¸ªsequence 15% çš„tokens<ol>
<li>pretrainæ—¶ input sequence æœ‰[MASK] token ä½†æ˜¯ fine-tuningæ—¶æ˜¯æ²¡æœ‰[MASK] tokençš„ï¼Œ ä¸ºäº†ç¼“è§£è¿™ç§å·®å¼‚ï¼Œå¯¹è¿™ 15% mask tokensè¿›è¡Œå¤„ç†</li>
<li>æœ€ç»ˆ 80% [MASK] 10 [RND(rondam token)] 10 [SAME(same token)]<br><img src="/2024/03/16/BERT/1710054577043.png" alt="1710054577043"><h3 id="Task-2-Next-Sentence-Prediction-NSP"><a href="#Task-2-Next-Sentence-Prediction-NSP" class="headerlink" title="Task #2: Next Sentence Prediction(NSP)"></a>Task #2: Next Sentence Prediction(NSP)</h3></li>
</ol>
</li>
<li>QA task and Natural Language Inference (NLI) are based on understanding the <strong>relationship between two sentences</strong>, <strong>which is not directly captured by language modeling.</strong></li>
<li><strong>binarized(0/1) next sentence prediction task</strong>: åˆ¤æ–­sentenceB æ˜¯å¦æ˜¯ sentenceA çš„ä¸‹ä¸€å¥<ul>
<li><strong>50%</strong> of the time B is the actual next sentence that follows A (labeled as IsNext),</li>
<li><strong>50%</strong> of the time it is a random sentence from the corpus (labeled as NotNext)</li>
<li>[CLS] C è¢«ç”¨ä½œ NSP äºŒåˆ†ç±»ä»»åŠ¡<h3 id="Pre-training-data"><a href="#Pre-training-data" class="headerlink" title="Pre-training data"></a>Pre-training data</h3></li>
</ul>
</li>
</ul>
<ol>
<li>BooksCorpus (800M words)</li>
<li>English Wikipedia (2,500M words).(Only passages)</li>
<li>It is critical to use a <strong>document-level corpus</strong> rather than a shuffled sentence-level corpus</li>
</ol>
<h2 id="Fine-tuning-BERT"><a href="#Fine-tuning-BERT" class="headerlink" title="Fine-tuning BERT"></a>Fine-tuning BERT</h2><ul>
<li>At the output, the token representations are fed into an output layer for tokenlevel tasks, such as sequence tagging or question answering, and the [CLS] representation is fed into an output layer for classification, such as entailment or sentiment analysis.</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/15/GoMARL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/15/GoMARL/" class="post-title-link" itemprop="url">GoMARL</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">å‘è¡¨äº</span>

      <time title="åˆ›å»ºæ—¶é—´ï¼š2024-03-15 11:17:36" itemprop="dateCreated datePublished" datetime="2024-03-15T11:17:36+08:00">2024-03-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">æ›´æ–°äº</span>
      <time title="ä¿®æ”¹æ—¶é—´ï¼š2024-03-20 18:44:46" itemprop="dateModified" datetime="2024-03-20T18:44:46+08:00">2024-03-20</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
      <span>3.7k</span>
    </span>
    <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
      <span>6 åˆ†é’Ÿ</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Automatic-Grouping-for-Efficient-Cooperative-Multi-Agent-Reinforcement-Learning"><a href="#Automatic-Grouping-for-Efficient-Cooperative-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Automatic Grouping for Efficient Cooperative Multi-Agent Reinforcement Learning"></a>Automatic Grouping for Efficient Cooperative Multi-Agent Reinforcement Learning</h1><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li><strong>GoMARL</strong>: Group-oriented Multi-Agent Reinforcement Learning learn automatic grouping without domain knowledge for efficient cooperation.</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul>
<li>GoMARL:<ol>
<li>GoMARL holds a dualhierarchical value factorization</li>
<li>learns dynamic groups with a â€œselect-and-kick-outâ€ scheme.</li>
</ol>
</li>
<li>GoMARL continuously selects agents unsuitable for their current groups based on the learning weights of the decomposition from the group-wise value to local utilities and kicks them out to reorganize the group division.</li>
<li>GoMARL transforms various informative training signals, including individual group-related information, group state, and global state, into network weights, which extracts effective guidance for policy improvement and enables flexible adaptation to the dynamic changes in the number of subgroups and the number of agents per group.</li>
</ul>
<h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><h2 id="Group-oriented-Multi-Agent-Reinforcement-Learning"><a href="#Group-oriented-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Group-oriented Multi-Agent Reinforcement Learning"></a>Group-oriented Multi-Agent Reinforcement Learning</h2><ul>
<li><strong>Atuomatic grouping module</strong>: GoMARL decomposes the global action-value Qtot into groupwise values Qg and trains agents by groups in a fine-grained manner.<br><img src="/2024/03/15/GoMARL/1710561769884.png" alt="1710561769884"><h2 id="4-1-Automatic-Grouping-Mechanism"><a href="#4-1-Automatic-Grouping-Mechanism" class="headerlink" title="4.1 Automatic Grouping Mechanism"></a>4.1 Automatic Grouping Mechanism</h2></li>
<li>learn a mapping relationship $f_{g}$ : A -&gt; G. -&gt; divide the team into dynamic groups in an end-to-end fashion by maximizing the expected global return $Q_{g}^{tot}$.</li>
<li><strong>Individual    w! Generator</strong>: GoMARL â€œselects and kicks outâ€ agents whose individual utilities hold small mixing weights and contribute a little to their group-wise Q values</li>
<li><p>We empirically utilize seventy percent of each groupâ€™s average weight to assess whether an agent fits its current group.<br><img src="/2024/03/15/GoMARL/1710852685014.png" alt="1710852685014"></p>
</li>
<li><p><strong>Group Adjustment Operator</strong>: $O_{g}:\{w_{1}^{1},â€¦,W_{1}^{n}\}-&gt;\{w_{1}^{g1},â€¦,w_{1}^{gm}\}$ concatenates the wi1 of agents in the same group to form a set of group-wise wg 1 to generate group action-value.<br><img src="/2024/03/15/GoMARL/1710852756019.png" alt="1710852756019"></p>
</li>
</ul>
<h2 id="4-2-Specialized-Agent-Network-for-Decentralized-Execution"><a href="#4-2-Specialized-Agent-Network-for-Decentralized-Execution" class="headerlink" title="4.2 Specialized Agent Network for Decentralized Execution"></a>4.2 Specialized Agent Network for Decentralized Execution</h2><ul>
<li><strong>group-wise information e</strong>: Integrating group-wise information e into the decision-making process enables consideration of cooperative behaviors.<br><img src="/2024/03/15/GoMARL/1710853359419.png" alt="1710853359419"></li>
<li><p><strong>group-related info encoder $f_{e}(Â·; \theta_{e})$</strong>: train the encoder network as an extractor, where the extracted agent info $e$ of agents from the same group should be similar. To avoid all agentsâ€™ $e^{i}$ collapsing to be alikem the regularizer also encourages diversity between agents from different groups.<br><img src="/2024/03/15/GoMARL/1710854191337.png" alt="1710854191337"></p>
</li>
<li><p><strong>Group-related Info Decoder</strong>: $e^{i}$ fed into a decoder $f_{d}(Â·;\theta_{d})$ to generate the parameters of the agent networkâ€™s upper MLP</p>
<ol>
<li>Our method hybridizes the efficiency of parameter-sharing and the policy diversity needed for complex collaboration.</li>
<li>providing informative group-related information to enrich local utilities and promote intra-group cooperation.</li>
</ol>
</li>
</ul>
<h2 id="4-3-Overall-Learning-Framework"><a href="#4-3-Overall-Learning-Framework" class="headerlink" title="4.3 Overall Learning Framework"></a>4.3 Overall Learning Framework</h2><p><img src="/2024/03/15/GoMARL/1710855631168.png" alt="1710855631168"></p>
<ul>
<li>two mixing networks:<ol>
<li>group-wise $Q^{g}$</li>
<li>global $Q^{tot}$</li>
</ol>
</li>
<li>group-wise $Q^{g}$: <ol>
<li>$w_{1}^{g}$ -&gt; â€œselects and kicks outâ€ decides the group division</li>
<li>$w_{2}^{g}$ -&gt; generate $Q^{g}$\ carries group status information</li>
</ol>
</li>
<li>$w_{2}^{g}$: Group-related Info $e = \{e_{t}^{1},e_{t}^{2},â€¦,e_{t}^{n}\}$  (from group-related info encoder) -&gt; pooling Operation -&gt; Group State$s = \{s_{t}^{g1},s_{t}^{g2},â€¦,s_{t}^{gm}\}$ -&gt; Group-wise ğ°ğŸ Generator$f_{w2}(s_{g})$ -&gt; $\{w_{2}^{g1}, â€¦ ,w_{2}^{gm}\}$</li>
<li>$Q^{tot}$: <ol>
<li>$w_{1}^{Q^{tot}}$: $s = \{s_{t}^{g1},s_{t}^{g2},â€¦,s_{t}^{gm}\}$ -&gt; $f_{w1}^{i}(Â·;\theta_{w1}^[i])$ -&gt; $\{w_{1}^{g1},â€¦,w_{1}^{gm}\}$ -&gt; k dim hidden state</li>
<li>global state $s$ -&gt; $f_{w2}(Â·|s)$ -&gt; $w_{2}$ -&gt; $Q^{tot}$<br><img src="/2024/03/15/GoMARL/1710860129623.png" alt="1710860129623"></li>
</ol>
</li>
</ul>
<h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h2 id="5-1-Performance-on-SMAC"><a href="#5-1-Performance-on-SMAC" class="headerlink" title="5.1 Performance on SMAC"></a>5.1 Performance on SMAC</h2><ul>
<li><strong>Overall performance</strong>:<br><img src="/2024/03/15/GoMARL/1710930045436.png" alt="1710930045436"></li>
<li><strong>Parameter size for value mixing.</strong>: GoMARL outperforms other methods despite using fewer mixing parameters, highlighting its inherent superiority over methods relying on stronger mixing networks.<br><img src="/2024/03/15/GoMARL/1710930152325.png" alt="1710930152325"></li>
<li><strong>Component analysis and ablation study</strong>:<ol>
<li>Learned grouping analysis<br><img src="/2024/03/15/GoMARL/1710930947555.png" alt="1710930947555"></li>
<li>Component study of the specialized agents: We transplant our specialized agent network (SAN) into other baselines to verify module effectiveness.<br><img src="/2024/03/15/GoMARL/1710931015065.png" alt="1710931015065"></li>
<li>Ablation study of the informative group-related signals: <h2 id="5-2-Performance-on-Google-Research-Football"><a href="#5-2-Performance-on-Google-Research-Football" class="headerlink" title="5.2 Performance on Google Research Football"></a>5.2 Performance on Google Research Football</h2></li>
</ol>
</li>
<li>in which the first group brought the ball into the penalty area through smooth coordination, while the second group created two shoots and the final goal through skillful cooperation<br><img src="/2024/03/15/GoMARL/1710931307596.png" alt="1710931307596"></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/12/RLHF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/12/RLHF/" class="post-title-link" itemprop="url">RLHF</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">å‘è¡¨äº</span>

      <time title="åˆ›å»ºæ—¶é—´ï¼š2024-03-12 12:45:44" itemprop="dateCreated datePublished" datetime="2024-03-12T12:45:44+08:00">2024-03-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">æ›´æ–°äº</span>
      <time title="ä¿®æ”¹æ—¶é—´ï¼š2024-03-15 11:17:03" itemprop="dateModified" datetime="2024-03-15T11:17:03+08:00">2024-03-15</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
      <span>2.1k</span>
    </span>
    <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
      <span>4 åˆ†é’Ÿ</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Training-language-models-to-follow-instructions-with-human-feedback"><a href="#Training-language-models-to-follow-instructions-with-human-feedback" class="headerlink" title="Training language models to follow instructions with human feedback"></a>Training language models to follow instructions with human feedback</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li><strong>Challenge</strong>: ä¸€å‘³åœ°å¢å¤§å¤§æ¨¡å‹ä¹Ÿä¸èƒ½ä»æœ¬è´¨ä¸Šæ›´å¥½åœ°éµå¾ªç”¨æˆ·çš„æ„å›¾ï¼Œ å¤§æ¨¡å‹ç”Ÿæˆçš„è¾“å‡ºå¯èƒ½æ˜¯ä¸çœŸå®çš„ï¼Œæœ‰æ¯’å®³çš„ æˆ–è€…æ˜¯å¯¹ç”¨æˆ·æ²¡æœ‰å¸®åŠ©çš„</li>
<li><strong>In this paper</strong>: å±•ç¤ºäº†ä¸€ç§é€šè¿‡æ ¹æ®äººç±»åé¦ˆè¿›è¡Œå¾®è°ƒæ¥ä½¿å¤§æ¨¡å‹ä¸ç”¨æˆ·å¯¹å„ç§ä»»åŠ¡çš„æ„å›¾ä¿æŒä¸€è‡´çš„é€”å¾„</li>
<li><strong>InstructGPT</strong>: <ol>
<li>we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning.</li>
<li>We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback.</li>
</ol>
</li>
<li><strong>Result</strong>: In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters.</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li><strong>misaligned</strong>: LMçš„ç›®æ ‡æ˜¯åœ¨äº’è”ç½‘çš„ç½‘é¡µä¸Šé¢„æµ‹ä¸‹ä¸€ä¸ªtoken è€Œä¸æ˜¯ æœ‰æ•ˆä¸”å®‰å…¨åœ°éµå¾ªäººç±»æ‰§è¡Œ</li>
<li><strong>RLHF</strong>: uses human preferences as reward signal to fine-tune our models.</li>
</ul>
<h2 id="Methods-and-experimental-details"><a href="#Methods-and-experimental-details" class="headerlink" title="Methods and experimental details"></a>Methods and experimental details</h2><h3 id="3-1-High-level-methodology"><a href="#3-1-High-level-methodology" class="headerlink" title="3.1 High-level methodology"></a>3.1 High-level methodology</h3><ul>
<li>start with:<ol>
<li>a pretrained language model</li>
<li>a distribution of prompts(which we want our model to produce aligned outputs)</li>
<li>a team of trained hunman labrlers</li>
</ol>
</li>
<li>steps:<ol>
<li><strong>collect demonstration data, and train a supervised policy</strong>: <ul>
<li>human labelers provide demonstrations of the desired behavior on the input prompt distribution. </li>
<li>We then fine-tune a pretrained GPT-3 model on this data using supervised learning.</li>
</ul>
</li>
<li><strong>Collect comparison data, and train a reward model.</strong>:<ul>
<li>We collect a dataset of comparisons between model outputs, where labelers indicate which output they prefer for a given input</li>
<li>We then train a reward model to predict the human-preferred output.</li>
</ul>
</li>
<li><strong>Optimize a policy against the reward model using PPO.</strong>:<ul>
<li>We use the output of the RM as a scalar reward.</li>
<li>We fine-tune the supervised policy to optimize this reward using the PPO algorithm<h3 id="3-2-Dataset"><a href="#3-2-Dataset" class="headerlink" title="3.2 Dataset"></a>3.2 Dataset</h3></li>
</ul>
</li>
</ol>
</li>
<li><strong>prompts dataset</strong>: 1. primarily of text prompts submitted to a commercial language model API 2. a small number of labeler-written prompts.</li>
<li><strong>prompts are diverse</strong>: include generation, question answering, dialog, summarization, extractions, and other natural language tasks</li>
<li><strong>prompts clean</strong>: 1. heuristically deduplicate prompts  2. ensure that the validation and test sets contain no data from users whose data is in the training set. 3. We also filter prompts containing personally identifiable information (PII).</li>
<li><strong>prompts  produce three different datasets used in our fine-tuning procedure</strong>:<ol>
<li>SFT dataset</li>
<li>RM dataset</li>
<li>PPO dataset</li>
</ol>
</li>
</ul>
<h3 id="3-3-Human-data-collection"><a href="#3-3-Human-data-collection" class="headerlink" title="3.3 Human data collection"></a>3.3 Human data collection</h3><h3 id="3-4-Models"><a href="#3-4-Models" class="headerlink" title="3.4 Models"></a>3.4 Models</h3><ol>
<li><strong>Supervised fine-tuning(SFT)</strong>: fine-tune GPT-3 on our labeler demonstrations using supervised learning.</li>
<li></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/11/DPO/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/11/DPO/" class="post-title-link" itemprop="url">DPO</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">å‘è¡¨äº</span>
      

      <time title="åˆ›å»ºæ—¶é—´ï¼š2024-03-11 13:16:25 / ä¿®æ”¹æ—¶é—´ï¼š15:28:32" itemprop="dateCreated datePublished" datetime="2024-03-11T13:16:25+08:00">2024-03-11</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
      <span>963</span>
    </span>
    <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
      <span>2 åˆ†é’Ÿ</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Direct-Preference-Optimization-Your-Language-Model-is-Secretly-a-Reward-Model"><a href="#Direct-Preference-Optimization-Your-Language-Model-is-Secretly-a-Reward-Model" class="headerlink" title="Direct Preference Optimization: Your Language Model is Secretly a Reward Model"></a>Direct Preference Optimization: Your Language Model is Secretly a Reward Model</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li><strong>RLHF</strong>: æ”¶é›†äººç±»åå¥½æ ‡ç­¾æ•°æ®ï¼Œä½¿ç”¨å¼ºåŒ–å­¦ä¹ å¯¹é½äººç±»åå¥½</li>
<li><strong>challenge</strong>: RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model</li>
<li><strong>DPO</strong>: <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2></li>
<li><strong>RLHF</strong>: <ol>
<li>fit a reward model to a dataset of human prefereneces</li>
<li>use RL to optimize a language model policy to produce response assigned high reward without drifting excessively far from the original model</li>
<li>RLHF pipline is considerably more complex than supervised learning</li>
</ol>
</li>
<li><strong>DPO</strong>: <ol>
<li>without explict reward modeling or reinforcement learning</li>
<li>implicity optimizes the same objective as existing RLHF algorithms(reward maximization with a KL-divergence constraint)</li>
<li>DPO update increases the relative log probability of preferred to dispreferred responses</li>
<li>but it incorporates a dynamic, per-example importance weight that prevents the model degeneration that we find occurs with a naive probability ratio objective.</li>
</ol>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/10/%E5%85%B3%E4%BA%8Ehexo-new/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/10/%E5%85%B3%E4%BA%8Ehexo-new/" class="post-title-link" itemprop="url">å…³äºhexo new</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">å‘è¡¨äº</span>

      <time title="åˆ›å»ºæ—¶é—´ï¼š2024-03-10 12:40:06" itemprop="dateCreated datePublished" datetime="2024-03-10T12:40:06+08:00">2024-03-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">æ›´æ–°äº</span>
      <time title="ä¿®æ”¹æ—¶é—´ï¼š2024-03-16 12:56:54" itemprop="dateModified" datetime="2024-03-16T12:56:54+08:00">2024-03-16</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
      <span>546</span>
    </span>
    <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
      <span>1 åˆ†é’Ÿ</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="å…³äºhexo-new"><a href="#å…³äºhexo-new" class="headerlink" title="å…³äºhexo new"></a>å…³äºhexo new</h1><p><a target="_blank" rel="noopener" href="https://hexo.io/docs/commands.html#new">å®˜ç½‘è¯´æ˜</a><br><img src="/2024/03/10/%E5%85%B3%E4%BA%8Ehexo-new/1710045767599.png" alt="1710045767599"></p>
<ul>
<li>å¦‚æœlayoutæ²¡æœ‰æŒ‡æ˜çš„è¯ï¼Œhexoä¼šä½¿ç”¨config.ymlä¸­çš„default_layoutçš„é»˜è®¤é…ç½®ï¼Œä¸€èˆ¬é»˜è®¤æ˜¯post</li>
<li>å¦‚æœtitleä¸­åŒ…å«ç©ºæ ¼çš„è¯ï¼Œåˆ™éœ€è¦ä½¿ç”¨å¼•å·</li>
</ul>
<h2 id="hexo-new-post"><a href="#hexo-new-post" class="headerlink" title="hexo new post"></a>hexo new post</h2><ul>
<li>layout ä¸º postæ—¶ï¼Œä¼šåœ¨./source/_postsä¸‹åˆ›å»ºä¸€ä¸ªtitle.mdæ–‡æ¡£ </li>
<li>ä½¿ç”¨markdownç¼–è¾‘title.md å¹¶ æ‰§è¡Œ <code>hexo g -d</code>åˆ™å¯ä»¥åœ¨ç½‘é¡µä¸­çœ‹åˆ°ç›¸åº”å†…å®¹</li>
</ul>
<h2 id="hexo-new-draft"><a href="#hexo-new-draft" class="headerlink" title="hexo new draft"></a>hexo new draft</h2><ul>
<li>æ‰§è¡Œ <code>hexo new draft &#39;title&#39;</code> åï¼Œ hexoä¼šåœ¨./source/_draftsä¸‹åˆ›å»ºä¸€ä¸ª title.mdæ–‡æ¡£ï¼ˆå¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ‰§è¡Œåˆ™ä¼šå…ˆåˆ›å»º_draftsæ–‡ä»¶å¤¹ï¼‰</li>
<li>è¯¥title.mdä¸ºè‰ç¨¿çŠ¶æ€ æ‰§è¡Œ <code>hexo g -d</code>åˆ™åœ¨ç½‘é¡µä¸­çœ‹ä¸åˆ°ç›¸åº”å†…å®¹</li>
<li><strong>å¦‚ä½•å‘å¸ƒdraftçŠ¶æ€çš„æ–‡æ¡£ï¼Ÿ</strong> -&gt; <code>hexo publish draft title</code> è¿™æ ·_draftsä¸‹çš„title.mdä¼šæ¶ˆå¤±ï¼Œ_postsä¸‹ä¼šå‡ºç°ä¸€ä¸ªtitle.md</li>
<li>å¯ä»¥ä½¿ç”¨<code>hexo g --draft</code>ï¼Œ <code>hexo s --draft</code>å‘½ä»¤æ¥åœ¨æœ¬åœ°é¢„è§ˆæˆ‘ä»¬çš„è‰ç¨¿æ•ˆæœ</li>
</ul>
<h2 id="hexo-new-page"><a href="#hexo-new-page" class="headerlink" title="hexo new page"></a>hexo new page</h2><ul>
<li><code>hexo new page &#39;about&#39;</code> ä¼šåœ¨sourceä¸‹ç”Ÿæˆä¸€ä¸ªåä¸ºaboutçš„æ–‡ä»¶å¤¹ï¼Œ æ–‡ä»¶å¤¹ä¸‹ä¼šæœ‰ä¸€ä¸ªindex.mdçš„æ–‡ä»¶</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/" class="post-title-link" itemprop="url">ATTENTION-GUIDED CONTRASTIVE ROLE REPRE-SENTATIONS FOR MULTI-AGENT REINFORCEMENT LEARNING</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">å‘è¡¨äº</span>

      <time title="åˆ›å»ºæ—¶é—´ï¼š2024-03-04 21:27:25" itemprop="dateCreated datePublished" datetime="2024-03-04T21:27:25+08:00">2024-03-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">æ›´æ–°äº</span>
      <time title="ä¿®æ”¹æ—¶é—´ï¼š2024-03-08 23:31:56" itemprop="dateModified" datetime="2024-03-08T23:31:56+08:00">2024-03-08</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
      <span>5k</span>
    </span>
    <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
      <span>8 åˆ†é’Ÿ</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING-ICLR-24-Nanjing-University"><a href="#ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING-ICLR-24-Nanjing-University" class="headerlink" title="ATTENTION-GUIDED CONTRASTIVE ROLE REPRE-SENTATIONS FOR MULTI-AGENT REINFORCEMENT LEARNING ICLR-24 Nanjing University"></a>ATTENTION-GUIDED CONTRASTIVE ROLE REPRE-SENTATIONS FOR MULTI-AGENT REINFORCEMENT LEARNING ICLR-24 Nanjing University</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li><strong>Challenge</strong>: æ™ºèƒ½ä½“ä¹‹é—´çš„æœ‰æ•ˆåˆä½œ</li>
<li><strong>motivation</strong>: å—è§’è‰²å’Œæ™ºèƒ½ä½“è¡Œä¸ºæ¨¡å¼ä¹‹é—´ç›¸å…³æ€§çš„å¯å‘</li>
<li><strong>ACORM</strong>: Attention-guided COntrastive Role representation learning for MARL (ACORM) -&gt; ä¿ƒè¿›æ™ºèƒ½ä½“ä¹‹é—´ è¡Œä¸ºå¼‚è´¨åŒ–ã€çŸ¥è¯†ä¼ è¾“ã€æŠ€èƒ½ä¸Šçš„åè°ƒ</li>
<li><strong>methods</strong>: <ol>
<li>ä½¿ç”¨æœ€å¤§åŒ–äº’ä¿¡æ¯æ¥å½¢å¼åŒ–è§’è‰²è¡¨å¾å­¦ä¹ (role representation learning) -&gt; æ¨å¯¼å‡ºå¯¹æ¯”å­¦ä¹ ç›®æ ‡ -&gt; ç²¾ç®€ä¼°è®¡è´Ÿæ ·æœ¬çš„åˆ†å¸ƒ </li>
<li>åˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶ä¿ƒè¿›åœ¨ä»·å€¼åˆ†è§£ä¸­global state å…³æ³¨åˆ° å­¦ä¹ åˆ°çš„role representations -&gt; éšå¼åœ°æŒ‡å¯¼æ™ºèƒ½ä½“åè°ƒåœ¨ä¸€ä¸ªæŠ€èƒ½æ€§çš„skillful role space ä»¥ç”Ÿæˆå…·æœ‰è¡¨ç°åŠ›çš„ä¿¡ç”¨åˆ†é…</li>
</ol>
</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li><strong>challenge</strong>: å…±äº«policyå‚æ•° åŠ é€Ÿmassive agentsåœºæ™¯ä¸‹çš„ åˆä½œå­¦ä¹  -&gt; å¯¼è‡´åŒè´¨çš„è¡Œä¸º é˜»ç¢äº†å¤šæ ·æ€§æ¢ç´¢å’Œå¤æ‚çš„åˆä½œ </li>
<li><strong>existing works</strong>: Contrastive Identity-Aware Learning for Multi-Agent Value Decomposition -&gt; åˆ©ç”¨å¯¹æ¯”å­¦ä¹ ä½¿å¾—agentå¯¹åº”çš„identify representation ç›¸äº’åŒºåˆ† -&gt; å¿½ç•¥äº†é€šè¿‡éšå¼ä»»åŠ¡åˆ†é…è¿›è¡Œteamåˆ†è§£çš„æœ‰æ•ˆæ€§   é€šè¿‡åˆ†å±‚æ§åˆ¶ç»“æ„å°†ä»»åŠ¡åˆ†è§£ä¸ºä¸€ç»„æŠ€èƒ½ æˆ–è€… å­ä»»åŠ¡</li>
<li><strong>methods</strong>: <ol>
<li>å½¢å¼åŒ–å­¦ä¹ ç›®æ ‡ä¸º role å’Œ å®ƒçš„representation ä¹‹é—´çš„äº’ä¿¡æ¯ -&gt; æœ€å¤§é™åº¦å‡å°‘roleçš„ä¸ç¡®å®šæ€§ æœ€å°åŒ–ä¿ç•™roleæ— å…³ä¿¡æ¯ ä¸ºäº†ç®€å•çš„è¿‘ä¼¼ negative pairs çš„åˆ†å¸ƒ -&gt; é€šè¿‡ç¼–ç å®ƒçš„trajectoryåˆ°éšç©ºé—´ä¸­ æå–agentçš„è¡Œä¸º å¹¶æ ¹æ®éšç©ºé—´å®šæœŸåœ°å°†agentåˆ†ä¸ºå‡ ä¸ªç°‡ -&gt; æ¥è‡ªä¸åŒç°‡çš„ç‚¹è¢«åˆ†é…ä¸ºè´Ÿå¯¹</li>
<li>ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶ ä¿ƒè¿› åœ¨ä»·å€¼åˆ†è§£æ—¶ global state æ³¨æ„ å­¦ä¹ åˆ°çš„role representation -&gt; éšå¼çš„æŒ‡å¯¼ agent åœ¨ä¸€ä¸ª skillful role space ä¸­åè°ƒ -&gt; éšç€roleçš„æ¶Œç°ç”Ÿæˆæ›´æœ‰è¡¨ç°åŠ›çš„ ä¿¡ç”¨åˆ†é…</li>
</ol>
</li>
</ul>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><ul>
<li><strong>idea</strong>: å­¦ä¹ ä¸€ä¸ªç´§å‡‘çš„è§’è‰²è¡¨ç¤º(compact role representation) è¿™ä¸ªcompact role representationå¯ä»¥ä¸ªæ€§åŒ–æ™ºèƒ½ä½“å¤æ‚çš„è¡Œä¸ºæ¨¡å¼ -&gt; ä½¿ç”¨è¿™ä¸ªè§’è‰²ä¿¡æ¯å¯ä»¥ä¿ƒè¿›ä¸ªä½“ policy å­¦ä¹  å’Œ å¼•å¯¼agent åä½œ -&gt; ç›¸ä¼¼è§’è‰²çš„ agents å¯ä»¥é€šè¿‡æ›´ç§¯æçš„çŸ¥è¯†ä¼ è¾“ äº«å—æ›´é«˜çš„å­¦ä¹ æ•ˆç‡ å¹¶ä¸” ä¸åŒè§’è‰²çš„åŒºåˆ†ä¹Ÿå¯ä»¥ä¿è¯æ™ºèƒ½ä½“çš„å¼‚è´¨æ€§<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Our idea is to learn a compact role representation that can characterize complex behavior patterns of agents, and use the role information to facilitate individual policy learning and guide agent coordination. Agents with similar roles can enjoy higher learning efficiency via more aggressive knowledge transfer, and agent heterogeneity is also guaranteed with the discrimination of diverse roles.</span><br></pre></td></tr></table></figure></li>
<li><strong>definition 1:</strong> åœ¨å¤šæ™ºèƒ½ä½“ä»»åŠ¡ä¸­ï¼Œæ¯ä¸ªagentéƒ½å’Œä¸€ä¸ªæè¿°å…¶è¡Œä¸ºæ¨¡å¼çš„role Mi ç›¸å…³è” -&gt; å…¶ä¸­Mi é€šè¿‡ role representation zi é‡åŒ–è¡¨ç¤º -&gt; zi é€šè¿‡ Lä¸ªobservation-action pairsè®­ç»ƒ è¿™äº›O-A pairsæ¥è‡ªagent içš„trajectory -&gt; Ï€zi : O Ã— A Ã— Z â†’ [0, 1] is the individual policy for agent i</li>
<li><strong>ACORM</strong>: ï¼ˆ1ï¼‰é€šè¿‡å¯¹æ¯”å­¦ä¹  å­¦ä¹  agents å¯¹åº”çš„ role representations zi ï¼ˆ2ï¼‰ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶ ä¿ƒè¿› global state å…³æ³¨ å­¦ä¹ åˆ°çš„role patterns -&gt; å¼•å¯¼åœ¨high-level role space ä¸­ æŠ€èƒ½ä¸Šçš„æ™ºèƒ½ä½“åè°ƒ -&gt; ä¿ƒè¿›æœ‰è¡¨ç°åŠ›çš„ä¿¡ç”¨åˆ†é…</li>
</ul>
<h3 id="Contrastive-Role-Representations"><a href="#Contrastive-Role-Representations" class="headerlink" title="Contrastive Role Representations"></a>Contrastive Role Representations</h3><ul>
<li><strong>Objective</strong>: 1. agents with similar behavior patterns exhibit closer role representations 2. with notably different strategies are pushed away from each other.</li>
<li><strong>key issues</strong> 1. how to define a feasible metric to quantify the degree of similaroty between agentâ€™s behaviors 2. how to develop an efficient method to optimize the discrimination of role representations</li>
<li><strong>1 Agent Embedding</strong>:  $e^{t}_{i}=f_{\phi}(o_{i}^{t-1}, a_{i}^{t-1}, e_{i}^{t-1})$ distance between the obtained agent embeddings -&gt; metric to measure the behavior dissimilarity between agents</li>
<li><p><strong>2 Contrastive Learning</strong>: discriminative role representation &lt;- agentâ€™s behaviors patterns   -&gt;   maximize the mutual information between the role and its representation learn a role encoder that maximally reduces role uncertainty while minimally preserving role-irrelevant information<br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709886563461.png" alt="1709886563461"></p>
</li>
<li><p>$L_{CL}$:<br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709886677274.png" alt="1709886677274"><br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709886690507.png" alt="1709886690507"><br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709886699683.png" alt="1709886699683"><br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709886709036.png" alt="1709886709036"></p>
<ul>
<li>$|M| = K$ Kï¼šwe partition all n agents into K clusters $\{C_{j}\}_{j=1}^{K}$ according to agent embeddings.</li>
<li>$z^{T}_{i}Wz_{iâ€™}$ where W is a learnable parameter matrix</li>
</ul>
</li>
<li><strong>MOCO method</strong>: maintain a query encoder Î¸q and a key encoder Î¸k, and use a momentum update to facilitate the key representationsâ€™ consistency as<br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709887238174.png" alt="1709887238174"><br>where Î² âˆˆ [0, 1) is a momentum coefficient, and only parameters Î¸q are updated by backpropagation.</li>
</ul>
<h3 id="ATTENTION-GUIDED-ROLE-COORDINATION"><a href="#ATTENTION-GUIDED-ROLE-COORDINATION" class="headerlink" title="ATTENTION-GUIDED ROLE COORDINATION"></a>ATTENTION-GUIDED ROLE COORDINATION</h3><ul>
<li>global state å’Œ agentâ€™s role representations è¿›è¡Œå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶è®¡ç®—: ä¿ƒè¿›global stateå…³æ³¨å­¦ä¹ åˆ°çš„ role representations -&gt; ä»è€Œåœ¨ä»·å€¼åˆ†è§£ä¸­æä¾›æ›´å…·æœ‰è¡¨ç°åŠ›çš„ä¿¡ç”¨åˆ†é…</li>
</ul>
<h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><p><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709893541789.png" alt="1709893541789"></p>
<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><ol>
<li>Can ACORM facilitate learning efficiency and stability in complex multi-agent domains? If so, what are the respective contributions of different modules to the performance gains? (See Sec. 3.1).</li>
<li>Can ACORM learn meaningful role representations associated with agentâ€™s behavior patterns and achieve effective dynamic team composition? (See Sec. 3.2).</li>
<li>Can ACORM successfully attend to learned role representations to realize skillful role coordination and more expressive credit assignment? (See Sec. 3.3).</li>
</ol>
<h3 id="3-1-efficiency-and-stability"><a href="#3-1-efficiency-and-stability" class="headerlink" title="3.1 efficiency and stability"></a>3.1 efficiency and stability</h3><ul>
<li><strong>performance</strong>:<br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709895486679.png" alt="1709895486679"></li>
<li>A noteworthy point is that ACORM outperforms all baselines by the largest margin on super hard maps that demand a significantly higher degree of behavior diversity and coordination: MMM2, 3s5z_vs_3s6z, and corridor.</li>
<li>ACORM exhibits the lowest variance in learning curves, signifying not only superior learning efficiency but also enhanced training stability.</li>
<li><strong>Abations</strong>:<br><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709897074004.png" alt="1709897074004"></li>
<li>It demonstrates that both components are essential for ACORMâ€™s capability and they are complementary to each other.</li>
<li>Specifically, ACORM_w/o_MHA (Vanilla) obtains very similar performance compared to ACORM_w/o_MHA, indicating that the effectiveness comes from the attention module other than encoding the state trajectory via a GRU.</li>
</ul>
<h3 id="3-2-CONTRASTIVE-ROLE-REPRESENTATIONS"><a href="#3-2-CONTRASTIVE-ROLE-REPRESENTATIONS" class="headerlink" title="3.2 CONTRASTIVE ROLE REPRESENTATIONS"></a>3.2 CONTRASTIVE ROLE REPRESENTATIONS</h3><p><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709908700732.png" alt="1709908700732"></p>
<ul>
<li><strong>why use the contrastive learning</strong>: <ul>
<li><strong>ei v.s. zi</strong>: Initially (t = 1, 12), all agent embeddings tend to be crowded together with limited discrimination, and the K-means algorithm moderately separates them into several clusters. Via contrastive learning, the acquired role representations within the same cluster are pushed closer to each other, and those in different clusters are notably separated.</li>
<li>At a later stage (t = 40), agent embeddings are already scattered widely throughout the space with a good clustering effect so far. This phenomenon indicates that the system has learned effective role assignment with heterogeneous behavior patterns. Then, the role encoder transforms these agent embeddings into more discriminative role representations.</li>
<li>è‡³äºæœ¬æ–‡ä¸ºä»€ä¹ˆè¦åœ¨K-meansèšç±»çš„åŸºç¡€ä¸Šå†åšå¯¹æ¯”å­¦ä¹ ï¼Œæˆ‘è®¤ä¸ºåº”è¯¥æ˜¯etçš„ç‰¹å¾åŒ…å«äº†å¾ˆå¤šä»»åŠ¡æ— å…³çš„ä¿¡æ¯ï¼Œè€Œè¿›è¡Œå¯¹æ¯”å­¦ä¹ å¯ä»¥æå–å‡ºæ›´ä¸ºæŠ½è±¡æœ‰ç”¨çš„ç‰¹å¾zt ä»…åŒ…å«agentæŠ€èƒ½åˆä½œç›¸å…³çš„ä¿¡æ¯<h3 id="3-3-ATTENTION-GUIDED-ROLE-COORDINATION"><a href="#3-3-ATTENTION-GUIDED-ROLE-COORDINATION" class="headerlink" title="3.3 ATTENTION-GUIDED ROLE COORDINATION"></a>3.3 ATTENTION-GUIDED ROLE COORDINATION</h3><img src="/2024/03/04/ATTENTION-GUIDED-CONTRASTIVE-ROLE-REPRE-SENTATIONS-FOR-MULTI-AGENT-REINFORCEMENT-LEARNING/1709909066167.png" alt="1709909066167"></li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/02/pytorch%E4%B8%ADreshape%E5%92%8Ctranspose/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/02/pytorch%E4%B8%ADreshape%E5%92%8Ctranspose/" class="post-title-link" itemprop="url">pytorchä¸­reshapeå’Œtranspose</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">å‘è¡¨äº</span>
      

      <time title="åˆ›å»ºæ—¶é—´ï¼š2024-03-02 20:58:24 / ä¿®æ”¹æ—¶é—´ï¼š22:01:24" itemprop="dateCreated datePublished" datetime="2024-03-02T20:58:24+08:00">2024-03-02</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
      <span>998</span>
    </span>
    <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
      <span>2 åˆ†é’Ÿ</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="pytorchä¸­reshapeå’Œtranspose"><a href="#pytorchä¸­reshapeå’Œtranspose" class="headerlink" title="pytorchä¸­reshapeå’Œtranspose"></a>pytorchä¸­reshapeå’Œtranspose</h1><h2 id="torch-reshape-input-shape-x-reshape-size"><a href="#torch-reshape-input-shape-x-reshape-size" class="headerlink" title="torch.reshape(input, shape) x.reshape(size)"></a>torch.reshape(input, shape) x.reshape(size)</h2><ul>
<li><strong>reshapeå°±ç›¸å½“äºæŠŠåŸæœ¬çš„æ•°æ®ä»æœ€é‡Œå±‚[]ä¸­çš„æ•°æ®å¼€å§‹é€å±‚å±•å¼€æˆä¸€ç»´çš„æ•°æ®, ç„¶åé‡æ„æ•°æ®</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.arange(<span class="number">24</span>).reshape(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">y = torch.reshape(x, (<span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;x: <span class="subst">&#123;x&#125;</span>\ny: <span class="subst">&#123;y&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">x: tensor([[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">         [ <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">         [ <span class="number">8</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">         [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>],</span><br><span class="line">         [<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>]]])</span><br><span class="line">y: tensor([[[ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>],</span><br><span class="line">         [ <span class="number">3</span>,  <span class="number">4</span>,  <span class="number">5</span>],</span><br><span class="line">         [ <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">8</span>],</span><br><span class="line">         [ <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>],</span><br><span class="line">         [<span class="number">15</span>, <span class="number">16</span>, <span class="number">17</span>],</span><br><span class="line">         [<span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">         [<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>]]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="/2024/03/02/pytorch%E4%B8%ADreshape%E5%92%8Ctranspose/1709385244067.png" alt="1709385244067"></p>
<h2 id="2-torch-transpose-input-dim0-dim1-gt-tensor"><a href="#2-torch-transpose-input-dim0-dim1-gt-tensor" class="headerlink" title="2 torch.transpose(input, dim0, dim1) -&gt; tensor"></a>2 torch.transpose(input, dim0, dim1) -&gt; tensor</h2><ul>
<li>transposeæ“ä½œå¯èƒ½ç»å¸¸ä½¿ç”¨ï¼Œä½†æ˜¯å½“ç»´åº¦é«˜æ—¶å¾ˆå®¹æ˜“å¯¹æ•°æ®çš„ç»“æ„äº§ç”Ÿç†è§£ä¸Šçš„æ··ä¹±ï¼Œ<strong>å…³é”®åœ¨äºä¸ç”¨ç®¡æ•°æ®å±‚é¢æ—¶æ€ä¹ˆè½¬ç½®çš„ï¼Œè€Œæ˜¯æŠ“ä½æ¯ä¸ªç»´åº¦çš„æ„ä¹‰ï¼Œè½¬ç½®åªæ˜¯æŠŠä¸¤ä¸ªç»´åº¦çš„æ„ä¹‰äº¤æ¢äº†ä¸€ä¸‹ï¼Œè€Œå…¶ä»–ç»´åº¦æ˜¯ä¸ä¼šæ”¹å˜çš„</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.arange(<span class="number">24</span>).reshape(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">y = torch.transpose(x, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;x=<span class="subst">&#123;x&#125;</span>\ny=<span class="subst">&#123;y&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">x=tensor([[[[ <span class="number">0</span>,  <span class="number">1</span>],</span><br><span class="line">          [ <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">          [ <span class="number">4</span>,  <span class="number">5</span>]],</span><br><span class="line"></span><br><span class="line">         [[ <span class="number">6</span>,  <span class="number">7</span>],</span><br><span class="line">          [ <span class="number">8</span>,  <span class="number">9</span>],</span><br><span class="line">          [<span class="number">10</span>, <span class="number">11</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[<span class="number">12</span>, <span class="number">13</span>],</span><br><span class="line">          [<span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">          [<span class="number">16</span>, <span class="number">17</span>]],</span><br><span class="line"></span><br><span class="line">         [[<span class="number">18</span>, <span class="number">19</span>],</span><br><span class="line">          [<span class="number">20</span>, <span class="number">21</span>],</span><br><span class="line">          [<span class="number">22</span>, <span class="number">23</span>]]]])</span><br><span class="line">y=tensor([[[[ <span class="number">0</span>,  <span class="number">1</span>],</span><br><span class="line">          [ <span class="number">6</span>,  <span class="number">7</span>]],</span><br><span class="line"></span><br><span class="line">         [[ <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">          [ <span class="number">8</span>,  <span class="number">9</span>]],</span><br><span class="line"></span><br><span class="line">         [[ <span class="number">4</span>,  <span class="number">5</span>],</span><br><span class="line">          [<span class="number">10</span>, <span class="number">11</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[<span class="number">12</span>, <span class="number">13</span>],</span><br><span class="line">          [<span class="number">18</span>, <span class="number">19</span>]],</span><br><span class="line"></span><br><span class="line">         [[<span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">          [<span class="number">20</span>, <span class="number">21</span>]],</span><br><span class="line"></span><br><span class="line">         [[<span class="number">16</span>, <span class="number">17</span>],</span><br><span class="line">          [<span class="number">22</span>, <span class="number">23</span>]]]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="/2024/03/02/pytorch%E4%B8%ADreshape%E5%92%8Ctranspose/1709388056943.png" alt="1709388056943"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/03/01/pytorch%E4%B8%AD%E5%85%B3%E4%BA%8E%E7%9F%A9%E9%98%B5%E7%9A%84%E4%B9%98%E6%B3%95%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/03/01/pytorch%E4%B8%AD%E5%85%B3%E4%BA%8E%E7%9F%A9%E9%98%B5%E7%9A%84%E4%B9%98%E6%B3%95%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">pytorchä¸­å…³äºçŸ©é˜µçš„ä¹˜æ³•æ€»ç»“</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">å‘è¡¨äº</span>

      <time title="åˆ›å»ºæ—¶é—´ï¼š2024-03-01 19:50:57" itemprop="dateCreated datePublished" datetime="2024-03-01T19:50:57+08:00">2024-03-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">æ›´æ–°äº</span>
      <time title="ä¿®æ”¹æ—¶é—´ï¼š2024-03-02 20:26:17" itemprop="dateModified" datetime="2024-03-02T20:26:17+08:00">2024-03-02</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
      <span>4.3k</span>
    </span>
    <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
      <span>7 åˆ†é’Ÿ</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="pytorchä¸­å…³äºçŸ©é˜µçš„ä¹˜æ³•æ€»ç»“"><a href="#pytorchä¸­å…³äºçŸ©é˜µçš„ä¹˜æ³•æ€»ç»“" class="headerlink" title="pytorchä¸­å…³äºçŸ©é˜µçš„ä¹˜æ³•æ€»ç»“"></a>pytorchä¸­å…³äºçŸ©é˜µçš„ä¹˜æ³•æ€»ç»“</h1><p><strong>torch.mul(), *, torch.mm(), @, torch.bmm(), torch.dot(), torch.mv(), torch.matmul(), torch.einsum()</strong></p>
<h2 id="1-torch-mul-x-y-å’Œ-è¿ç®—"><a href="#1-torch-mul-x-y-å’Œ-è¿ç®—" class="headerlink" title="1 torch.mul(x, y) å’Œ * è¿ç®—"></a>1 torch.mul(x, y) å’Œ * è¿ç®—</h2><ul>
<li>è¡¨ç¤ºä¸¤ä¸ªçŸ©é˜µå¯¹åº”ä½ç½®ä¸Šçš„å…ƒç´ ç›¸ä¹˜ï¼Œå¯ä»¥å¹¿æ’­<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">y = <span class="number">2</span></span><br><span class="line">z = torch.mul(x, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(x, y, x * y, z))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>]])</span><br><span class="line"><span class="number">2</span></span><br><span class="line">tensor([[<span class="number">2.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>]])</span><br><span class="line">tensor([[<span class="number">2.</span>, <span class="number">2.</span>],</span><br><span class="line">        [<span class="number">2.</span>, <span class="number">2.</span>]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="2-torch-mm-x-y-å’Œ-è¿ç®—"><a href="#2-torch-mm-x-y-å’Œ-è¿ç®—" class="headerlink" title="2 torch.mm(x, y) å’Œ @è¿ç®—"></a>2 torch.mm(x, y) å’Œ @è¿ç®—</h2><ul>
<li>çº¿æ€§ä»£æ•°ä¸­çš„çŸ©é˜µä¹˜æ³• x å’Œ yåªèƒ½æ˜¯äºŒç»´ x = (n, m) y = (m, p) torch.mm(x, y) = (n, p) <strong>ä¸æ”¯æŒå¹¿æ’­</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">y = torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">z = torch.mm(x, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(x, y, x @ y, z))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tensor([[-<span class="number">0.6012</span>,  <span class="number">1.4065</span>, -<span class="number">0.8835</span>],</span><br><span class="line">        [ <span class="number">0.4794</span>,  <span class="number">0.7086</span>,  <span class="number">0.6491</span>]])</span><br><span class="line">tensor([[ <span class="number">0.4244</span>, -<span class="number">0.4029</span>,  <span class="number">1.6911</span>,  <span class="number">0.5680</span>],</span><br><span class="line">        [ <span class="number">2.0811</span>,  <span class="number">0.4253</span>, -<span class="number">0.9852</span>,  <span class="number">0.8593</span>],</span><br><span class="line">        [-<span class="number">0.5978</span>,  <span class="number">0.7914</span>, -<span class="number">0.7826</span>,  <span class="number">0.4671</span>]])</span><br><span class="line">tensor([[ <span class="number">3.2000</span>,  <span class="number">0.1413</span>, -<span class="number">1.7111</span>,  <span class="number">0.4544</span>],</span><br><span class="line">        [ <span class="number">1.2901</span>,  <span class="number">0.6219</span>, -<span class="number">0.3954</span>,  <span class="number">1.1845</span>]])</span><br><span class="line">tensor([[ <span class="number">3.2000</span>,  <span class="number">0.1413</span>, -<span class="number">1.7111</span>,  <span class="number">0.4544</span>],</span><br><span class="line">        [ <span class="number">1.2901</span>,  <span class="number">0.6219</span>, -<span class="number">0.3954</span>,  <span class="number">1.1845</span>]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="3-torch-bmm-x-y"><a href="#3-torch-bmm-x-y" class="headerlink" title="3 torch.bmm(x, y)"></a>3 torch.bmm(x, y)</h2><ul>
<li>æ‰§è¡Œä¸€ä¸ªbatchçš„çŸ©é˜µä¹˜æ³• <strong>x å’Œ y å¿…é¡»æ˜¯3-Då¼ é‡ ä¸”æ˜¯x = (b, n, m) y = (b, n, p)</strong> <strong>ä¸æ”¯æŒå¹¿æ’­</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">y = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">z = torch.bmm(x, y) <span class="comment"># [2, 2, 4]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(x, y, z))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[ <span class="number">0.4304</span>,  <span class="number">0.9056</span>,  <span class="number">0.4578</span>],</span><br><span class="line">         [-<span class="number">3.1024</span>,  <span class="number">0.1185</span>,  <span class="number">0.8143</span>]],</span><br><span class="line"></span><br><span class="line">        [[-<span class="number">0.1249</span>, -<span class="number">0.7876</span>, -<span class="number">0.0426</span>],</span><br><span class="line">         [-<span class="number">1.5175</span>, -<span class="number">1.0602</span>,  <span class="number">2.4620</span>]]])</span><br><span class="line">tensor([[[-<span class="number">0.2403</span>, -<span class="number">0.5954</span>,  <span class="number">1.2178</span>, -<span class="number">1.3661</span>],</span><br><span class="line">         [ <span class="number">0.7626</span>, -<span class="number">0.0728</span>,  <span class="number">0.2353</span>,  <span class="number">0.0733</span>],</span><br><span class="line">         [-<span class="number">0.1070</span>, -<span class="number">0.3414</span>, -<span class="number">0.2480</span>, -<span class="number">1.0626</span>]],</span><br><span class="line"></span><br><span class="line">        [[-<span class="number">0.5171</span>, -<span class="number">0.6608</span>,  <span class="number">1.3164</span>, -<span class="number">1.2351</span>],</span><br><span class="line">         [ <span class="number">1.9305</span>,  <span class="number">0.1607</span>,  <span class="number">0.8634</span>, -<span class="number">0.6855</span>],</span><br><span class="line">         [-<span class="number">0.3664</span>,  <span class="number">0.3081</span>,  <span class="number">1.1023</span>, -<span class="number">1.6237</span>]]])</span><br><span class="line">tensor([[[ <span class="number">0.5383</span>, -<span class="number">0.4785</span>,  <span class="number">0.6237</span>, -<span class="number">1.0081</span>],</span><br><span class="line">         [ <span class="number">0.7487</span>,  <span class="number">1.5606</span>, -<span class="number">3.9523</span>,  <span class="number">3.3816</span>]],</span><br><span class="line"></span><br><span class="line">        [[-<span class="number">1.4404</span>, -<span class="number">0.0572</span>, -<span class="number">0.8915</span>,  <span class="number">0.7634</span>],</span><br><span class="line">         [-<span class="number">2.1641</span>,  <span class="number">1.5909</span>, -<span class="number">0.1993</span>, -<span class="number">1.3964</span>]]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="4-torch-dot-x-y-gt-tensor-scalar"><a href="#4-torch-dot-x-y-gt-tensor-scalar" class="headerlink" title="4 torch.dot(x, y) -&gt; tensor (scalar)"></a>4 torch.dot(x, y) -&gt; tensor (scalar)</h1><ul>
<li><strong>ä¸¤ä¸ªå…ƒç´ ä¸ªæ•°ç›¸åŒçš„ä¸€ç»´å¼ é‡</strong>ç‚¹ç§¯è¿ç®— <strong>å’Œnumpyçš„dotä¸åŒï¼Œtorch.dot(x, y)ä»…æ”¯æŒä¸¤ä¸ªä¸€ç»´å¼ é‡</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">y = torch.tensor([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">z = torch.dot(x, y) <span class="comment"># 1*4 + 2*5 + 3*6 = 32</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(x, y, z))</span><br><span class="line"></span><br><span class="line"><span class="comment"># error</span></span><br><span class="line"><span class="comment"># y = torch.tensor([[1, 2, 3], [1, 2, 3], [1, 2, 3]])</span></span><br><span class="line"><span class="comment"># z = torch.dot(x, y)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">tensor([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"><span class="number">32</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="5-torch-mv-x-y-gt-Tensor"><a href="#5-torch-mv-x-y-gt-Tensor" class="headerlink" title="5 torch.mv(x, y) -&gt; Tensor"></a>5 torch.mv(x, y) -&gt; Tensor</h1><ul>
<li><strong>matrix-vector and x = (n, m) y = (m, ) -&gt; return = (n, )</strong> ä¸æ”¯æŒå¹¿æ’­<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">y = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">z = torch.mv(x, y) <span class="comment"># [1*1 + 2*2 + 3*3, 4*1 + 5*2 + 6*3]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(x, y, z))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ERROR</span></span><br><span class="line"><span class="comment"># z = torch.mv(y, x)</span></span><br><span class="line"><span class="comment"># print(&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;.format(x, y, z))</span></span><br><span class="line"><span class="comment"># y = torch.tensor([1, 2])</span></span><br><span class="line"><span class="comment"># z = torch.mv(y, x)</span></span><br><span class="line"><span class="comment"># print(&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;.format(x, y, z))</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">tensor([<span class="number">14</span>, <span class="number">32</span>])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="6-torch-matmul-x-y-gt-tensor"><a href="#6-torch-matmul-x-y-gt-tensor" class="headerlink" title="6 torch.matmul(x, y) -&gt; tensor"></a>6 torch.matmul(x, y) -&gt; tensor</h1><ul>
<li>æ¯”è¾ƒå…¨èƒ½çš„ä¸€ç§ä¹˜æ³• <strong>æ”¯æŒå¹¿æ’­</strong> æ”¯æŒä»»ä½•ç»´åº¦å¯ç›¸ä¹˜çš„tensorç›¸ä¹˜<br><img src="/2024/03/01/pytorch%E4%B8%AD%E5%85%B3%E4%BA%8E%E7%9F%A9%E9%98%B5%E7%9A%84%E4%B9%98%E6%B3%95%E6%80%BB%E7%BB%93/1709381483833.png" alt="1709381483833"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">y = torch.randn(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">z = torch.matmul(x, y) <span class="comment"># [2, 2, 2, 2]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;\n&#123;&#125;\n&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(x, y, z))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[[-<span class="number">0.9772</span>, -<span class="number">0.0628</span>, -<span class="number">0.5369</span>],</span><br><span class="line">          [-<span class="number">0.3113</span>,  <span class="number">1.7524</span>,  <span class="number">0.7249</span>]],</span><br><span class="line"></span><br><span class="line">         [[-<span class="number">1.1878</span>,  <span class="number">0.0895</span>,  <span class="number">0.7625</span>],</span><br><span class="line">          [ <span class="number">0.2828</span>,  <span class="number">0.1154</span>, -<span class="number">0.8482</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ <span class="number">0.8277</span>,  <span class="number">0.4449</span>,  <span class="number">0.0741</span>],</span><br><span class="line">          [ <span class="number">0.9390</span>, -<span class="number">0.6762</span>,  <span class="number">0.4093</span>]],</span><br><span class="line"></span><br><span class="line">         [[-<span class="number">0.2564</span>,  <span class="number">0.8857</span>, -<span class="number">0.1946</span>],</span><br><span class="line">          [-<span class="number">0.9418</span>,  <span class="number">0.0510</span>, -<span class="number">0.2456</span>]]]])</span><br><span class="line">tensor([[[[-<span class="number">0.0997</span>,  <span class="number">0.2760</span>],</span><br><span class="line">          [-<span class="number">0.7134</span>, -<span class="number">0.4839</span>],</span><br><span class="line">          [-<span class="number">1.3931</span>,  <span class="number">0.2729</span>]],</span><br><span class="line"></span><br><span class="line">         [[-<span class="number">0.4765</span>,  <span class="number">0.5714</span>],</span><br><span class="line">          [ <span class="number">1.4368</span>,  <span class="number">1.2979</span>],</span><br><span class="line">          [ <span class="number">1.0061</span>,  <span class="number">0.2874</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[-<span class="number">0.0596</span>,  <span class="number">0.5366</span>],</span><br><span class="line">          [ <span class="number">0.2938</span>, -<span class="number">0.6728</span>],</span><br><span class="line">          [-<span class="number">0.0664</span>, -<span class="number">1.8749</span>]],</span><br><span class="line"></span><br><span class="line">         [[ <span class="number">0.1983</span>, -<span class="number">0.2220</span>],</span><br><span class="line">          [-<span class="number">1.4755</span>, -<span class="number">2.2627</span>],</span><br><span class="line">          [-<span class="number">0.4390</span>,  <span class="number">0.4608</span>]]]])</span><br><span class="line">tensor([[[[ <span class="number">0.8902</span>, -<span class="number">0.3858</span>],</span><br><span class="line">          [-<span class="number">2.2289</span>, -<span class="number">0.7362</span>]],</span><br><span class="line"></span><br><span class="line">         [[ <span class="number">1.4617</span>, -<span class="number">0.3435</span>],</span><br><span class="line">          [-<span class="number">0.8224</span>,  <span class="number">0.0675</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ <span class="number">0.0764</span>,  <span class="number">0.0058</span>],</span><br><span class="line">          [-<span class="number">0.2818</span>,  <span class="number">0.1914</span>]],</span><br><span class="line"></span><br><span class="line">         [[-<span class="number">1.2722</span>, -<span class="number">2.0368</span>],</span><br><span class="line">          [-<span class="number">0.1542</span>, -<span class="number">0.0195</span>]]]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="7-torch-einsum-gt-çˆ±å› æ–¯å¦æ±‚å’Œçº¦å®š"><a href="#7-torch-einsum-gt-çˆ±å› æ–¯å¦æ±‚å’Œçº¦å®š" class="headerlink" title="7 torch.einsum() -&gt; çˆ±å› æ–¯å¦æ±‚å’Œçº¦å®š"></a>7 torch.einsum() -&gt; çˆ±å› æ–¯å¦æ±‚å’Œçº¦å®š</h1><ul>
<li><em>åŠŸèƒ½ååˆ†å¼ºå¤§ï¼Œæ”¯æŒæ±‚å’Œè¿ç®—, å„ç§ä¹˜æ³•è¿ç®—, transposeè¿ç®—ç­‰ç­‰</em><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># trace</span></span><br><span class="line">torch.einsum(<span class="string">&#x27;ii&#x27;</span>, torch.randn(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># diagonal</span></span><br><span class="line">torch.einsum(<span class="string">&#x27;ii-&gt;i&#x27;</span>, torch.randn(<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># outer product</span></span><br><span class="line">x = torch.randn(<span class="number">5</span>)</span><br><span class="line">y = torch.randn(<span class="number">4</span>)</span><br><span class="line">torch.einsum(<span class="string">&#x27;i,j-&gt;ij&#x27;</span>, x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># batch matrix multiplication</span></span><br><span class="line">As = torch.randn(<span class="number">3</span>, <span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line">Bs = torch.randn(<span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>)</span><br><span class="line">torch.einsum(<span class="string">&#x27;bij,bjk-&gt;bik&#x27;</span>, As, Bs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># with sublist format and ellipsis</span></span><br><span class="line">torch.einsum(As, [..., <span class="number">0</span>, <span class="number">1</span>], Bs, [..., <span class="number">1</span>, <span class="number">2</span>], [..., <span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># batch permute</span></span><br><span class="line">A = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">torch.einsum(<span class="string">&#x27;...ij-&gt;...ji&#x27;</span>, A).shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># equivalent to torch.nn.functional.bilinear</span></span><br><span class="line">A = torch.randn(<span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>)</span><br><span class="line">l = torch.randn(<span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line">r = torch.randn(<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">torch.einsum(<span class="string">&#x27;bn,anm,bm-&gt;ba&#x27;</span>, l, A, r)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="8-æ€»ç»“"><a href="#8-æ€»ç»“" class="headerlink" title="8 æ€»ç»“"></a>8 æ€»ç»“</h1><p>ä¸€èˆ¬åœ¨ç¥ç»ç½‘ç»œä¸­å¸¸ç”¨çš„å°±æ˜¯ 1. torch.dot(x, y) æ±‚ä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯ 2. torch.bmm(x, y) æ±‚ä¸€ä¸ªbatchçš„çŸ©é˜µæ•°æ®ç›¸ä¹˜ (<strong>å¿…é¡»æ˜¯ä¸‰ç»´[b, n, m] Ã— [b, m, q]</strong>) 3. torch.matmul(x, y)<strong>æ±‚ç»´åº¦è¶…è¿‡ä¸‰ç»´æˆ–è€…éœ€è¦å¹¿æ’­çš„çŸ©é˜µä¹˜æ³•</strong></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://xwqianbei.github.io/2024/02/26/RACE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wei">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="attention is all you need">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | ç±³å…°çš„å°é“é…±">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/02/26/RACE/" class="post-title-link" itemprop="url">RACE</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">å‘è¡¨äº</span>

      <time title="åˆ›å»ºæ—¶é—´ï¼š2024-02-26 20:57:10" itemprop="dateCreated datePublished" datetime="2024-02-26T20:57:10+08:00">2024-02-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">æ›´æ–°äº</span>
      <time title="ä¿®æ”¹æ—¶é—´ï¼š2024-02-29 12:06:50" itemprop="dateModified" datetime="2024-02-29T12:06:50+08:00">2024-02-29</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
      <span>2k</span>
    </span>
    <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
      <span>3 åˆ†é’Ÿ</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="RACE-Improve-Multi-Agent-Reinforcement-Learning-with-Representation-Asymmetry-and-Collaborative-Evolution"><a href="#RACE-Improve-Multi-Agent-Reinforcement-Learning-with-Representation-Asymmetry-and-Collaborative-Evolution" class="headerlink" title="RACE: Improve Multi-Agent Reinforcement Learning with Representation Asymmetry and Collaborative Evolution"></a>RACE: Improve Multi-Agent Reinforcement Learning with Representation Asymmetry and Collaborative Evolution</h1><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li><strong>challenge</strong>: MARL åœ¨åˆä½œæ–¹é¢ æŒ£æ‰åœ¨ä½è´¨é‡çš„å¥–åŠ±ä¿¡å·å’Œé«˜ä¸ç¨³å®šæ€§</li>
<li><strong>Evolutionary Algorithm(EA)</strong>: æ›´å¥½çš„æ”¶æ•›ã€æ›´åŠ å¥å£®é²æ£’ã€å¯¹å¥–åŠ±ä¿¡å·ä¸æ•æ„Ÿ</li>
<li><strong>in this paper</strong>: æœ¬æ–‡æå‡ºä¸€ä¸ªæ··åˆæ¡†æ¶ï¼š Representation Asymmetry and Collaboration Evolution (RACE) -&gt; å°†EAå’ŒMARLç»“åˆ ä»¥è¾¾åˆ°é«˜æ•ˆçš„åˆä½œ</li>
<li><strong>method</strong>: RACE ç»´æŒä¸€ä¸ªMARL teamå’Œä¸€ç¾¤EA teams. ä¸ºäº†é«˜æ•ˆçš„çŸ¥è¯†å…±äº«å’Œç­–ç•¥æ¢ç´¢ -&gt; RACE æŠŠä¸åŒteamæ§åˆ¶ç›¸åŒagentçš„ policies åˆ†è§£æˆ 1. shared nonlinear observation representation encoderï¼ˆå…±äº«çš„éçº¿æ€§è§‚å¯Ÿè¡¨ç¤ºç¼–ç å™¨encoderï¼‰ 2. individual linear policy representations.ï¼ˆç‹¬ç«‹çš„çº¿æ€§ç­–ç•¥è¡¨ç¤ºï¼‰ trick1: ä¸ºäº†è§£å†³éƒ¨åˆ†è§‚å¯Ÿçš„é—®é¢˜, æœ¬æ–‡å¼•å…¥Value-Aware Mutual Information Maximization ï¼ˆä»·å€¼æ„ŸçŸ¥ äº’ä¿¡æ¯æœ€å¤§åŒ–ï¼‰-&gt; åˆ©ç”¨æœ‰å…³å…¨å±€çŠ¶æ€çš„æœ‰ç”¨ä¿¡æ¯å¢å¼ºå…±äº«è¡¨ç¤º    trick2: ä¸ºäº†ä¿ƒè¿›åè°ƒ -&gt; ä½¿ç”¨æ–°é¢–çš„ agent-level äº¤å‰å’Œå˜å¼‚ç®—å­æ¥è¿›åŒ–ç§ç¾¤ -&gt; ä¸ºMARLæä¾›å¤šæ ·åŒ–çš„ç»éªŒ  trick3: MARLä¼˜åŒ–å®ƒçš„ç­–ç•¥å¹¶ä¸”å°†å®ƒä»¬æ³¨å…¥åˆ°ç§ç¾¤ä¸­è¿›åŒ–</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><ul>
<li><strong>motivation</strong>: EA has strong exploration ability, good robustness, and stable convergence. EA offers numerous strengths that can complement the weaknesses of MARL.</li>
<li><strong>challenge</strong>: ç‹¬ç«‹ç»´æŒå’Œä¼˜åŒ–æ¯ä¸ªteamçš„policyæ˜¯éå¸¸ä¸é«˜æ•ˆçš„ å¹¶ä¸”è¿™æ ·æ— æ³•åˆ©ç”¨å…¶ä»–teamè·å¾—çš„æœ‰ä»·å€¼çš„çŸ¥è¯† åœ¨å¹¿é˜”çš„éçº¿æ€§ç­–ç•¥ç©ºé—´æ¢ç´¢åˆä½œæ˜¯éå¸¸ä½æ•ˆçš„</li>
<li><strong>methods</strong>: æå‡ºä¸¤çº§å›¢é˜Ÿç­–ç•¥æµ‹ç»“æ„ 1. å…±äº«çš„éçº¿æ€§è§‚å¯Ÿè¡¨ç¤º(shared observation represention encoder) 2. ç‹¬ç«‹çš„çº¿æ€§ç­–ç•¥è¡¨ç¤º(independent policy representions)</li>
<li><strong>represention asymmetry</strong>: independent policyæ„å»ºçš„ä¸åŒè¡¨ç¤ºèŒƒå›´</li>
<li><strong>observation representation encoder</strong>: è´Ÿè´£å…±äº«ä»»åŠ¡ç›¸å…³å’Œåˆä½œç›¸å…³çš„çŸ¥è¯† -&gt; é€šè¿‡ä»·å€¼å‡½æ•°æœ€å¤§åŒ–çš„é›†æˆï¼ˆæ¶‰åŠæ‰€æœ‰çš„EA team å’Œ MARL teamï¼‰æ›´æ–°æ–¹å‘è¿›è¡Œä¼˜åŒ–</li>
<li><strong>Value-Aware Mutual Information Maximization</strong>: æœ€å¤§åŒ–å…±äº«è§‚å¯Ÿè¡¨ç¤º(shared observation representations) å’Œå…¨å±€çŠ¶æ€çš„äº’ä¿¡æ¯(MI)ã€‚ -&gt; åœ¨ä½ä»·å€¼çŠ¶æ€ä¸‹è¿›è¡Œæœ€å¤§åŒ–å¯èƒ½å¯¼è‡´å¯¹å…±äº«è§‚å¯Ÿè¡¨ç¤º(shared observation representation)çš„è´Ÿé¢å½±å“ -&gt; å¯¼è‡´åˆä½œä¸ç†æƒ³ -&gt; Value-Aware MI: å½’ä¸€åŒ–çŠ¶æ€ä»·å€¼å‡½æ•°ä½œä¸ºæƒé‡ å·²åˆ°è¾¾ æå–å…¨å±€çŠ¶æ€ä¿¡æ¯åŠ å…¥å…±äº«è§‚å¯Ÿè¡¨ç¤º(shared observation representations)</li>
<li><strong>independent linear policy</strong>: åœ¨æ›´åŠ ç´§å‡‘å’Œæœ‰åˆ©çš„çº¿æ€§ç©ºé—´ policyçš„æ¢ç´¢æ›´åŠ æœ‰æ•ˆ ä»è€Œä¿ƒè¿›åˆä½œ</li>
<li><strong>EA</strong>: EAè¿›åŒ–ç§ç¾¤ ç”Ÿæˆå¤šæ ·æ€§çš„ç»éªŒ -&gt; è¢«MARLä½¿ç”¨ -&gt; åè¿‡æ¥ï¼ŒMARL teamé€šè¿‡æ”¶é›†çš„æ ·æœ¬è¿›è¡Œä¼˜åŒ– å¹¶ä¸”å®šæœŸåŠ å…¥ç§ç¾¤è¿›åŒ–</li>
<li>agent-level äº¤å‰å˜å¼‚ -&gt; äº¤æ¢ä¸¤ä¸ªteamçš„individual policy representation -&gt; æ¢ç´¢æ›´å¥½çš„å›¢é˜Ÿåˆä½œ</li>
</ul>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><ol>
<li>Representation Asymmetry of team construction</li>
<li>How to learn the shared observation representation encoders</li>
<li>How to improve MARL with Collaborative Evolution</li>
</ol>
<ul>
<li><strong>motivation</strong>: æ¯ä¸ªteam ç‹¬ç«‹çš„ç­–ç•¥æ„å»ºé™åˆ¶äº†teamsä¹‹é—´çš„çŸ¥è¯†å…±äº«å’Œåœ¨ç­–ç•¥ç©ºé—´ä¸Šçš„æ¢ç´¢ -&gt; inspired by ERL-Re -&gt; æœ¬æ–‡æå‡ºRepresentation-Asymmetry Team Construction(RATC) ä½¿èƒ½å¤Ÿé«˜æ•ˆçš„çŸ¥è¯†å…±äº«å’Œç­–ç•¥æ¢ç´¢</li>
</ul>
<h3 id="Shared-Observation-Representation-Learning"><a href="#Shared-Observation-Representation-Learning" class="headerlink" title="Shared Observation Representation Learning"></a>Shared Observation Representation Learning</h3>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" title="ä¸‹ä¸€é¡µ" aria-label="ä¸‹ä¸€é¡µ" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Wei</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="ç«™ç‚¹æ€»å­—æ•°">41k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="ç«™ç‚¹é˜…è¯»æ—¶é•¿">1:08</span>
  </span>
</div>
  <div class="powered-by">ç”± <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> å¼ºåŠ›é©±åŠ¨
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="è¿”å›é¡¶éƒ¨">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
